var documenterSearchIndex = {"docs":
[{"location":"tutorial_linsolve/#Tutorial:-Your-own-linear-solver-1","page":"Tutorial 10 (Linear solvers)","title":"Tutorial: Your own linear solver","text":"","category":"section"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"Many of the NEP-solvers are based on solving linear systems of the type","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"M(Œª)x=b","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"In some methods the linear system matrices are the same, i.e., Œª does not change. You can specify which numerical methods should be used to solve the linear system when you call a NEP-solver. This tutorial illustrates this functionality, and finally shows how you can specify your own method for linear systems.","category":"page"},{"location":"tutorial_linsolve/#Built-in-linear-solvers-1","page":"Tutorial 10 (Linear solvers)","title":"Built-in linear solvers","text":"","category":"section"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"The linear solver is specified with the linsolvercreator keyword argument in most NEP-solvers. Let us contruct an example which we will solve with several methods. The matrix M(Œª) is sparse, and the nonlinearity is an exponential term:","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"using NonlinearEigenproblems, SparseArrays, LinearAlgebra;\nn=100;\nŒ±=0.01;\nA=spdiagm(0=>ones(n),1=>Œ±*ones(n-1),-3=>Œ±*ones(n-3));\nB=spdiagm(0=>ones(n));\nC=spdiagm(0=>(1:n)/n);\nnep= SPMF_NEP([A,B,C],[s->one(s),s->s,s->exp(s)],align_sparsity_patterns=true);\nŒª0=-1.2; # Starting guess","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"Let us first solve it with the  resinv method, using the default solver for the linear system:","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"julia> (Œª,x)=resinv(nep,Œª=Œª0,v=ones(n),logger=1,tol=1e-16);\nPrecomputing linsolver\niter 1 err:0.003863455199119409 Œª=-1.2 + 0.0im\niter 2 err:0.0012874946992780317 Œª=-1.175478914232863 + 0.0im\niter 3 err:0.016919177734890205 Œª=-0.9045032212171923 + 0.0im\niter 4 err:7.884718326366283e-5 Œª=-1.1998094425367551 + 0.0im\niter 5 err:9.586775788595438e-5 Œª=-1.1974656536889654 + 0.0im\niter 6 err:3.7870317997772634e-5 Œª=-1.1994205846695276 + 0.0im\niter 7 err:3.0752556063829646e-5 Œª=-1.1985663733901704 + 0.0im\n...\niter 69 err:5.647660764089489e-16 Œª=-1.1989892137958458 + 0.0im\niter 70 err:5.055053391642266e-16 Œª=-1.1989892137958578 + 0.0im\niter 71 err:1.781530900695102e-17 Œª=-1.1989892137958473 + 0.0im","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"We will carry out some timing experiments, so let's use the BenchmarkTools-package and swith off printouts in the NEP-solver:","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"julia> using BenchmarkTools\njulia> @btime (Œª,x)=resinv(nep,Œª=Œª0,v=ones(n),tol=1e-16);\n  8.373 ms (33714 allocations: 11.37 MiB)","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"The linear system that has to be solved in every iteration in resinv has a constant system matrix, and therefore a prefactorization (typically an LU-factorization) is useful. This is done with the FactorizeLinSolverCreator, which is actually the default behaviour, so we get no substantial difference when we specify a creator if the type FactorizeLinSolverCreator.","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"julia> creator=FactorizeLinSolverCreator();\njulia> @btime (Œª,x)=resinv(nep,Œª=Œª0,v=ones(n),maxit=100,linsolvercreator=creator,tol=1e-16);\n  8.332 ms (33704 allocations: 11.37 MiB)","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"If we do not want to use a prefactorization, you can specify BackslashLinSolverCreator as your creator object.","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"julia> creator=BackslashLinSolverCreator();\njulia> @btime (Œª,x)=resinv(nep,Œª=Œª0,v=ones(n),maxit=100,linsolvercreator=creator,tol=1e-16);\n  20.640 ms (38251 allocations: 22.87 MiB)","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"This does not use a prefactorization and is therefore slower.","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"The above approach corresponded to direct methods for linear systems. You can also use iterative methods, e.g., the GMRES-method. The GMRES-method is available in the GMRESLinSolverCreator function. Iterative methods in general need preconditioners. We continue the example and use a diagonal preconditioner:","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"julia> D0=(Diagonal(compute_Mder(nep,Œª0))); # Preconditioner\njulia> creator=GMRESLinSolverCreator(Pl=D0, tol=1e-10);","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"All the keyword arguments in the call GMRESLinSolverCreator are passed to gmres!. Hence, the tol here  specifies a termination criteria for the GMRES-method, and Pl specifies the left preconditioner, in this case just a diagonal matrix.","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"julia> (Œª,x)=resinv(nep,Œª=Œª0,v=ones(n),maxit=100,linsolvercreator=creator,logger=1,tol=1e-16);\nPrecomputing linsolver\niter 1 err:0.003863455199119409 Œª=-1.2 + 0.0im\niter 2 err:0.0012874946993129863 Œª=-1.175478914232863 + 0.0im\niter 3 err:0.01691917773640539 Œª=-0.9045032211965017 + 0.0im\niter 4 err:7.884718724884878e-5 Œª=-1.1998094425350523 + 0.0im\niter 5 err:9.586776747525804e-5 Œª=-1.1974656535293027 + 0.0im\n...\niter 69 err:7.114086177493848e-16 Œª=-1.1989892137958427 + 0.0im\niter 70 err:3.434521011774537e-16 Œª=-1.1989892137958578 + 0.0im\niter 71 err:1.1060298018746236e-16 Œª=-1.1989892137958504 + 0.0im\niter 72 err:1.1903842077731908e-16 Œª=-1.1989892137958529 + 0.0im\niter 73 err:3.82409101411086e-16 Œª=-1.1989892137958553 + 0.0im\niter 74 err:2.8385047264009487e-16 Œª=-1.1989892137958476 + 0.0im\niter 75 err:2.578560246193603e-16 Œª=-1.1989892137958535 + 0.0im\niter 76 err:3.8680157882039993e-16 Œª=-1.198989213795848 + 0.0im\niter 77 err:1.4633231742581634e-16 Œª=-1.1989892137958562 + 0.0im\niter 78 err:2.324747046412835e-16 Œª=-1.198989213795853 + 0.0im\niter 79 err:1.7053137640282208e-16 Œª=-1.1989892137958487 + 0.0im\niter 80 err:5.364097787291277e-17 Œª=-1.1989892137958522 + 0.0im","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"The printout reveals that we need more iterations, than with a direct method. In terms of computation time, this approach can however still be competitive:","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"julia> creator=GMRESLinSolverCreator(Pl=D0, tol=1e-2);\njulia> @btime (Œª,x)=resinv(nep,Œª=Œª0,v=ones(n),maxit=100,linsolvercreator=creator,tol=1e-16);\n  12.734 ms (59414 allocations: 21.14 MiB)","category":"page"},{"location":"tutorial_linsolve/#Your-own-linear-solver-1","page":"Tutorial 10 (Linear solvers)","title":"Your own linear solver","text":"","category":"section"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"There are many ways to solve linear systems in Julia, e.g., by using package such as KrylovKit.jl, Pardiso.jl or KrylovMethods.jl. These are not natively supported by NEP-PACK, but due to the extendability of the LinSolverCreator-objects specified above, you can still use them. We illustrate the extendability by creating a linear solver based on solving a Schur complement. The following helper-function for the Schur complement solve will be used later.","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"function schur_complement_lin_solve(AA,b,n0)\n  A=AA[1:n0,1:n0];\n  B=AA[1:n0,(n0+1):end];\n  C=AA[(n0+1):end,1:n0];\n  D=AA[(n0+1):end,(n0+1):end];\n  S=D-C*(A\\B); # Schur complement\n  b1=b[1:n0]; b2=b[(n0+1):end];\n  Ainvb1=A\\b1; Sinvb2=S\\b2;\n  # Formula for the linear solve:\n  x1=A\\(b1+(B*(S\\(C*(Ainvb1)))))-A\\(B*(Sinvb2))\n  x2=-S\\(C*(Ainvb1))+Sinvb2;\n  return [x1;x2];\nend","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"Julia's efficiency stems partially from the extensive use of types. We need to define new types to specify our own linear solver and integrate it with NEP-PACK.","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"struct MyLinSolverCreator <: LinSolverCreator; end\nstruct MyLinSolver <: LinSolver;\n  mynep\n  myŒª\nend","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"NEP-solvers call the function create_linsolver(creator,nep,Œª), which should return a linear solver. We need to overload this function for our own creator-type. In general, this is to allow precomputation. However, in this example we do not have any precomputations and thus just return an instance ofMyLinSolver`.","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"import NonlinearEigenproblems.create_linsolver # Needed since we want overload it\nfunction create_linsolver(::MyLinSolverCreator,nep,Œª)\n   return MyLinSolver(nep,Œª);\nend","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"The rest of the implementation of the solver goes in the function lin_solve, where we utilize our function schur_complement_lin_solve from above.","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"import NonlinearEigenproblems.LinSolvers.lin_solve # Needed since we want overload it\nfunction lin_solve(solver::MyLinSolver,b::Vector;tol=eps())\n   n0=10;\n   return schur_complement_lin_solve(compute_Mder(solver.mynep,solver.myŒª),b,n0)\nend","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"You can now solve the problem by passing a creator object of type MyLinSolverCreator() to a NEP-solver, e.g., augnewton:","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"julia> dep=nep_gallery(\"dep0\",50);\njulia> creator=MyLinSolverCreator();\njulia> augnewton(dep,v=ones(size(dep,1)),logger=1,linsolvercreator=creator);\niter 1 err:0.09618148118463332 Œª=0.0 + 0.0im\niter 2 err:0.0413217667237937 Œª=0.898990887813898 + 0.0im\niter 3 err:0.02631955794084684 Œª=1.4448248571934017 + 0.0im\niter 4 err:0.00449344510220487 Œª=0.9306146373776565 + 0.0im\niter 5 err:9.030138969728166e-5 Œª=0.9176939995973337 + 0.0im\niter 6 err:9.801547301302623e-7 Œª=0.9205599293430545 + 0.0im\niter 7 err:1.2125237229048776e-10 Œª=0.9205883567517953 + 0.0im\niter 8 err:4.3151896277593487e-16 Œª=0.9205883602865768 + 0.0im","category":"page"},{"location":"tutorial_linsolve/#","page":"Tutorial 10 (Linear solvers)","title":"Tutorial 10 (Linear solvers)","text":"(Image: To the top)","category":"page"},{"location":"movebc_tutorial/#Tutorial:-Application-to-absorbing-boundary-conditions-1","page":"Tutorial 1 (ABC)","title":"Tutorial: Application to absorbing boundary conditions","text":"","category":"section"},{"location":"movebc_tutorial/#A-Schr√∂dinger-equation-1","page":"Tutorial 1 (ABC)","title":"A Schr√∂dinger equation","text":"","category":"section"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"We consider the  Schr√∂dinger type eigenvalue problem on the interval 0L_1,","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"begineqnarray*\n left(\n fracpartial^2partial x^2\n-V(x)-lambda\nright)psi(x)=0 xin0L_1\n   psi(0)=0\n   psi(L_1)=0\nendeqnarray*","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"We wish to compute eigenvalue Œª and eigenfunction psi. Moreover, we assume that the potential function V(x) is benign in the domain L_0L_1, in our case for simplicity it is constant, such that we can later solve the problem in that domain analytically. In the simulations we will consider this function","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"  V(x)=\nbegincases\n1+sin(alpha x)   xin0L_0=01\nV_0  xin(L_0L_1)=(18)\nendcases","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"where Œ± is large, i.e., the potential has high frequency oscillations in one part of the domain.","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"<br>\n<img src=\"https://user-images.githubusercontent.com/11163595/49676288-62c71080-fa79-11e8-8542-3b7857720473.png\" height=300>","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"This tutorial illustrates how we can avoid a discretization of the domain L_0L_1 and only discretize 0L_0, by solving a NEP. The implementation described below is also directly available in the gallery: nep_gallery(\"schrodinger_movebc\").","category":"page"},{"location":"movebc_tutorial/#Derivation-of-reduced-domain-differential-equation-1","page":"Tutorial 1 (ABC)","title":"Derivation of reduced domain differential equation","text":"","category":"section"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"The technique is based on moving the boundary condition at L_1 to L_0. This can be done without doing any approximation, if we allow the new artificial boundary condition at L_0 to depend on Œª. We introduce what is called an absorbing boundary condition, also known as a artificial boundary condition.","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"We first note that we can transform the problem to first order form","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"  fracddx\nbeginbmatrixpsi(x)psi(x)endbmatrix\n=\nbeginbmatrix\n0  1\nlambda+V(x)  0\nendbmatrix\nbeginbmatrixpsi(x)psi(x)endbmatrix","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"The potential V(x) is constant in the domain L_0L_1. This  allows us to directly express the solution using the matrix exponential","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"beginbmatrixpsi(x)psi(x)endbmatrix\n=expleft((x-L_0)\nbeginbmatrix\n0  1\nlambda+V_0  0\nendbmatrix\nright)\nbeginbmatrixpsi(L_0)psi(L_0)endbmatrix","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"when xinL_0L_1. The boundary condition psi(L_1)=0 can be imposed as","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"0=psi(L_1)=beginbmatrix1  0endbmatrix\nbeginbmatrixpsi(L_1)psi(L_1)endbmatrix\n=beginbmatrix1  0endbmatrixexpleft((L_1-L_0)\nbeginbmatrix\n0  1\nlambda+V_0  0\nendbmatrix\nright)\nbeginbmatrixpsi(L_0)psi(L_0)endbmatrix","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"By explicitly using the hyperbolic functions formula for the matrix exponential of an antidiagonal two-by-two matrix we obtain the relation","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"0=\ng(Œª)psi(L_0)+\nf(Œª)psi(L_0)","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"where","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"g(Œª)=coshleft((L_1-L_0)sqrtŒª+V_0right)","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"f(Œª)=fracsinhleft((L_1-L_0)sqrtŒª+V_0right)sqrtŒª+V_0","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"Note that a solution to the original boundary value problem will satisfy the condition 0=g(Œª)psi(L_0)+f(Œª)psi(L_0), which involves only the point x=L_0, i.e., the middle of the domain. We can now disconnect the problem and only consider only the domain 0L_0 by using this condition instead, since a solution to the original boundary value problem satisfies","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"begineqnarray*\n left(\n fracpartial^2partial x^2\n-V(x)-lambda\nright)psi(x)=0 xin0L_0\n   psi(0)=0\n   g(Œª)psi(L_0)+f(Œª)psi(L_0)=0\nendeqnarray*","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"which is a boundary value problem on the reduced domain 0L_0. The boundary condition is a Robin boundary condition (also called mixed boundary condition) at x=L_0, since it contains both psi(L_0) and psi(L_0). It can be shown that the solutions to the original problem are the same as the solutions on the reduced domain, except for some unintresting special cases.","category":"page"},{"location":"movebc_tutorial/#Discretization-of-the-Œª-dependent-boundary-value-problem-1","page":"Tutorial 1 (ABC)","title":"Discretization of the Œª-dependent boundary value problem","text":"","category":"section"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"The boundary condition in the reduced domain boundary value problem is Œª-dependent. Therefore a standard discretization the domain 0L_0, e.g., finite difference, will lead to a nonlinear eigenvalue problem. More precisely, we discretize the problem as follows.","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"Let x_k=hk, k=1ldots n and h=1n such that x_1=h and x_n=1=L_0. An approximation of the lambda-dependent boundary condition can be found with the one-sided second order difference scheme","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"   0=g(Œª)psi(L_0)+f(Œª)frac1hleft(frac32 psi(L_0)\n-2psi(x_n-1)\n+frac12psi(x_n-2)right)+O(h^2)","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"Let","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"  D_n=\nfrac1h^2\nbeginbmatrix\n-2   1  0 \n1  ddots 1 \n0  1 -2  1\n0  cdots  0  0\nendbmatrixtextrm and \nunderlineI_n=beginbmatrix1  ddots 1    0endbmatrix","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"Then the boundary value problem can expressed as","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"M(Œª)v=0","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"where","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"M(Œª)=A-ŒªunderlineI_n\n+g(Œª)e_ne_n^T+f(Œª)F","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"and","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"A=D_n-operatornamediag(V(x_1)ldotsV(x_n-1)0)F=frac12he_ne_n-2^T-frac2he_ne_n-1^T+frac32he_ne_n^T","category":"page"},{"location":"movebc_tutorial/#Implementation-in-NEP-PACK-1","page":"Tutorial 1 (ABC)","title":"Implementation in NEP-PACK","text":"","category":"section"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"The above discretization can be expressed as a SPMF_NEP with four terms. Let us set up the matrices first","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"using LinearAlgebra,SparseArrays;\nL0=1; L1=8; V0=10.0;\nxv=Vector(range(0,stop=L0,length=1000))\nh=xv[2]-xv[1];\nn=size(xv,1);\nŒ±=25*pi/2;\nV=x->1+sin(Œ±*x);\nDn=spdiagm(-1 => [ones(n-2);0]/h^2, 0 => -2*ones(n-1)/h^2, 1 => ones(n-1)/h^2)\nVn=spdiagm(0 => [V.(xv[1:end-1]);0]);\nA=Dn-Vn;\nIn=spdiagm(0 => [ones(n-1);0])\nF=sparse([n, n, n],[n-2, n-1, n],[1/(2*h), -2/h, 3/(2*h)])\nG=sparse([n],[n],[1]);","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"The corresponding functions in the SPMF are defined as follows","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"f1=S->one(S);\nf2=S->-S;\nhh=S-> sqrt(S+V0*one(S))\ng=S-> cosh((L1-L0)*hh(S))\nf=S-> inv(hh(S))*sinh((L1-L0)*hh(S))","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"Note that when defining an SPMF, all functions should be defined in a matrix function sense (not element-wise sence). Fortunately, in Julia, sinh(A) and cosh(A) for matrix A are interpreted as matrix functions. The NEP can now be created and solved by directly invoking the SPMF-creator and applying a NEP-solver:","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"using NonlinearEigenproblems\nnep=SPMF_NEP([Dn-Vn,In,G,F],[f1,f2,g,f]);\n(Œª1,v1)=quasinewton(Float64,nep,logger=1,Œª=-5,v=ones(n),tol=1e-9);\n(Œª2,v2)=quasinewton(nep,logger=1,Œª=-11,v=ones(n),tol=1e-9)\n(Œª3,v3)=quasinewton(nep,logger=1,Œª=-20,v=ones(n),tol=1e-9)\n(Œª4,v4)=quasinewton(nep,logger=1,Œª=-35,v=ones(n),tol=1e-9)","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"We can easily do a sanity check of the solution by visualizing it in this way","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"using Plots\nplot(xv,v1/norm(v1))\nplot!(xv,real(v2)/norm(v2))\nplot!(xv,real(v3)/norm(v3))\nplot!(xv,real(v4)/norm(v4))","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"resulting in","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"<br>\n<img src=\"https://user-images.githubusercontent.com/11163595/49675575-96ed0200-fa76-11e8-8341-b3faef1e800b.png\" height=450>","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"Rather than making several calls to a specific method, some NEP-solvers directly compute several solutions. The NEP-solver iar works quite well for this problem (see also the deflation approach to compute several solutions):","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"julia> (Œª,v)=iar(nep,logger=1,œÉ=-36,v=ones(n),tol=1e-9,neigs=5,maxit=100);\n-\n--\n---\n----\n-----\n------\n=------\n+-------\n+--------\n+---------\n+----------\n+-----------\n+=-----------\n++------------\n++-------------\n++--------------\n++---------------\n++----------------\n+++----------------\n++=-----------------\n++=------------------\n+++-------------------\n+++--------------------\n+++---------------------\n+++----------------------\n+++-----------------------\n+++------------------------\n+++-------------------------\n+++=-------------------------\n+++=--------------------------\n++++---------------------------\n++++----------------------------\n++++-----------------------------\n++++------------------------------\n++++-------------------------------\n++++--------------------------------\n++++=--------------------------------\n+++++---------------------------------\njulia> Œª\n5-element Array{Complex{Float64},1}:\n  -34.93072323018405 + 4.272712516424266e-18im\n  -39.14039540604307 + 2.054980381709175e-16im\n -31.057106551809486 - 3.2616991503097867e-15im\n  -43.66198303378091 - 4.3753274496659e-15im\n -27.537645678335437 + 4.8158177866759774e-15im","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"The output of the logging of iar is a compact notation for how many eigenvalues have converged at a specific iteration. Every line corresponds to one iteration step. The signs corresponds to: +=a converged eigenvalue, -=not converged eigenvalue, ==almost converged eigenvalue in the sense that it almost (up to a factor 10) satisfies the convergence criteria.","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"tip: Tip\nThe performance of many NEP-algorithms for this problem can be improved. One improvement is achieved with a simple variable transformation. If we let mu=sqrtlambda+V_0 we have lambda=mu^2-V_0. Therefore the NEP can be transformed in a way that it does not contain square roots. Square roots are undesirable, since they can limit convergence in many methods due to the fact that they are not entire functions. The sinh and cosh can be merged to a tanh-expression, leading to less nonlinear terms (but possibly more difficult singularities).","category":"page"},{"location":"movebc_tutorial/#Verifying-the-solution-1","page":"Tutorial 1 (ABC)","title":"Verifying the solution","text":"","category":"section"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"Let us verify the solution with a direct discretization of the domain. The ApproxFun.jl package provides tools to solve differential equations in one dimension. We use this package to discretize the entire domain 0L_1, whereas only a discretization of 0L_0 is necessary in the NEP-approach.","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"The eigenvalues of the operator can be computed as follows (where we approximate the singular point of the potential with a regularized heaviside function).","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"julia> using LinearAlgebra, ApproxFun;\njulia> x = Fun(0 .. 8)\njulia> V0 = 10;\njulia> Œ± = 25*pi/2;\njulia> # Let Ha be an approximation of H(x-1) where H is a Heaviside function\njulia> kk=10; Ha = 1 ./(1+exp(-2*kk*(x .- 1.0)));\njulia> VV=V0*Ha + (1-Ha) * sin(Œ±*x)\njulia> L = ùíü^2-VV\njulia> S = space(x)\njulia> B = Dirichlet(S)\njulia> ee= eigvals(B, L, 500,tolerance=1E-10);","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"We obtain approximations of the same eigenvalues as with the NEP-approach","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"julia> ee[sortperm(abs.(ee.+36))[1:5]]\n -34.85722089717211\n -39.051578662445074\n -30.984470654329677\n -43.54933251507695\n -27.450712883781343","category":"page"},{"location":"movebc_tutorial/#","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"(Image: To the top)","category":"page"},{"location":"deflate_tutorial/#Tutorial:-Computing-several-solutions-with-deflation-1","page":"Tutorial 4 (Deflation)","title":"Tutorial: Computing several solutions with deflation","text":"","category":"section"},{"location":"deflate_tutorial/#Background-1","page":"Tutorial 4 (Deflation)","title":"Background","text":"","category":"section"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"Several algorithms for NEPs compute one solution to the NEP given a starting value. In many applications several solutions are of interest. Let us first consider the trivial partial \"work-around\": You can try to run an algorithm which computes one eigenvalue twice with different starting values, e.g., quasinewton as in this example:","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"julia> nep=nep_gallery(\"dep0\");\njulia> (Œª1,_)=quasinewton(nep,Œª=0,v=ones(size(nep,1)))\n(-0.3587189459686377 + 0.0im, Complex{Float64}[4.41411+0.0im, -2.22171+0.0im, 4.31544+0.0im, -7.76501+0.0im, -9.51261+0.0im])\njulia> (Œª2,_)=quasinewton(nep,Œª=1im,v=ones(size(nep,1)))\n(-0.04093521177097875 + 1.4860115309416284im, Complex{Float64}[-3.28271+11.7399im, 5.08623-8.05479im, 7.16697-6.25547im, -2.69349+4.63954im, -9.91065+14.4678im])","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"This simple approach often suffers from the problem called reconvergence (we obtain the same solution again) or solutions of interest may be missed. In this case we get reconvergence when we use starting value -1:","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"julia> (Œª3,_)=quasinewton(nep,Œª=-1,v=ones(size(nep,1)))\n(-0.358718945968621 + 0.0im, Complex{Float64}[-6.65881+0.0im, 3.35151+0.0im, -6.50997+0.0im, 11.7137+0.0im, 14.3501+0.0im])","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"Note that applying the algorithm with starting values Œª=0 and Œª=-1 lead to the same solution. Other solution methods do not suffer from this, e.g., block Newton method, the infinite Arnoldi method and nleigs since they compute several solutions at once. Another attempt to remedy reconvergence is to use the technique called deflation. See also the manual page on deflation.","category":"page"},{"location":"deflate_tutorial/#Deflation-in-NEP-PACK-1","page":"Tutorial 4 (Deflation)","title":"Deflation in NEP-PACK","text":"","category":"section"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"The term deflation is referring to making something smaller (in the sense of opposite of inflating a balloon). In this case we can make the solution set smaller. We compute a solution and subsequently construct a deflated problem, which has the same solutions as the original problem except of the solution we have already computed.","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"A general solver independent deflation technique is available in NEP-PACK based on increasing the problem size. (There are also NEP-solver deflation techniques incoprorated in, e.g., in the nonlinear Arnoldi method and the Jacobi-Davidson method.) The solver independent technique is inspired by what is described in the PhD thesis of Cedric Effenberger. It is implemented in the method effenberger_deflation.","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"In NEP-PACK, this type of deflation is implemented in the function deflate_eigpair, which takes a NEP and an eigenpair as input and returns a new NEP.","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"julia> # first compute a solution\njulia> (Œª1,v1)=quasinewton(nep,Œª=0,v=ones(size(nep,1)))\njulia> # Construct a deflated NEP where we remove (Œª1,v1)\njulia> dnep=deflate_eigpair(nep,Œª1,v1)\njulia> # The dnep is a new NEP but with dimension increased by one\njulia> size(nep)\n(5, 5)\njulia> size(dnep)\n(6, 6)","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"We now illustrate that we can avoid reconvergence:","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"julia> (Œª4,v4)=quasinewton(dnep,Œª=-1,v=ones(size(dnep,1)),maxit=1000)\n(0.8347353572199264 + 0.0im, Complex{Float64}[10.6614+0.0im, 0.351814+0.0im, -0.940539+0.0im, 1.10798+0.0im, 3.53392+0.0im, -0.447213+0.0im])","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"Note: In contrast to the initial example, starting value Œª=-1 does not lead to converge to the eigenvalue we obtained from starting value Œª=0.","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"The computed solution is indeed a solution to the original NEP since M(Œª4) is singular:","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"julia> minimum(svdvals(compute_Mder(nep,Œª4)))\n1.2941045763733582e-14","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"In fact, you can even start with the first starting value Œª=0, and get a new solution","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"julia> quasinewton(dnep,Œª=0,v=ones(size(dnep,1)),maxit=1000)\n(0.8347353572199577 + 0.0im, Complex{Float64}[9.28596+0.0im, 0.306425+0.0im, -0.819196+0.0im, 0.965031+0.0im, 3.07799+0.0im, -0.389516+0.0im])","category":"page"},{"location":"deflate_tutorial/#Repeated-deflation-1","page":"Tutorial 4 (Deflation)","title":"Repeated deflation","text":"","category":"section"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"The above procedure can be repeated by calling deflate_eigpair on the deflated NEP. This effectively deflates another eigenpair (but without creating a recursive deflated nep structure).","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"function multiple_deflation(nep,Œª0,p)\n   n=size(nep,1);\n   dnep=nep;\n   for k=1:p\n      # Compute one solution of the deflated problem\n      (Œª2,v2)=quasinewton(dnep,Œª=Œª0,v=ones(size(dnep,1)),maxit=1000);\n      # expand the invariant pair\n      dnep=deflate_eigpair(dnep,Œª2,v2)\n   end\n   return get_deflated_eigpairs(dnep);\n\nend","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"We can now compute several solutions by calling multiple_deflation. Note that we use the same starting eigenvalue for all eigenvalues: 0.5im. It has to be complex in this case, since if it was real, we would not find complex solution and this problem only has two real eigenvalues.","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"julia> nep=nep_gallery(\"dep0\");\njulia> (Œõ,VV)=multiple_deflation(nep,0.5im,3)\n(Complex{Float64}[-0.358719+1.33901e-14im, 0.834735+7.05729e-15im, -0.0409352+1.48601im], Complex{Float64}[-0.0148325-0.316707im -0.670282+0.268543im -0.41261+0.229832im; 0.00746549+0.159405im -0.0881321+0.0353094im 0.360381-0.0796982im; ‚Ä¶ ; 0.0260924+0.557131im -0.298976+0.119782im -0.201138+0.0524051im; 0.0319648+0.68252im -0.528234+0.211633im -0.668441+0.121828im])","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"The values in Œõ and VV are eigenpairs:","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"julia> norm(compute_Mlincomb(nep,Œõ[1],VV[:,1]))\n2.0521012310648373e-13\njulia> norm(compute_Mlincomb(nep,Œõ[2],VV[:,2]))\n2.8707903010898464e-13\njulia> norm(compute_Mlincomb(nep,Œõ[3],VV[:,3]))\n1.883394132275381e-13","category":"page"},{"location":"deflate_tutorial/#","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"(Image: To the top)","category":"page"},{"location":"tutorial_call_python/#Tutorial:-Solving-NEP-defined-in-Python-1","page":"Tutorial 5 (Python)","title":"Tutorial: Solving NEP defined in Python","text":"","category":"section"},{"location":"tutorial_call_python/#A-problem-defined-in-Python-1","page":"Tutorial 5 (Python)","title":"A problem defined in Python","text":"","category":"section"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"Julia is a great programming language, but your problem may not be easy to define in Julia code, e.g., for legacy reasons. Don't let that prevent you from using the package. We now show how a problem defined in Python can be solved with NEP-PACK.","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"One of the advantages of the Julia language is that it is reasonably easy to interface with code written in other languages. In this tutorial we work with Python, and the two following tutorials we interface MATLAB and fortran.","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"note: Note\nTo work with NEPs defined in Python you need to have Python installed on your computer. With the pakcage PyCall it is possible to let Julia control execution of Python code.","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"The following python code correspond to the NEP","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"M(Œª)=beginbmatrix12newline34endbmatrix+\nŒªbeginbmatrix00newline01endbmatrix+\ne^Œªbeginbmatrix11newline11endbmatrix","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"The code has two functions: one that can compute an evaluation of M(Œª) and one that can form a linear combination of derivatives","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"  sum_i=1^kM^(k)(Œª)x_i","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"Put a file  mynep.py  in your current directory with the following contents:","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"import numpy as np;\nimport cmath as m;\ndef compute_M(s):\n    \"\"\"Compute the matrix M(s) for a given eigenvalue approximation\"\"\"\n    A=np.matrix('1 2; 3 4');  B=np.matrix('0 0; 0 1');   C=np.matrix('1 1; 1 1');\n    M=A+s*B+m.exp(s)*C\n    return M\n\ndef compute_Mlincomb(s,X):\n    \"\"\"Compute the linear combination of derivatives for value s\"\"\"\n    A=np.matrix('1 2; 3 4');  B=np.matrix('0 0; 0 1');   C=np.matrix('1 1; 1 1');\n\n    X=np.matrix(X) # Explicitly convert to matrix\n    z=np.zeros((2,1));\n    # Zeroth derivative\n    z=z+A*X[:,0]\n    z=z+B*(s*X[:,0])\n    z=z+C*(m.exp(s)*X[:,0])\n\n    # First derivative\n    if (np.size(X,1)>1):\n        z=z+B*(X[:,1])+C*(m.exp(s)*X[:,1])\n    # Higher derivatives\n    if (np.size(X,1)>1):\n        for k in range(2,np.size(X,1)):\n            z=z+C*(m.exp(s)*X[:,k])\n    return z","category":"page"},{"location":"tutorial_call_python/#Interfacing-Python-code-1","page":"Tutorial 5 (Python)","title":"Interfacing Python code","text":"","category":"section"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"We first initiate PyCall as follows. Note that the pushfirst! command is needed, otherwise the module defined in the file mynep.py we gave above will not be found. (PyCall does not include the current directory in the module search path by default.)","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"using PyCall;\npushfirst!(PyVector(pyimport(\"sys\").\"path\"), \"\");\nmynep = pyimport(\"mynep\")","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"This gives us direct access to the compute_M and compute_Mlincomb functions from python, e.g., if we want to evaluate M(3+3i) we run this code","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"julia> mynep.compute_M(3+3im)\n2√ó2 Array{Complex{Float64},2}:\n -18.8845+2.83447im  -17.8845+2.83447im\n -16.8845+2.83447im  -12.8845+5.83447im","category":"page"},{"location":"tutorial_call_python/#Implementation-in-NEP-PACK-(using-Mder_Mlincomb_NEP)-1","page":"Tutorial 5 (Python)","title":"Implementation in NEP-PACK (using Mder_Mlincomb_NEP)","text":"","category":"section"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"We can now use the Python interface to define a NEP in Julia. The type Mder_Mlincomb_NEP is a special type made for this situation. The required inputs are the size, called n; a function to compute M(Œª), called fder; and a function to compute sum_i=1^kM^(k)(Œª)x_i, called flincomb. The extra 0 passed in the definition defines that M(Œª) is available, but no higher derivatives.","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"using NonlinearEigenproblems\nn=2;\nfder = (Œª,der) -> mynep.compute_M(complex(Œª));\nflincomb =  (Œª,X) -> mynep.compute_Mlincomb(complex(Œª),complex(reshape(X,size(X,1),size(X,2))));\nnep=Mder_Mlincomb_NEP(n,fder,0,flincomb);","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"We can compare the Python call with the NEP-PACK call","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"julia> compute_Mder(nep,3+3im)\n2√ó2 Array{Complex{Float64},2}:\n -18.8845+2.83447im  -17.8845+2.83447im\n -16.8845+2.83447im  -12.8845+5.83447im","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"We continue by computing some eigenvalues of the the NEP using the Infinite Arnoldi method (iar).","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"julia> (Œª,v)=iar(nep,v=[1;1],œÉ=1,logger=0,neigs=3);\njulia> Œª\n3-element Array{Complex{Float64},1}:\n  0.6748316143423988 + 7.336803319821954e-19im\n 0.11742590291190791 - 3.649946317867008im    \n 0.11742590291191168 + 3.6499463178670144im  ","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"We can verify that we actually computed solutions as follows:","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"julia> norm(compute_Mlincomb(nep,Œª[1],v[:,1]))\n1.106424240899132e-15","category":"page"},{"location":"tutorial_call_python/#Implementation-in-NEP-PACK-(using-new-type)-1","page":"Tutorial 5 (Python)","title":"Implementation in NEP-PACK  (using new type)","text":"","category":"section"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"The previous implementation utilizes the convenience type Mder_Mlincomb_NEP, and solves the problem in a satisfactory way. Nevertheless, to illustrate more of the inner workings of NEP-PACK we solve the problem in a second way, by defining our own type. The first thing we need to do is to define the size-function, which is hard-coded in this example.","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"import NonlinearEigenproblems.size # We will overload these functions\nimport NonlinearEigenproblems.compute_Mlincomb;\nimport NonlinearEigenproblems.compute_Mder;\nstruct PyNEP <: NEP # Set up a dummy type for our specific NEP\nend\nsize(::PyNEP) = (2,2) # Trivial function definitions\nsize(::PyNEP,::Int) = 2","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"As explained in NEPTypes, a NEP is defined by its compute functions. Here is how you define two compute functions that call our python-defined NEP:","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"function compute_Mder(::PyNEP,s::Number,der::Integer=0)\n    if (der>0)\n        error(\"Higher derivatives not implemented\");\n    end\n    return mynep.compute_M(complex(s)); # Call python\nend\nfunction compute_Mlincomb(::PyNEP,s::Number,X::AbstractVecOrMat)\n    XX=complex(reshape(X,size(X,1),size(X,2))) # Turn into a matrix\n    return mynep.compute_Mlincomb(complex(s),XX); # Call python\nend","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"We now create an object of our newly created type and we can access the NEP with the NEP-PACK specific compute functions:","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"julia> pynep=PyNEP();\njulia> compute_Mder(pynep,3+3im)\n2√ó2 Array{Complex{Float64},2}:\n -18.8845+2.83447im  -17.8845+2.83447im\n -16.8845+2.83447im  -12.8845+5.83447im","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"The behavior is the same as above. Since a NEP-object is defined by its compute functions, we can now use many NEP-solvers to solve this problem. We again use iar:","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"julia> (Œª2,v2)=iar(pynep,v=[1;1],œÉ=1,logger=0,neigs=3);\njulia> Œª2\n3-element Array{Complex{Float64},1}:\n  0.6748316143423988 + 7.336803319821954e-19im\n 0.11742590291190791 - 3.649946317867008im    \n 0.11742590291191168 + 3.6499463178670144im   ","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"We can compare with the eigenvalues computed above and, again, verify that we actually computed solutions as follows:","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"julia> norm(compute_Mlincomb(pynep,Œª2[1],v2[:,1]))\n1.106424240899132e-15","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"Residual is almost zero, so we have a solution.","category":"page"},{"location":"tutorial_call_python/#","page":"Tutorial 5 (Python)","title":"Tutorial 5 (Python)","text":"(Image: To the top)","category":"page"},{"location":"development/#Developer-info-1","page":"Developer info","title":"Developer info","text":"","category":"section"},{"location":"development/#Compiling-the-documentation-1","page":"Developer info","title":"Compiling the documentation","text":"","category":"section"},{"location":"development/#","page":"Developer info","title":"Developer info","text":"Compile this documentation page by running:","category":"page"},{"location":"development/#","page":"Developer info","title":"Developer info","text":"jarl@bjork:~/src/NonlinearEigenproblems.jl/docs$ julia --color=yes make.jl &&  mkdocs build --clean\njarl@bjork:~/src/NonlinearEigenproblems.jl/docs$ firefox site/index.html","category":"page"},{"location":"development/#","page":"Developer info","title":"Developer info","text":"If you want this to appear on our documentation page https://nep-pack.github.io/NonlinearEigenproblems.jl/ you need to push it to the gh-branch, e.g.,  by running","category":"page"},{"location":"development/#","page":"Developer info","title":"Developer info","text":"jarl@bjork:~/src/NonlinearEigenproblems.jl/docs$ export DOCSDIR=`pwd`\njarl@bjork:~/src/NonlinearEigenproblems.jl/docs$ cd /tmp\njarl@bjork:/tmp$ git clone -b \"gh-pages\" git@github.com:nep-pack/NonlinearEigenproblems.jl.git\njarl@bjork:/tmp$ cd NonlinearEigenproblems.jl\njarl@bjork:/tmp/NonlinearEigenproblems.jl$ cp -r $DOCSDIR/site/* .\njarl@bjork:/tmp/NonlinearEigenproblems.jl$ git add *;  git commit . -m \"refresh docs\"; git push","category":"page"},{"location":"development/#","page":"Developer info","title":"Developer info","text":"More information about Documenter.jl: here","category":"page"},{"location":"tutorial_contour/#Contour-integral-tutorial-1","page":"Tutorial 2 (Contour)","title":"Contour integral tutorial","text":"","category":"section"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"NEP-PACK contains several implementations of methods in the family of approaches based on contour integration. Although they have been worked out and presented independently (in different research articles by different research groups), we have implemented them in a unified and extendible way.","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"Contour integral methods have one property which makes them attractive from the perspective of parallelization, which we will illustrate in the final example below.","category":"page"},{"location":"tutorial_contour/#Basic-usage-1","page":"Tutorial 2 (Contour)","title":"Basic usage","text":"","category":"section"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"The most popular methods contour integral methods are Beyn's contour integral method and the block SS method of Asakura and Sakurai. We illustrate both of them. First set up a large and sparse problem:","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> using SparseArrays, LinearAlgebra;\njulia> n=1000;\njulia> A0=spdiagm(0 => ones(n))\njulia> A1=spdiagm(-2 => ones(n-2), 0 => 30*(n:-1:1)/n,  1 => 3*ones(n-1))/3\njulia> A2=spdiagm(-1 => ones(n-1), 0 => (1:n)/n, 1 => sin.(range(0,5,length=n-1)))/10\njulia> nep=SPMF_NEP([A0,A1,A2],[s->one(s), s->s, s->exp(-s)])","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"and call the two integral solution methods:","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> (Œª,v)= contour_beyn(nep,radius=0.5,k=10);","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"We can verify that we found some good solutions","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> Œª\n2-element Array{Complex{Float64},1}:\n -0.4938003805961036 + 0.03369433628038132im\n -0.4984653501095431 - 0.013414744968396205im\njulia> norm(compute_Mlincomb(nep,Œª[1],normalize(v[:,1])))\n2.8693125572899838e-6\njulia> norm(compute_Mlincomb(nep,Œª[2],normalize(v[:,2])))\n3.0028543096707394e-6","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"For comparison we also use contour_block_SS","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> (Œª,v)= contour_block_SS(nep,radius=0.5,k=10);\njulia> julia> Œª\n7-element Array{Complex{Float64},1}:\n -0.49789562317811836 + 0.029382625854591973im\n  -0.5020899933123398 - 0.027308288264250524im\n  -0.5006296180796399 + 0.011976675667372098im\n  -0.5000287784310599 - 0.010301420892154335im\n  -0.5044451294089868 - 0.0074606034247795975im\n  -0.5001550771105308 - 0.00026147429323077303im\n -0.49957316937095864 + 0.003511006328045692im","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"and the corresponding residual norms","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> for j=1:7; @show norm(compute_Mlincomb(nep,Œª[j],normalize(v[:,j]))); end\nnorm(compute_Mlincomb(nep, Œª[j], normalize(v[:, j]))) = 2.8693125572899838e-6\nnorm(compute_Mlincomb(nep, Œª[j], normalize(v[:, j]))) = 3.0028543096707394e-6\nnorm(compute_Mlincomb(nep, Œª[j], normalize(v[:, j]))) = 1.1514402700870265e-7\nnorm(compute_Mlincomb(nep, Œª[j], normalize(v[:, j]))) = 4.123810796391466e-8\nnorm(compute_Mlincomb(nep, Œª[j], normalize(v[:, j]))) = 6.261761794674978e-8\nnorm(compute_Mlincomb(nep, Œª[j], normalize(v[:, j]))) = 1.7269388863226059e-9\nnorm(compute_Mlincomb(nep, Œª[j], normalize(v[:, j]))) = 2.994085882385125e-9","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"The functions contour_beyn and contour_block_SS have compatible keyword argumengs. The kwarg radius=0.5, means that we numerically integrate  a circle of radius 0.5. The center of the circle is given by the œÉ, argument and by default œÉ=0. We should expect the method to find eigenvalues (hopefully all eigenvalues) within that disk. Our implementation also supports ellipses, by specifying radius as a length two vector with the two radii of the ellipse. The value k=10 specifies how many columns the rectangular probe matrix has. In general, we do not obtain more k eigenvalues.","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"It seems that in this case contour_block_SS is better since it finds eigenvalues  which contour_beyn misses. However, a closer look reveals that the additional eigenvalues are outside the requested disc, and the call to  contour_block_SS also requires more computation time, making the comparison unfair.","category":"page"},{"location":"tutorial_contour/#Your-own-quadrature-method-1","page":"Tutorial 2 (Contour)","title":"Your own quadrature method","text":"","category":"section"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"The contour integral methods are based on numerical quadrature. There are many different ways to carry out quadrature, and NEP-PACK provides a way to use user-defined quadrature methods. The default behaviour is to use the trapezoidal rule. When we parameterize a circle (or ellipse) with a phase, the integrand is periodic and the trapezoidal rule works particularly well. It is however not the only option for quadrature and we can for instance implement a gauss quadrature, in this case by using the functionality in the package QuadGK:","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> using Pkg\njulia> Pkg.add(\"QuadGK\");\njulia> using QuadGK","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"The function (x,w)=gauss(N) provides weights and quadrature points for a function to be integrated over the interval [-1,1] with N quadrature points.","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"Before implementing the method, let us first have a look at the documtation of MatrixIntegrator:","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"MatrixIntegrator","category":"page"},{"location":"tutorial_contour/#NonlinearEigenproblems.NEPSolver.MatrixIntegrator","page":"Tutorial 2 (Contour)","title":"NonlinearEigenproblems.NEPSolver.MatrixIntegrator","text":"abstract type MatrixIntegrator\n\nThis type is used for integration of (matrix valued) functions with a particular structure. It is used in contour_beyn and contour_block_SS.\n\nIn order to specify your own way to do numerical quadrature you should inherit from this type\n\njulia> abstract type MyIntegrator <: MatrixIntegrator; end\n\nand implement the method integrate_interval:\n\njulia> import NonlinearEigenproblems.NEPSolver.integrate_interval\njulia> function integrate_interval(ST::Type{MyType},::Type{T},f,gv,a,b,N,logger) where {T<:Number}\n\nThe function integrate_interval should integrate functions on the interval [a,b] with N quadrature points. Further parameters:\n\nThe type T (typically ComplexF64) specifies what the target number type is.\nThe logger::Logger specifies if / how things should written to the log.\nf::Function, takes a scalar input (in the interval [a,b]) and returns a matrix or a vector.\ngv::Vector{Function} which takes scalar input (in the interval [a,b])  and returns scalars.\n\nThe function integrate_interval should return a tensor I where the last dimension is m=length(gv) and should contain the integrals. More precisely,  I[:,:,1], ... I[:,:,m] should contain approximations of the product of f(x)gv[1](x),...f(x)gv[m](x) over [a,b], e.g., I[:,:,j] should contain an approximation of\n\nint_a^b f(x)g_j(x)dx\n\nUsually, f(x) is considerably more expensive to evaluate than g_1(x),..,g_m(x).\n\nSee also: contour_beyn, contour_block_SS, MatrixTrapezoidal\n\n\n\n\n\n","category":"type"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"Let us now combine the Gauss method in an implementation of a numerical quadrature to be used in the quadrature methods.","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> abstract type GaussIntegrator <: MatrixIntegrator; end\njulia> import  NonlinearEigenproblems.NEPSolver.integrate_interval\njulia> function integrate_interval(ST::Type{GaussIntegrator},::Type{T},f,gv,a,b,N,logger) where {T<:Number}\n    x,w=gauss(N);        # Compute the Gauss weights\n    w=w*(b-a)/2;         # Rescale w to interval [a,b]\n    t=a .+ ((x .+ 1)/2)*(b-a); # Rescale t\n    m=size(gv,1);\n    # create the tensor and compute all quadratures\n    S = zeros(T,size(f(t[1]))...,m)\n    for i = 1:N\n        ## Extra code goes here\n        temp = f(t[i]) # Only computed once for all g-functions\n        for j=1:m\n            S[:,:,j] += temp*(gv[j](t[i])*w[i]);\n        end\n    end\n    return S\nend","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"To specify this solver, you need to add the type you just created as a parameter in the call. This is an argument (not a keyword argument) after the argument nep:","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> (Œª,v)= contour_block_SS(nep,GaussIntegrator,radius=0.5, k=10);\njulia> Œª\n6-element Array{Complex{Float64},1}:\n  -0.5030050924478993 + 0.025867789190345332im\n  -0.4998917126923037 - 0.014647029189145597im\n -0.49991828738335686 - 0.007092586236661307im\n  -0.5000067107140442 - 0.0026614262456865663im\n -0.49903549969757116 + 0.0075397370638041255im\n   -0.501620024772268 + 0.00393810326235837im","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"Let's make it print some pretty decoration during the progress of the method. In the code where it currently says ## Extra code goes here we will now insert","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"if (mod(i,round(N/50))==1)\n   print(\".\")\nend","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"In this way, we will print a progress bar, which prints in total (approximately) 50 dots. You will see dots gradually appearing as a progress bar:","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> (Œª,v)= contour_beyn(nep,GaussIntegrator,radius=0.5,k=10);\n..................................................","category":"page"},{"location":"tutorial_contour/#Parallellized-quadrature-method-1","page":"Tutorial 2 (Contour)","title":"Parallellized quadrature method","text":"","category":"section"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"The main computational effort of the contour integral methods lies in solving many linear systems. This is done in the call to f in the integrate_interval-function. Since they are completely independent operations in the for-loop, they can be easily parallelized.","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"Install the package Distributed and BenchmarkTools and include with","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> using Distributed,BenchmarkTools","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"Similar to the previous example we make a new type corresponding to our integrator and explicitly import that","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> abstract type ParallelIntegrator <: MatrixIntegrator; end\njulia> import  NonlinearEigenproblems.NEPSolver.integrate_interval","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"and define a function which computes the main for-loop in parallel using the @distributed macro:","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> function integrate_interval(ST::Type{ParallelIntegrator},::Type{T},f,gv,a,b,N,logger) where {T<:Number}\n    h = (b-a)/N\n    t = range(a, stop = b-h, length = N)\n    m = size(gv,1);\n    S = @distributed (+) for i = 1:N\n        temp = f(t[i])\n        Z=zeros(T,size(temp,1),size(temp,2),m);\n        for j=1:m\n            Z[:,:,j]=temp*gv[j](t[i]);\n        end\n        Z\n    end\n    return S\nend","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"To use the parallelization you may need to start julia with command-line arguments to specify the number of parallel processes to be used, e.g., -p 4. The @btime macro provides a way to measure how much faster the parallel implementation is.","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> @btime (Œª,v)= contour_block_SS(nep,ParallelIntegrator,radius=0.5, k=10);\n  863.420 ms (1385 allocations: 10.46 MiB)\njulia> @btime (Œª,v)= contour_block_SS(nep,radius=0.5, k=10);\n  2.990 s (321362 allocations: 5.84 GiB)","category":"page"},{"location":"tutorial_contour/#","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"This is a speed up of 3.4, with p=4 processes.","category":"page"},{"location":"bemtutorial/#Tutorial:-User-defined-matrices-boundary-element-method-1","page":"Tutorial 3 (BEM)","title":"Tutorial: User-defined matrices - boundary element method","text":"","category":"section"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"Suppose you have a new type of NEP, which does not naturally fit into the standard types in NEP-PACK. This tutorial shows how you can define a NEP where the only way to access the NEP is a function to compute M^(k)(Œª). We first show the manual way to do it, as it illustrates some of the workings of NEP-PACK. However, the use case is common enough to have native support in NEP-PACK. Hence, we also show how to use a special NEP-type called Mder_NEP.","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"For this example we use a boundary element method approach for computation of resonances. The complete code is available in gallery_extra/bem_hardcoded. The example is also available as a gallery problem: nep=nep_gallery(\"bem_fichera\").","category":"page"},{"location":"bemtutorial/#Boundary-element-method-1","page":"Tutorial 3 (BEM)","title":"Boundary element method","text":"","category":"section"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"The boundary element method applied to Helmholtz eigenvalue problem can be described by the matrix consisting of elements","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"M(Œª)_ij=frac14piint_Delta_iint_Delta_jfrace^iotalambdaxi-etaxi-etadS(eta)dS(xi)","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"where Delta_i, i=1ldotsn are boundary elements. The boundary element approach is available through three functions: gen_ficheramesh to compute the mesh, precompute_quad! to precompute the quadrature coeeficients, and assemble_BEM to compute the matrix consisting of all the integrals corresponding to Œª. These functions are based on the model (and inspired by some of the code) in \"A boundary element method for solving PDE eigenvalue problems\", Steinlechner, bachelor thesis, ETH Z√ºrich, 2010 and also used in the simulations in \"Chebyshev interpolation for nonlinear eigenvalue problems\", Effenberger, Kressner, BIT Numerical Mathematics, 2012, Volume 52, Issue 4, pp 933‚Äì951.","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"To get access to the helper functions you need either to work in the gallery_extra/bem_hardcoded-directory, or copy the files in there to your current working directory. The code can also be found directly on github. We start by loading the necessary code:","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> using NonlinearEigenproblems;\njulia> include(\"triangle.jl\");\njulia> include(\"genmesh.jl\");\njulia> include(\"assemble_BEM.jl\");","category":"page"},{"location":"bemtutorial/#Manual-implementation-in-NEP-PACK-1","page":"Tutorial 3 (BEM)","title":"Manual implementation in NEP-PACK","text":"","category":"section"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"In order to define your new NEP you need to define a new NEP-type","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> struct BEM_NEP <: NEP\n    mesh::Vector{Triangle}\n    n::Int\n    gauss_order::Int\n    function BEM_NEP(mesh,gauss_order)\n        return new(mesh,length(mesh),gauss_order)\n    end\nend","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"The mesh variable is a vector of triangle objects defining the domain, n is the size of the mesh and gauss_order the quadrature order. All NEPs have to define size() functions","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> import Base.size; # Import from Base explicitly since we overload\n\njulia> function size(nep::BEM_NEP)\n    return (nep.n,nep.n);\nend\nsize (generic function with 142 methods)\njulia> function size(nep::BEM_NEP,dim)\n    return nep.n;\nend\nsize (generic function with 143 methods)","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"The function assemble_BEM computes the matrix defined by the integrals. Hence, we need to call this function for every call to compute_Mder:","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> import NonlinearEigenproblems.NEPCore.compute_Mder # We overload the function\njulia> function compute_Mder(nep::BEM_NEP,Œª::Number,der::Int=0)\n    return assemble_BEM(Œª, nep.mesh, nep.gauss_order, der)[:,:,1];\nend\ncompute_Mder (generic function with 42 methods)","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"In order to make other compute functions available to the methods, we can use the conversion functions. In particular, the compute_Mlincomb function can be implemented by making several calls in compute_Mder. This is done in the NEP-PACK-provided helper function compute_Mlincomb_from_Mder. We make this the default behaviour for this NEP:","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> import NonlinearEigenproblems.NEPCore.compute_Mlincomb # Since we overload\n# Delegate the compute Mlincomb functions. This can be quite inefficient.\njulia> compute_Mlincomb(nep::BEM_NEP,Œª::Number,V::AbstractVecOrMat, a::Vector) =\n      compute_Mlincomb_from_Mder(nep,Œª,V,a)\ncompute_Mlincomb (generic function with 36 methods)\njulia> compute_Mlincomb(nep::BEM_NEP,Œª::Number,V::AbstractVecOrMat) =\n      compute_Mlincomb(nep,Œª,V, ones(eltype(V),size(V,2)))\ncompute_Mlincomb (generic function with 37 methods)","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"We can now create a BEM_NEP as follows:","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> gauss_order=3; N=5;\njulia> mymesh=gen_ficheramesh(N);\njulia> precompute_quad!(mymesh,gauss_order);\njulia> nep=BEM_NEP(mymesh,gauss_order);","category":"page"},{"location":"bemtutorial/#Solving-the-NEP-1","page":"Tutorial 3 (BEM)","title":"Solving the NEP","text":"","category":"section"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"After creating the NEP, you can try to solve the problem with methods in the package, e.g., mslp works quite well for this problem:","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> (Œª,v)=mslp(nep,Œª=8,logger=1);\niter 1 err:4.122635537095191e-6 Œª=8.128272919317748 + 0.007584851218213724im\niter 2 err:1.787963303966838e-8 Œª=8.132181234599429 - 1.952792817333862e-5im\niter 3 err:3.2884911876526185e-13 Œª=8.132145310156645 - 1.2648247030082216e-5im\niter 4 err:4.417989064002117e-18 Œª=8.132145310195458 - 1.264891803723658e-5im","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"This is the computed solution:","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"<br>\n<img src=\"https://user-images.githubusercontent.com/11163595/49595409-324b7d80-f978-11e8-818d-eeeaf9441505.png\" height=450>","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"The plotting was done with the following code (by using internals of the BEM-implementation):","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> using PyPlot\njulia> v=v./maximum(abs.(v));\njulia> for k=1:size(nep.mesh,1);\n    tri=nep.mesh[k];\n    col=[1-abs.(v)[k];0;0]; # plot abslolute value\n    X=[tri.P1[1] tri.P2[1]; tri.P3[1] tri.P3[1]];\n    Y=[tri.P1[2] tri.P2[2]; tri.P3[2] tri.P3[2]];\n    Z=[tri.P1[3] tri.P2[3]; tri.P3[3] tri.P3[3]];\n    plot_surface(X,Y,Z,color=col,alpha=0.8);\n    plot_wireframe(X,Y,Z,color=[0;0;0],linewidth=1,alpha=0.5,);\nend","category":"page"},{"location":"bemtutorial/#Implementation-in-NEP-PACK-using-the-Mder_NEP-type-1","page":"Tutorial 3 (BEM)","title":"Implementation in NEP-PACK using the Mder_NEP type","text":"","category":"section"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"Some of the manual implementation can be avoided by using the Mder_NEP type. We only need to pass the size of the NEP and a function to compute M^(k)(Œª), i.e., (Œªf,derf) -> assemble_BEM(Œªf, mymesh, gauss_order, derf)[:,:,1], to the Mder_NEP.","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> n = length(mymesh);\njulia> mdernep = Mder_NEP(n, (Œªf,derf) -> assemble_BEM(Œªf, mymesh, gauss_order, derf)[:,:,1]);\njulia> (mderŒª,mderv)=mslp(mdernep,Œª=8,logger=1);\niter 1 err:4.122635537095191e-6 Œª=8.128272919317748 + 0.007584851218213724im\niter 2 err:1.787963303966838e-8 Œª=8.132181234599429 - 1.952792817333862e-5im\niter 3 err:3.2884911876526185e-13 Œª=8.132145310156645 - 1.2648247030082216e-5im\niter 4 err:4.417989064002117e-18 Œª=8.132145310195458 - 1.264891803723658e-5im\njulia> Œª-mderŒª\n0.0 + 0.0im","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"note: Note\nThe above code executes under the assumption that the following code had been run:precompute_quad!(mymesh,gauss_order);","category":"page"},{"location":"bemtutorial/#","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"(Image: To the top)","category":"page"},{"location":"errmeasure/#Measuring-the-error-1","page":"Measuring the error","title":"Measuring the error","text":"","category":"section"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"All iterative algorithms need some form of termination criteria. In NEP-PACK, all NEP-solvers provide the possibility to specify the desired tolerance, as well as how the error is measured or estimated. The tolerance is specified in the kwarg  tol (which is a real number) and the way to measure the error is given in errmeasure.","category":"page"},{"location":"errmeasure/#Standard-usage-1","page":"Measuring the error","title":"Standard usage","text":"","category":"section"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"NEP-PACK comes with several ways to measure errors for many NEP-types.","category":"page"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"errmeasure=ResidualErrmeasure(nep): The error is estimated by the use of the residual norm:","category":"page"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"mathrmerr=fracM(Œª)vv","category":"page"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"errmeasure=BackwardErrmeasure(nep): The error is estimated by using the backward error bounds. This error measure will not work for all NEPs. An implementation is provided for any AbstractSPMF. If your NEP is an AbstractSPMF with terms:\nM(Œª)=A_1f_1(Œª)+cdots+A_mf_m(Œª)\nthe error will be estimated by\nmathrmerr=fracM(Œª)vvfrac1A_1_Ff_1(Œª)+cdots+A_m_Ff_m(Œª)\nIn other words, the BackwardErrmeasure is a weighting of the ResidualErrmeasure.\nerrmeasure=DefaultErrmeasure(nep): When this errmeasure is specified, NEP-PACK tries to determine a error measure for you. In general, BackwardErrmeasure will be preferred if possible. This behavior may change in future versions of NEP-PACK.\nerrmeasure=EigvalReferenceErrmeasure(nep,Œªref): This errmeasure is used when an exact (or very accurate) eigenvalue is already known. Typically, if you wish to visualize the eigenvalue error of a specific method, you run the method twice and use the result of the first run as to instantiate this error measure and get real eigenvalue errors as output.\nerrmeasure=(Œª,v)-> compute_error(Œª,v): A user defined error measure can be specified using a function. The function should be take an eigenpair as input, and return a real value. See ErrmeasureType for an example.","category":"page"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"Example: Most NEP-solvers take the errmeasure as an kwarg.","category":"page"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"julia> nep=nep_gallery(\"qdep0\");\njulia> # Solve the problem to residual norm 1e-8\njulia> (Œª,v)=mslp(nep,errmeasure=ResidualErrmeasure(nep),tol=1e-8)\njulia> norm(compute_Mlincomb(nep,Œª,v))/norm(v) # It's smaller than tol?\n3.503700819937386e-9\njulia> nep isa AbstractSPMF # Is it an AbstractSPMF so we can use BackwardErrmeasure?\ntrue\njulia> (Œª,v)=mslp(nep,errmeasure=BackwardErrmeasure(nep),tol=1e-10)\njulia> factor=abs(fv[1](Œª))*norm(Av[1])+\n     abs(fv[2](Œª))*norm(Av[2])+abs(fv[3](Œª))*norm(Av[3]);\njulia> norm(compute_Mlincomb(nep,Œª,v))/(norm(v)*factor)\n1.659169482386331e-11","category":"page"},{"location":"errmeasure/#User-defined-error-measure-1","page":"Measuring the error","title":"User defined error measure","text":"","category":"section"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"There are two ways that a user can specify how to measure the error.","category":"page"},{"location":"errmeasure/#User-defined-error-1:-Function-handle-1","page":"Measuring the error","title":"User defined error 1: Function handle","text":"","category":"section"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"The user can provide a function handle which is called to obtain the error. The errmeasure can be a function, which takes two parameters as input (Œª,v) and returns the error (or estimate thereof).","category":"page"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"The most common situation is that you want to report the error (as a function of iteration) with a reference solutions. If we want to get a very accurate approximation of the true error, we can run the algorithm twice, and the second time we run the algorithm we use the result of the first run as a reference.","category":"page"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"julia> nep=nep_gallery(\"qdep0\");\njulia> v0=ones(size(nep,1));\njulia> (Œªref,_)=resinv(nep,v=v0,Œª=-0.1,logger=1);\njulia> myerrmeasure = (Œª,v) -> abs(Œª-Œªref)/abs(Œª);\njulia> (Œª,v)=resinv(nep,v=v0,Œª=-0.1,logger=1,tol=1e-10,errmeasure=myerrmeasure);\nPrecomputing linsolver\niter 1 err:0.02854168838549373 Œª=-0.1 + 0.0im\niter 2 err:0.8397508140476416 Œª=-0.6418389474323298 + 0.0im\niter 3 err:0.17336372619725743 Œª=-0.08765753239354723 + 0.0im\niter 4 err:0.0005771170619943501 Œª=-0.1029135620110966 + 0.0im\niter 5 err:4.762006833879597e-7 Œª=-0.10285411985934721 + 0.0im\niter 6 err:4.074039107701665e-7 Œª=-0.10285421074175707 + 0.0im\niter 7 err:2.6448037288912206e-8 Œª=-0.10285417155884034 + 0.0im\niter 8 err:1.3926542408883378e-9 Œª=-0.10285416898178967 + 0.0im\niter 9 err:6.324560618281378e-11 Œª=-0.10285416884505445 + 0.0im","category":"page"},{"location":"errmeasure/#User-defined-error-2:-A-user-defined-type-1","page":"Measuring the error","title":"User defined error 2: A user defined type","text":"","category":"section"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"Due to the multiple dispatch and handling of types in Julia, code may run faster if one uses types instead of function handles. It is possible to do the same simulation as above with a user defined type.","category":"page"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"You first need to define a new type","category":"page"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"julia> struct RefErrmeasure <: Errmeasure; end","category":"page"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"The error measure should then provided in the function estimate_error which we now define as the relative eigenvalue error:","category":"page"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"julia> v0=ones(size(nep,1));\njulia> (Œªref,v)=resinv(nep,v=v0,Œª=230^2+1im,logger=0);\njulia> function NonlinearEigenproblems.estimate_error(e::RefErrmeasure,Œª,v)\n         return abs(Œª-Œªref)/abs(Œª);\n       end\njulia> (Œª,v)=resinv(nep,v=v0,Œª=250^2+1im,logger=1,tol=1e-10,errmeasure=RefErrmeasure());\niter 1 err:0.12740916184575013 Œª=62500.0 + 1.0im\niter 2 err:0.9535794095609479 Œª=1.175146205389422e6 + 6663.738915456258im\niter 3 err:2.4041334742321228 Œª=-38815.06145769358 + 1301.0064120392753im\n....\niter 50 err:7.608430406801785e-11 Œª=54550.13915567685 + 459.51715820395947im","category":"page"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"The printouts of the last call correspond to the relative eigenvalue error.","category":"page"},{"location":"errmeasure/#As-a-NEP-solver-developer-1","page":"Measuring the error","title":"As a NEP-solver developer","text":"","category":"section"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"NEP-solvers should use the Errmeasure as follows. The NEP-solver should take as input an object of the type Errmeasure  or function. The fact that it can be different types, is transparent and a NEP-solver developer does not have to do anything to take care of that if the following procedure is followed.","category":"page"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"Suppose your solver is defined in a function with this signature:","category":"page"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"function mysolver(nep::NEP;errmeasure::ErrmeasureType=DefaultErrmeasure(nep))","category":"page"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"In the main for loop you want to call the estimate_error function:","category":"page"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"for k=1:maxit\n    err=estimate_error(errmeasure,Œª,v)\n    if (err < 1e-10)\n       return (Œª,v)\n    end\n    ....\n\nend","category":"page"},{"location":"errmeasure/#Methods-and-types-1","page":"Measuring the error","title":"Methods and types","text":"","category":"section"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"Errmeasure","category":"page"},{"location":"errmeasure/#NonlinearEigenproblems.NEPTypes.Errmeasure","page":"Measuring the error","title":"NonlinearEigenproblems.NEPTypes.Errmeasure","text":"abstract type Errmeasure; end\n\nConcrete subtypes of Errmeasure represent specific ways of measuring the error of an eigenpair. NEP-solvers take such an object as input. As a NEP-solver user, you use the type as follows\n\njulia> quasinewton(nep,errmeasure=ResidualErrmeasure(nep))\n\nUser-specified ways of measuring error can be given by creating a new subtype of Errmeasure and using it as a errmeasure keyword. You need to specify the way to measure the error in the method estimate_error.\n\nNote that in practice a Function can essentially be used instead of a Errmeasure-object, which is a simple way to have user-defined error measures. See ErrmeasureType.\n\nSee also: ErrmeasureType, DefaultErrmeasure, ResidualErrmeasure, BackwardErrmeasure, estimate_error, EigvalReferenceErrmeasure.\n\n\n\n\n\n","category":"type"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"DefaultErrmeasure","category":"page"},{"location":"errmeasure/#NonlinearEigenproblems.NEPTypes.DefaultErrmeasure","page":"Measuring the error","title":"NonlinearEigenproblems.NEPTypes.DefaultErrmeasure","text":"struct DefaultErrmeasure <: Errmeasure\nfunction DefaultErrmeasure(nep::NEP)\n\nWhen you specify this Errmeasure, NEP-PACK tries to determine a suitable Errmeasure based on the type of the NEP. Note that this behavior may change in future versions.\n\nSee also: Errmeasure\n\n\n\n\n\n","category":"type"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"BackwardErrmeasure","category":"page"},{"location":"errmeasure/#NonlinearEigenproblems.NEPTypes.BackwardErrmeasure","page":"Measuring the error","title":"NonlinearEigenproblems.NEPTypes.BackwardErrmeasure","text":"struct BackwardErrmeasure <: Errmeasure\nfunction BackwardErrmeasure(nep::NEP)\n\nThis Errmeasure provides a way to compute the backward error. The backward error estimate are only given for NEPs which are subtypes of  AbstractSPMF. We use the Frobenius norm as the matrix norm, since it is much cheaper to compute than the spectral norm.\n\nExample\n\njulia> nep=nep_gallery(\"qdep0\");\njulia> (Œª,v)=quasinewton(nep,Œª=-1,errmeasure=BackwardErrmeasure(nep),tol=1e-10);\n\nSee also: Errmeasure\n\n\n\n\n\n","category":"type"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"ResidualErrmeasure","category":"page"},{"location":"errmeasure/#NonlinearEigenproblems.NEPTypes.ResidualErrmeasure","page":"Measuring the error","title":"NonlinearEigenproblems.NEPTypes.ResidualErrmeasure","text":"struct ResidualErrmeasure <: Errmeasure\nfunction ResidualErrmeasure(nep::NEP)\n\nThis Errmeasure species that the residual norm should be used to measure the error.\n\nSee also: Errmeasure\n\n\n\n\n\n","category":"type"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"EigvalReferenceErrmeasure","category":"page"},{"location":"errmeasure/#NonlinearEigenproblems.NEPTypes.EigvalReferenceErrmeasure","page":"Measuring the error","title":"NonlinearEigenproblems.NEPTypes.EigvalReferenceErrmeasure","text":"struct EigvalReferenceErrmeasure{X<:Number} <: Errmeasure\nfunction EigvalReferenceErrmeasure(Œªref,nep)\n\nUse the difference between a precomputed Œª-value (reference solution) and the eigenvalue estimate as the error measure.\n\nExample\n\njulia> using LinearAlgebra\njulia> nep=nep_gallery(\"qdep0\");\njulia> (Œªref,vref)=quasinewton(nep,Œª=-1,v=ones(size(nep,1)));\njulia> (Œª,v)=quasinewton(nep,errmeasure=EigvalReferenceErrmeasure(nep,Œªref),Œª=-1.0 ,logger=1,tol=5e-13,v=ones(size(nep,1)))\nPrecomputing linsolver\niter 1 err:0.0024669885857651064 Œª=-1.0 + 0.0im\niter 2 err:0.2961339774298044 Œª=-0.7063330111559607 + 0.0im\niter 3 err:0.11050908031267426 Œª=-0.8919579082730908 + 0.0im\niter 4 err:0.007291415670313883 Œª=-1.009758404256079 + 0.0im\niter 5 err:8.460128136422718e-5 Œª=-1.0023823873044009 + 0.0im\niter 6 err:9.01533362851481e-7 Œª=-1.0024660870524023 + 0.0im\niter 7 err:8.006004341698514e-7 Œª=-1.0024677891861993 + 0.0im\niter 8 err:3.889644784038637e-8 Œª=-1.0024669496893173 + 0.0im\niter 9 err:3.2391431759037914e-9 Œª=-1.0024669918249083 + 0.0im\niter 10 err:2.418489852828998e-10 Œª=-1.0024669883439161 + 0.0im\niter 11 err:2.0229151687090052e-11 Œª=-1.0024669886059943 + 0.0im\niter 12 err:0.0 Œª=-1.002466988585765 + 0.0im\n\nSee also: Errmeasure\n\n\n\n\n\n","category":"type"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"estimate_error","category":"page"},{"location":"errmeasure/#NonlinearEigenproblems.NEPTypes.estimate_error","page":"Measuring the error","title":"NonlinearEigenproblems.NEPTypes.estimate_error","text":"function estimate_error(E::ErrmeasureType,Œª,v)\n\nReturns the error estimate for the eigenpair (Œª,v). The way to measure the error is specified in E, which can be an Errmeasure or a Function.\n\nSee also: Errmeasure, ErrmeasureType\n\n\n\n\n\n","category":"function"},{"location":"errmeasure/#","page":"Measuring the error","title":"Measuring the error","text":"ErrmeasureType","category":"page"},{"location":"errmeasure/#NonlinearEigenproblems.NEPTypes.ErrmeasureType","page":"Measuring the error","title":"NonlinearEigenproblems.NEPTypes.ErrmeasureType","text":"ErrmeasureType = Union{Type{<:Errmeasure}, Function}\n\nThe ErrmeasureType represents (essentially) what you can insert in the errmeasure keyword argument for most NEP-solvers. It can be a function or an  Errmeasure object. If it is a Function this function will be used to obtain error estimate.\n\nExample\n\nThis shows how to compute a reference solution and then use this as a reference solution. The error in the second run will be effectively the eigenvector error (appropriately normalized).\n\njulia> using LinearAlgebra\njulia> nep=nep_gallery(\"qdep0\");\njulia> (Œªref,vref)=quasinewton(nep,Œª=-1,v=ones(size(nep,1)));\njulia> myerrmeasure=(Œª,v) -> norm(vref/vref[1]-v/v[1])\njulia> (Œª,v)=quasinewton(nep,errmeasure=myerrmeasure,Œª=-1.0 ,logger=1,tol=5e-13,v=ones(size(nep,1)))\nPrecomputing linsolver\niter 1 err:0.0024669885857651064 Œª=-1.0 + 0.0im\niter 2 err:0.2961339774298044 Œª=-0.7063330111559607 + 0.0im\niter 3 err:0.11050908031267426 Œª=-0.8919579082730908 + 0.0im\niter 4 err:0.007291415670313883 Œª=-1.009758404256079 + 0.0im\niter 5 err:8.460128136422718e-5 Œª=-1.0023823873044009 + 0.0im\niter 6 err:9.01533362851481e-7 Œª=-1.0024660870524023 + 0.0im\niter 7 err:8.006004341698514e-7 Œª=-1.0024677891861993 + 0.0im\niter 8 err:3.889644784038637e-8 Œª=-1.0024669496893173 + 0.0im\niter 9 err:3.2391431759037914e-9 Œª=-1.0024669918249083 + 0.0im\niter 10 err:2.418489852828998e-10 Œª=-1.0024669883439161 + 0.0im\niter 11 err:2.0229151687090052e-11 Œª=-1.0024669886059943 + 0.0im\niter 12 err:0.0 Œª=-1.002466988585765 + 0.0im\n\nThe eigenvalue error can be measured with the EigvalReferenceErrmeasure.\n\nSee also: Errmeasure\n\n\n\n\n\n","category":"constant"},{"location":"tutorial_fortran1/#Tutorial:-Solving-a-NEP-defined-in-fortran-1","page":"Tutorial 7 (FORTRAN)","title":"Tutorial: Solving a NEP defined in fortran","text":"","category":"section"},{"location":"tutorial_fortran1/#A-problem-defined-in-fortran-1","page":"Tutorial 7 (FORTRAN)","title":"A problem defined in fortran","text":"","category":"section"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"A situation may arise where you  have to (or have the opportunity to) work with fortran code. This is not as uncommon as many think, mostly due to the legacy software in many engineering disciplines. The Julia language is designed with interoperability in mind. Don't let some fortran code scare you. The following tutorial illustrates interoperability in Julia and how to use it in NEP-PACK.","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"note: Note\nTo work with NEPs defined in fortran you need to compile your fortran code. This tutorial is written for Ubuntu Linux and GNU fortran. However, it is possible also under the Windows OS.","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"We assume our NEP is defined in fortran code and defines the problem","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"M(lambda)=A_0+lambda^3e_ne_1^T-exp(lambda)e_1e_n^T","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"where A_0 is a finite difference approximation of a scaled Laplacian matrix. The problem can be naturally represented in sparse format, which we will also take advantage of.","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"The fortran implementation of the problem is given in the following subroutine which computes three vectors I, J and F, where I and J correspond to row and column pointers and F the value of the sparse matrix. The variable s is Œª, i.e., the evaluation point. The input der determines which derivative of M(Œª) should be computed.","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"tip: Tip\nLater in this tutorial we look at what can be done if the derivatives are not easily available.","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"This is the implementation which we put in myproblem.f95:","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"subroutine mder(s,n,der,I,J,F)\n  real*8, intent(in) :: s\n  integer*8, intent(in) :: n\n  integer*8, intent(in) :: der\n  integer*8, intent(out), dimension(3*n):: I\n  integer*8, intent(out), dimension(3*n):: J\n  real*8, intent(out), dimension(3*n):: F\n  integer*8 :: p\n  real*8 :: factor\n  if (der==0) then\n     factor=1;\n  else\n     factor=0;\n  end if\n  do p = 1, n\n     I(p) = p\n     J(p) = p\n     F(p) = 2.0*factor;\n  end do\n  do p = 1, n-1\n     I(n+p) = p\n     J(n+p) = p+1\n     F(n+p) = -1.0*factor;\n     I(2*n+p) = p+1\n     J(2*n+p) = p\n     F(2*n+p) = -1.0*factor;\n  end do\n  I(2*n)=n;\n  J(2*n)=1;\n  if (der == 0) then\n     F(2*n)=s*s*s;\n  else if (der == 1) then\n     F(2*n)=3*s*s;\n  else if (der == 2) then\n     F(2*n)=3*2*s;\n  else if (der == 3) then\n     F(2*n)=3*2;\n  else\n     F(2*n)=0;\n  end if\n  I(3*n)=1;\n  J(3*n)=n;\n  F(3*n)=-exp(s);\nend subroutine mder","category":"page"},{"location":"tutorial_fortran1/#Compile-and-call-the-code-1","page":"Tutorial 7 (FORTRAN)","title":"Compile and call the code","text":"","category":"section"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"Compile the code to a shared object file with the command gfortran:","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"$ gfortran -shared -fPIC -o myproblem.so myproblem.f95","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"(Under the Windows OS, you would want to compile the code to a dll-file.) In Julia, you can now call this routine using the Libdl package:","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"using NonlinearEigenproblems, Libdl;\nmylib=Libdl.dlopen(\"./myproblem.so\");\nŒª=0.3;\nder=0;\nn=3; # Problem size\nI=Vector{Int}(undef,3*n); # 3*n nnz elements in matrix\nJ=Vector{Int}(undef,3*n); # 3*n nnz elements in matrix\nF=Vector{Float64}(undef,3*n); # 3*n nnz elements in matrix\n# This is the call to the fortran code\n# Note that :mder_ is a reference to a fortran subroutine:\n# it must be lower-case and  a _ should be appended\nccall(Libdl.dlsym(mylib,:mder_), Nothing,\n   (Ref{Float64}, Ref{Int},Ref{Int},  Ptr{Int}, Ptr{Int}, Ptr{Float64}),\n   Œª, n, der, I, J, F)","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"The above code sets vectors I, J and F such that they represent a sparse matrix. The sparse matrix can be constructed with the sparse command:","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"julia> using SparseArrays\njulia> A=sparse(I,J,F)\n3√ó3 SparseMatrixCSC{Float64,Int64} with 9 stored entries:\n  [1, 1]  =  2.0\n  [2, 1]  =  -1.0\n  [3, 1]  =  0.027\n  [1, 2]  =  -1.0\n  [2, 2]  =  2.0\n  [3, 2]  =  -1.0\n  [1, 3]  =  -1.34986\n  [2, 3]  =  -1.0\n  [3, 3]  =  2.0\njulia> Matrix(A)\n3√ó3 Array{Float64,2}:\n  2.0    -1.0  -1.34986\n -1.0     2.0  -1.0\n  0.027  -1.0   2.0","category":"page"},{"location":"tutorial_fortran1/#Implementation-in-NEP-PACK:-basic-usage-1","page":"Tutorial 7 (FORTRAN)","title":"Implementation in NEP-PACK: basic usage","text":"","category":"section"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"We saw above how to compute a derivative matrix with a fortran call. This is sufficient to define a NEP-object in NEP-PACK using the Mder_NEP type.","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"n=100;\n# A function which allocates vectors and calls fortran,\n# and returns a sparse matrix\nfunction my_Mder(Œª::Float64,der::Int=0)\n  # Index vectors: Length 3*n since we have 3n nnz elements in matrix\n  I=Vector{Int}(undef,3*n);\n  J=Vector{Int}(undef,3*n);\n  F=Vector{Float64}(undef,3*n);\n  ccall(Libdl.dlsym(mylib,:mder_), Nothing,\n     (Ref{Float64}, Ref{Int},Ref{Int},  Ptr{Int}, Ptr{Int}, Ptr{Float64}),\n     Œª, n, der, I, J, F)\n  return sparse(I,J,F);\nend\nnep=Mder_NEP(n,my_Mder);","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"With the NEP defined, we can use, e.g., quasinewton, to solve it:","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"julia> quasinewton(Float64,nep,Œª=-1.8,v=ones(n), logger=1);\nPrecomputing linsolver\nIteration:  1 errmeasure:4.903565024143569095e-01, Œª=-1.8\nIteration:  2 errmeasure:8.776860766232853772e-02, Œª=-1.3816406142423465\nIteration:  3 errmeasure:6.109070850428219984e-02, Œª=-2.0060080798679913\n...\nIteration: 11 errmeasure:5.305001776886219717e-12, Œª=-1.7940561686588974\nIteration: 12 errmeasure:2.895637837297152945e-14, Œª=-1.7940561686787597\nIteration: 13 errmeasure:3.874312247075750238e-16, Œª=-1.7940561686786516","category":"page"},{"location":"tutorial_fortran1/#Implementation-in-NEP-PACK:-basic-usage,-no-derivatives-1","page":"Tutorial 7 (FORTRAN)","title":"Implementation in NEP-PACK: basic usage, no derivatives","text":"","category":"section"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"In the above example, all the derivatives of M(Œª) were easy to compute by hand and made available in the fortran subroutine. In many applications, the nonlinearity is not so simple, and its derivatives may require man-hours to analyze and implement, or may be very computationally expensive.","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"Most NEP-algorithms in NEP-PACK do require the derivative (except for certain versions of nleigs, broyden, contour_beyn, and sgiter). However, many NEP-algorithms do not require a very accurate derivative. We now show how you can make a numerical approximation of the derivative available, if you do not want to compute the exact derivative. The example below uses finite differences, but any numerical differentiation procedure may be used. (The code does not use derivatives in mder, since all calls are done with der=0.)","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"n=100;\nfunction my_Mder_FD(Œª::Float64,der::Int=0)\n  if (der>1)\n   error(\"Higher derivatives not supported\");\n  end\n  # 3*n nnz elements in matrix\n  I=Vector{Int}(undef,3*n);\n  J=Vector{Int}(undef,3*n);\n  F1=Vector{Float64}(undef,3*n);\n  ccall(Libdl.dlsym(mylib,:mder_), Nothing,\n     (Ref{Float64}, Ref{Int},Ref{Int},  Ptr{Int}, Ptr{Int}, Ptr{Float64}),\n     Œª, n, 0, I, J, F1)\n  if (der==0)\n     return sparse(I,J,F1);\n  end\n\n  if (der==1)\n     # Make another fortran call to make a finite difference approximation\n     ee=sqrt(eps());\n     F2=Vector{Float64}(undef,3*n);\n     ccall(Libdl.dlsym(mylib,:mder_), Nothing,\n          (Ref{Float64}, Ref{Int},Ref{Int},  Ptr{Int}, Ptr{Int}, Ptr{Float64}),\n          Œª-ee, n, 0, I, J, F2)\n     # We exploit the fact that the sparsity pattern is independent of Œª\n     Fder=(F1-F2)/ee;\n     return sparse(I,J,Fder);\n  end\nend","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"Create the NEP and call a solver, in this case MSLP.","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"julia> nep=Mder_NEP(n,my_Mder_FD,maxder=1);\njulia> mslp(Float64,nep,Œª=-1.8,logger=1);\niter 1 err:5.14547949525844e-6 Œª=-1.7941228234498503\niter 2 err:6.60477516490422e-10 Œª=-1.7940561772509709\niter 3 err:5.617933513637005e-16 Œª=-1.794056168678654","category":"page"},{"location":"tutorial_fortran1/#Implementation-in-NEP-PACK:-advanced-usage-1","page":"Tutorial 7 (FORTRAN)","title":"Implementation in NEP-PACK: advanced usage","text":"","category":"section"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"The above procedure requires that sparse matrices are created every time the NEP is accessed. This may be computationally demanding. A common call in NEP-PACK, is to compute the matrix vector product M(Œª)*v. If the creation of the matrix M(Œª) requires considerable computation or storage, you may want to implement the function which directly computes the matrix vector product. This is made available to the NEP-PACK object as follows.","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"Add the following to your myproblem.f95:","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"subroutine matvec(s,n,v,x)\n  real*8, intent(in) :: s\n  integer*8, intent(in) :: n\n  real*8, intent(in), dimension(n):: v\n  real*8, intent(out), dimension(n):: x\n  integer*8 :: p\n  do p = 1, n\n      x(p)=2*v(p)\n  end do\n  do p = 1, n-1\n      x(p)= x(p) - v(p+1)\n      x(p+1)= x(p+1) - v(p)\n  end do\n  x(n)=x(n)+v(1)*s*s*s;\n  x(1)=x(1)-v(n)*exp(s);\nend subroutine matvec","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"After recompilation of the library file myproblem.so, restarting Julia, and loading again myproblem.so, we can make a matvec function available.","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"function my_matvec(Œª,v)\n   v=vec(v);  # It has to be a vector\n   x=copy(v); # Allocate a vector for storage of result\n   ccall(Libdl.dlsym(mylib,:matvec_), Nothing,\n      (Ref{Float64}, Ref{Int}, Ptr{Float64},  Ptr{Float64}),\n      Œª, n, v, x)\n   return x;\nend","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"We can now create a Mder_Mlincomb_NEP which is defined from both matrix derivative computations as well as matrix vector products (or more generally linear combinations of derivatives).","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"julia> nep2=Mder_Mlincomb_NEP(n,my_Mder,1,my_matvec,0);","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"The 1 and 0 specify the highest derivative available for the two functions. We can now solve the NEP with many methods, e.g. resinv.","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"julia> resinv(Float64,nep2,Œª=-1.8,v=ones(n),logger=1);\nPrecomputing linsolver\niter 1 err:0.4903565024143571 Œª=-1.8\niter 2 err:0.11453605256493624 Œª=-1.1926857650225988\n...\niter 7 err:5.834331567428063e-13 Œª=-1.7940561686808254\niter 8 err:2.989922602862964e-15 Œª=-1.794056168678641","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"When using NEP-solvers requiring higher derivatives, the above procedure can also be used to compute linear combinations of higher derivatives by implementing a compute_Mlincomb which takes a matrix as input.","category":"page"},{"location":"tutorial_fortran1/#","page":"Tutorial 7 (FORTRAN)","title":"Tutorial 7 (FORTRAN)","text":"(Image: To the top)","category":"page"},{"location":"methods/#NEP-Solvers-1","page":"NEP-Solvers","title":"NEP-Solvers","text":"","category":"section"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"The NEP solver methods implemented in NEP-PACK, are accessed by the functions below. The functions all return Œªv where Œª is either a number (eigenvalue) a vector of eigenvalues v is either a vector containing an eigenvector or a matrix whose columns corresponding to the eigenvectors. Two-sided methods may return Œªvw where w are the left eigenvectors.","category":"page"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"The first parameter optional parameter in all NEP solver methods is a type. This type specifies which arithmetic should be used for the algorithm.","category":"page"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"Example:","category":"page"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"julia> nep=nep_gallery(\"dep0\")\njulia> Œª,v=augnewton(Complex128,nep,v=ones(5))\n(0.8347353572199425 + 0.0im, Complex{Float64}[0.480386+0.0im, 0.0631636+0.0im, -0.136405+0.0im, 0.214274+0.0im, 0.378581+0.0im])\njulia> typeof(Œª)\nComplex{Float64}\njulia> Œª,v=augnewton(Float16,nep,v=ones(5))\n(Float16(0.8223), Float16[0.47388, 0.063904, -0.13843, 0.21692, 0.38306])\njulia> typeof(Œª)\nFloat16","category":"page"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"The NEP-solvers can be separated into the following types (with some overlap):","category":"page"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"Newton type methods\nProjection methods\nContour integral methods\nArnoldi and Krylov based methods\nClass specific methods","category":"page"},{"location":"methods/#Newton-type-methods-1","page":"NEP-Solvers","title":"Newton type methods","text":"","category":"section"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"newton","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.newton","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.newton","text":"Œª,v = newton([eltype],nep::NEP;[errmeasure,][tol,][maxit,][Œª,][v,][c,][logger,][armijo_factor=1,][armijo_max])\n\nApplies Newton-Raphsons method on the system of nonlinear equations with n+1 unknowns:\n\nM(Œª)v=0\n\nc^Hv-1=0\n\nThe vector c is the orthogonalization vector.  If c=0 the current approximation will be used for the orthogonalization. See augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"dep0\");\njulia> Œª,v=newton(nep);\njulia> minimum(svdvals(compute_Mder(nep,Œª)))\n1.6066157878930876e-16\n\nReferences\n\nNichtlineare Behandlung von Eigenwertaufgaben, Z. Angew. Math. Mech. 30 (1950) 281-282.\nA. Ruhe, Algorithms for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 10 (1973) 674-689\n\n\n\n\n\n","category":"function"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"augnewton","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.augnewton","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.augnewton","text":"augnewton([eltype], nep::NEP; [errmeasure,][tol,][maxit,][Œª,][v,][c,][logger,][linsolvercreator,][armijo_factor,][armijo_max])\n\nRun the augmented Newton method. The method is equivalent to newton() in exact arithmetic,  but works only with operations on vectors of length n.\n\nThe following keyword arguments are in common for many NEP-solvers:\n\nlogger is either a Logger object or an Int. If it is an Int, a PrintLogger(logger) will be instantiated. logger=0 prints nothing, logger=1 prints more, etc.\nerrmeasure determines how error is measured. It is either a function handle or an object of the type Errmeasure.  If it is a function handle, it should take (Œª,v) as input and return a real scalar (the error). See Errmeasure and ErrmeasureType for further description.\ntol is a scalar which determines termination. If errmeasure is less than tol the eigenpair is marked as converged.\nThe scalar Œª and the vector v are starting approximations.\nmaxit determines the maximum number of iterations. The error NoConvergenceException is thrown if this is exceeded.\nThe linsolvecreator specifies how the linear system should be solved. See LinSolver for further information.\narmijo_factor specifies if an Armijo rule should be applied, and its value specifies the scaling factor of the step length (per reduction step). The variable armijo_max specifies the maximum number of step length reductions.\n\nExample\n\nThis illustrates the equivalence between newton and augnewton.\n\njulia> nep=nep_gallery(\"dep1\")\njulia> Œª1,v1=newton(nep,maxit=20,v=ones(size(nep,1)),Œª=0)\njulia> Œª2,v2=augnewton(nep,maxit=20,v=ones(size(nep,1)),Œª=0)\njulia> Œª1-Œª2\n0.0 + 0.0im\n\nReferences\n\nNichtlineare Behandlung von Eigenwertaufgaben, Z. Angew. Math. Mech. 30 (1950) 281-282.\nA. Ruhe, Algorithms for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 10 (1973) 674-689\n\n\n\n\n\n","category":"function"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"resinv","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.resinv","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.resinv","text":"Œª,v = resinv([eltype],nep::NEP;[errmeasure,][tol,][maxit,][Œª,][v,][c,][logger,][armijo_factor=1,][armijo_max,][linsolvecreator])\n\nApplies residual inverse iteration method for nonlinear eigenvalue problems. The kwarg linsolvecreator is a function which specifies how the linear system is created. The function calls compute_rf for the computation of the Rayleigh functional. See augnewton for other parameters.\n\nExample\n\nThe example shows how to specify if the method should run in real or complex mode (or any other Number type).\n\njulia> nep=nep_gallery(\"qdep0\");\njulia> Œª,v=resinv(nep,Œª=-2,v=ones(size(nep,1)))\njulia> typeof(Œª)\nComplex{Float64}\njulia> norm(compute_Mlincomb(nep,Œª,v))\n1.817030659827106e-14\njulia> Œª,v=resinv(Float64,nep,Œª=-2,v=ones(size(nep,1)))\njulia> typeof(Œª)\nFloat64\njulia> norm(compute_Mlincomb(nep,Œª,v))\n1.817030659827106e-14\n\nReferences\n\nA. Neumaier, Residual inverse iteration for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 22 (1985) 914-923\n\n\n\n\n\n","category":"function"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"quasinewton","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.quasinewton","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.quasinewton","text":"quasinewton([T=ComplexF64],nep,[errmeasure,][tol,][maxit,][Œª,][v][ws][logger][linsolvercreator,][armijo_factor,][armijo_max])\n\nAn implementation of the quasi-Newton approach referred to as quasi-Newton 2 in the reference. The method involves one linear system solve per iteration corresponding with the matrix M(Œª), where Œª is constant. The vector ws is a representation of the normalization, in the sense that c^T=w_s^TM(Œª), where all iterates satisfy c^Tx_i=1. See augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"pep0\")\njulia> Œª,v=quasinewton(nep,v=ones(size(nep,1)));\njulia> norm(compute_Mlincomb(nep,Œª,v))/norm(v)\n6.301479387102376e-15\n\nReferences\n\nJarlebring, Koskela, Mele, Disguised and new Quasi-Newton methods for nonlinear eigenvalue problems, Numer. Algorithms, 79:311-335, 2018. preprint\n\n\n\n\n\n","category":"function"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"mslp","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.mslp","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.mslp","text":" mslp([eltype],nep::NEP;[errmeasure,][tol,][maxit,][Œª,][v,][logger,][eigsolvertype::Type][armijo_factor=1,][armijo_max])\n\nRuns the method of successive linear problems. The  method requires the solution of a generalized eigenvalue problem in every iteration. The method used for the eigenvalue computation is specified in eigsolvertype. See augnewton for other parameters.\n\nExample\n\nCreate a rational NEP using a SPMF_NEP.\n\njulia> eye=Matrix{Float64}(I,3,3);\njulia> Av=[ones(3,3),eye,triu(ones(3,3))];\njulia> fv=[S-> S, S -> S^2, S->inv(S-one(S)*10)]\njulia> nep=SPMF_NEP(Av,fv)\njulia> (Œª,v)=mslp(nep)\njulia> compute_Mlincomb(nep,Œª,v)\n3-element Array{Complex{Float64},1}:\n -1.38778e-17+1.65715e-18im\n -5.55112e-17+1.30633e-17im\n -4.16334e-17-1.54436e-17im\n\nReferences\n\nA. Ruhe, Algorithms for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 10 (1973) 674-689\n\n\n\n\n\n","category":"function"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"sgiter","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.sgiter","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.sgiter","text":"Œª,v = sgiter([eltype],nep::NEP,j::Integer;[Œª_min,][Œª_max,][Œª,][errmeasure,][tol,][maxit,][logger,][eigsolvertype::Type,])\n\nFinds the j-th eigenvalue of the NEP using safeguarded iteration, with eigenvalue numbering according to min-max theory. The method only works for Hermitian problems, and the eigenvalues are assumed to be real. If an interval [Œª_min,Œª_max] is given, then the Rayleigh functional is assumed to be unique on the interval. If no interval is given, then the minimum solution is always taken. The method requires the computation of (all) eigenvalues of a matrix. The eigsolvertype is a Type that specifies which eigevalue solver is used inside the algorithm.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> nep = nep_gallery(\"real_quadratic\");\njulia> Œª,v = sgiter(nep, 1, Œª_min = -10, Œª_max = 0,  Œª = -10, maxit = 100);\njulia> minimum(svdvals(compute_Mder(nep,Œª)))\n0.0\njulia> norm(v)\n1.0\n\nReferences\n\nV. Mehrmann and H. Voss, Nonlinear eigenvalue problems: a challenge for modern eigenvalue methods, GAMM‚ÄêMitteilungen 27.2 (2004): 121-152.\nH. Voss and B. Werner, Solving sparse nonlinear eigenvalue problems. Technical Report 82/4, Inst. f. Angew. Mathematik, Universit√§t Hamburg, 1982.\nB. Werner. Das Spektrum von Operatorenscharen mit verallgemeinerten Rayleighquotienten. PhD thesis, Fachbereich Mathematik, Universit√§t Hamburg, 1970\n\n\n\n\n\n","category":"function"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"rfi","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.rfi","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.rfi","text":"rfi(nep,nept,[Œª=0,][errmeasure,][tol=eps()*100,][maxit=100,][v=randn,][u=randn,][logger=0,][linsolvecreator=DefaultLinSolverCreator(),])\n\nThis is an implementation of the two-sided Rayleigh functional Iteration (RFI) to compute an eigentriplet of the problem specified by nep. This method requires the transpose of the NEP, specified in nept. Œª, u and v are initial guesses for the eigenvalue, the right eigenvector and the left eigenvector respectively. See augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"dep0\");\njulia> nept=DEP([nep.A[1]',nep.A[2]'])\njulia> Œª,v,u=rfi_b(nep,nept)\njulia> compute_resnorm(nep,Œª,v) % v is a right eigenvector\n4.347204570675246e-16\njulia> compute_resnorm(nept,Œª,u) % u is a left eigenvector\n7.173081573164097e-16\n\nReference\n\nAlgorithm 4 in  Schreiber, Nonlinear Eigenvalue Problems: Newton-type Methods and Nonlinear Rayleigh Functionals, PhD thesis, TU Berlin, 2008.\n\n\n\n\n\n","category":"function"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"rfi_b","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.rfi_b","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.rfi_b","text":"rfi_b(nep,nept,[Œª=0,][errmeasure,][tol=eps()*100,][maxit=100,][v=randn,][u=randn,][logger=0,][linsolvecreator=DefaultLinSolverCreator(),])\n\nThis is an implementation of the two-sided Rayleigh functional Iteration(RFI)-Bordered version to compute an eigentriplet of the problem specified by nep. This method requires the transpose of the NEP, specified in nept. Œª, u and v are initial guesses for the eigenvalue, the right eigenvector and the left eigenvector respectively. See augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"dep0\");\njulia> nept=DEP([nep.A[1]',nep.A[2]'])\njulia> Œª,v,u=rfi_b(nep,nept,v=ones(size(nep,1)))\njulia> compute_resnorm(nep,Œª,v) % v is a right eigenvector\n5.343670589284583e-15\njulia> compute_resnorm(nept,Œª,u) % u is a left eigenvector\n5.271390516634306e-16\n\nReference\n\nAlgorithm 5 in  Schreiber, Nonlinear Eigenvalue Problems: Newton-type Methods and Nonlinear Rayleigh Functionals, PhD thesis, TU Berlin, 2008.\n\n\n\n\n\n","category":"function"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"blocknewton","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.blocknewton","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.blocknewton","text":"(S,X)=blocknewton(nep [S,] [X,] [errmeasure,] [tol,] [maxit,] [armijo_factor,] [armijo_max,] [logger])\n\nApplies the block Newton method to nep::AbstractSPMF. The method computes an invariant pair (S,X) using the block Newton approach of Kressner. The variables S,X correspond to starting approximations. The function errmeasure shoule be defined for errmeasure(S,X) and meausures the error in the pair (S,X). See augnewton for other parameters.\n\nExample\n\nThe example shows that compute_MM() becomes zero when a solution has been computed.\n\njulia> nep=nep_gallery(\"dep0\",3);\njulia> (S,X)= blocknewton(nep)\njulia> compute_MM(nep,S,X)\n3√ó2 Array{Complex{Float64},2}:\n -2.22045e-16-1.0842e-19im  -2.08167e-17+0.0im\n  1.94289e-16-1.0842e-19im  -5.55112e-17-6.77626e-20im\n  7.63278e-17-1.0842e-19im   2.77556e-17-2.71051e-20im\n\nThis example solves the gun problem from the Berlin-Manchester collection\n\njulia> using NonlinearEigenproblems.Gallery\njulia> nep=nep_gallery(\"nlevp_native_gun\");\njulia> II=[1.0 0; 0 1]; S=150^2*II; V=[II;zeros(size(nep,1)-2,2)];\njulia> (Z,X)=blocknewton(nep,S=S,X=V,logger=1,armijo_factor=0.5,maxit=20)\nIteration 1: Error: 6.081316e+03\nIteration 2: Error: 1.701970e-02 Armijo scaling=0.031250\nIteration 3: Error: 1.814887e-02 Armijo scaling=0.250000\n...\nIteration 13: Error: 6.257442e-09\nIteration 14: Error: 2.525942e-15\n\nReferences\n\nD. Kressner A block Newton method for nonlinear eigenvalue problems, Numer. Math., 114 (2) (2009), pp. 355-372\n\n\n\n\n\n","category":"function"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"newtonqr","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.newtonqr","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.newtonqr","text":"Œª,v = newtonqr([eltype],nep::NEP;[errmeasure,][tol,][maxit,][Œª,][v,][c,][logger])\n\nThis function implements the Newton-QR method as formulated in the reference. The method ivolves the computation of a rank-revealing QR factorization of M(Œª), with the idea that on convergence the the last diagonal element Rnn of the upper-triangular matrix R becomes zero as a result of M(Œª) becoming singular. Since the computation of a QR factorization is expensive, it is advisable to use this method for problems of small size or problems with a certain structure that makes the QR computation less expensive. See augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"pep0\")\njulia> Œª,v=newtonqr(nep,v=ones(size(nep,1)));\njulia> norm(compute_Mlincomb(nep,Œª,v))/norm(v)\n1.0442559980785471e-14\n\nReferences\n\nKublanovskaya, V. N., (1970).  On an approach to the solution of the generalized latent value problem for Œª-matrices, SIAM J. Numer. Anal. 7, 532‚Äì537\nG√ºttel, S., & Tisseur, F. (2017). The nonlinear eigenvalue problem. Acta Numerica, 26, 1-94. doi:10.1017/S0962492917000034\n\n\n\n\n\n","category":"function"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"implicitdet","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.implicitdet","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.implicitdet","text":"Œª,v = implicitdet([eltype],nep::NEP;[errmeasure,][tol,][maxit,][Œª,][v,][c,][logger])\n\nThis function implements the Implicit determinant method as formulated Algorithm 4.3 in the reference. The method applies Newton-Raphson to the equation det(M(Œª))det(G(Œª)) = 0, where G(Œª) is a saddle point matrix with M(Œª) in the (1,1) block. The (2,1) and (1,2) blocks of G(Œª) are set to c^H and c respectively. Note that G(Œª) can be non-singular even when M(Œª) is singular. See reference for more information. See augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"pep0\")\njulia> Œª,v=implicitdet(nep,v=ones(size(nep,1)));\njulia> norm(compute_Mlincomb(nep,Œª,v))/norm(v)\n3.75723275262885e-14\n\nReferences\n\nSpence, A., & Poulton, C. (2005). Photonic band structure calculations using nonlinear eigenvalue techniques, J. Comput. Phys., 204 (2005), pp. 65‚Äì8\nG√ºttel, S., & Tisseur, F. (2017). The nonlinear eigenvalue problem. Acta Numerica, 26, 1-94. doi:10.1017/S0962492917000034\n\n\n\n\n\n","category":"function"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"broyden","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.broyden","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.broyden","text":"S,V = broyden([eltype,]nep::NEP[,approxnep::NEP];kwargs)\n\nRuns Broydens method (with deflation) for the nonlinear eigenvalue problem defined by nep. An approximate nep can be provided which is used as an initialization of starting matrix/vectors.\n\nThe method computes an invariant pair and can therefore find several eigenvalues. The retured value is (S,V) is an invariant pair and the eigenvalues are on the diagonal of S.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"dep0\");\njulia> S,V=broyden(nep);\njulia> Œª=S[1,1]\n-0.3587189459686267 - 3.0010731412746105e-31im\njulia> minimum(svdvals(compute_Mder(nep,Œª)))\n1.6066157878930856e-16\njulia> Œª=S[2,2]\n-0.04093521177097334 + 1.486011530941621im\njulia> minimum(svdvals(compute_Mder(nep,Œª)))\n4.159109513753696e-16\njulia> Œª=S[3,3]\n0.8347353572199486 + 1.5032076225139986e-14im\njulia> minimum(svdvals(compute_Mder(nep,Œª)))\n1.296144276122994e-14\njulia> broyden(nep,logger=2,check_error_every=1);  % Prints out a lot more convergence info\n\nReferences\n\nJarlebring, Broyden‚Äôs method for nonlinear eigenproblems, 2018, https://arxiv.org/pdf/1802.07322\n\n\n\n\n\n","category":"function"},{"location":"methods/#Projection-methods-1","page":"NEP-Solvers","title":"Projection methods","text":"","category":"section"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"nlar\njd_betcke\njd_effenberger","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.nlar","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.nlar","text":"function nlar([eltype],nep::ProjectableNEP,[orthmethod=ModifiedGramSchmidt],[neigs=10],[errmeasure],[tol=eps(real(T))*100],[maxit=100],[Œª0=0],[v0=randn(T,size(nep,1))],[logger=0],[linsolvercreator=DefaultLinSolverCreator()],[R=0.01],[eigval_sorter=residual_eigval_sorter],[qrfact_orth=false],[max_subspace=100],[num_restart_ritz_vecs=8],[inner_solver_method=DefaultInnerSolver(),][inner_logger=0])\n\nThe function implements the Nonlinear Arnoldi method, which finds neigs eigenpairs (or throws a NoConvergenceException) by projecting the problem to a subspace that is expanded in the course  of the algorithm. The basis is orthogonalized either by using the QR method if qrfact_orth is true or else by an orthogonalization method orthmethod). This entails solving a smaller projected problem using a method specified by inner_solver_method. The logging of the inner solvers are descided by inner_logger, which works in the same way as logger. (Œª0,v0) is the initial guess for the eigenpair. linsolvercreator specifies how the linear system is created and solved. R is a parameter used by the function specified by eigval_sorter to reject those ritz values that are within a distance R from any of the converged eigenvalues, so that repeated convergence to the same eigenpair can be avoided. max_subspace is the maximum allowable size of the basis befor the algorithm restarts using a basis made of num_restart_ritz_vecs ritz vectors and the eigenvectors that the algorithm has converged to.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"dep0_tridiag\");\njulia> Œª,v=nlar(nep,tol=1e-5,neigs=1,maxit=50);\njulia> norm(compute_Mlincomb(nep,Œª[1],v))\n7.722757003764154e-7\n\nReferences\n\nH. Voss, An Arnoldi method for nonlinear eigenvalue problems. BIT. Numer. Math. 44: 387-401, 2004.\n\n\n\n\n\n","category":"function"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.jd_betcke","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.jd_betcke","text":"jd_betcke([eltype]], nep::ProjectableNEP; [neigs=1], [tol=eps(real(T))*100], [maxit=100], [Œª=zero(T)], [orthmethod=DGKS],  [errmeasure], [linsolvercreator=DefaultLinSolverCreator()], [v = randn(size(nep,1))], [logger=0], [inner_logger=0], [inner_solver_method=DefaultInnerSolver()], [projtype=:PetrovGalerkin], [target=zero(T)])\n\nThe function computes eigenvalues using Jacobi-Davidson method, which is a projection method. The projected problems are solved using a solver spcified through the type inner_solver_method. The logging of the inner solvers are descided by inner_logger, which works in the same way as logger. For numerical stability the basis is kept orthogonal, and the method for orthogonalization is specified by orthmethod, see the package IterativeSolvers.jl. The function tries to compute neigs number of eigenvalues, and throws a NoConvergenceException if it cannot. The value Œª and the vector v are initial guesses for an eigenpair. linsolvercreator is a function which specifies how the linear system is created and solved. The target is the center around which eiganvlues are computed. By default the method uses a Petrov-Galerkin framework, with a trial (left) and test (right) space, hence W^H T(Œª) V is the projection considered. By specifying  projtype to be :Galerkin then W=V.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"dep0\",50);\njulia> Œª,v=jd_betcke(nep,tol=1e-5,maxit=20);\njulia> norm(compute_Mlincomb(nep,Œª[1],v[:,1]))\n1.2277391762692744e-8\n\nReferences\n\nT. Betcke and H. Voss, A Jacobi-Davidson-type projection method for nonlinear eigenvalue problems. Future Gener. Comput. Syst. 20, 3 (2004), pp. 363-372.\nH. Voss, A Jacobi‚ÄìDavidson method for nonlinear eigenproblems. In: International Conference on Computational Science. Springer, Berlin, Heidelberg, 2004. pp. 34-41.\n\nSee also\n\nC. Effenberger, Robust successive computation of eigenpairs for nonlinear eigenvalue problems. SIAM J. Matrix Anal. Appl. 34, 3 (2013), pp. 1231-1256.\n\n\n\n\n\n","category":"function"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.jd_effenberger","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.jd_effenberger","text":"jd_effenberger([eltype]], nep::ProjectableNEP; [maxit=100], [neigs=1], [inner_solver_method=DefaultInnerSolver()], [orthmethod=DGKS], [linsolvercreator=DefaultLinSolverCreator()], [tol=eps(real(T))*100], [Œª=zero(T)], [v = rand(T,size(nep,1))], [target=zero(T)],  [logger=0], [inner_logger=0])\n\nThe function computes eigenvalues using the Jacobi-Davidson method, which is a projection method. Repreated eigenvalues are avoided by using deflation, as presented in the reference by Effenberger. The projected problems are solved using a solver spcified through the type inner_solver_method. The logging of the inner solvers are descided by inner_logger, which works in the same way as logger. For numerical stability the basis is kept orthogonal, and the method for orthogonalization is specified by orthmethod, see the package IterativeSolvers.jl. The function tries to compute neigs number of eigenvalues, and throws a NoConvergenceException if it cannot. The value Œª and the vector v are initial guesses for an eigenpair. linsolvercreator is a function which specifies how the linear system is created and solved. The target is the center around which eiganvalues are computed. For further specifications on the deflation_mode, see the function deflate_eigpair.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"dep0\",100);\njulia> Œª,v=jd_effenberger(nep,maxit=30,v=ones(size(nep,1)),Œª=0);\njulia> norm(compute_Mlincomb(nep,Œª[1],v[:,1]))\n1.902783771915309e-14\n\nReferences\n\nC. Effenberger, Robust successive computation of eigenpairs for nonlinear eigenvalue problems. SIAM J. Matrix Anal. Appl. 34, 3 (2013), pp. 1231-1256.\n\nSee also\n\nT. Betcke and H. Voss, A Jacobi-Davidson-type projection method for nonlinear eigenvalue problems. Future Gener. Comput. Syst. 20, 3 (2004), pp. 363-372.\nH. Voss, A Jacobi‚ÄìDavidson method for nonlinear eigenproblems. In: International Conference on Computational Science. Springer, Berlin, Heidelberg, 2004. pp. 34-41.\n\n\n\n\n\n","category":"function"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"The following NEP-solvers can also be seen as projection methods:","category":"page"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"iar, tiar, iar_chebyshev,\nnleigs.","category":"page"},{"location":"methods/#Contour-integral-methods-1","page":"NEP-Solvers","title":"Contour integral methods","text":"","category":"section"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"contour_beyn\ncontour_block_SS","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.contour_beyn","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.contour_beyn","text":"Œªv,V=contour_beyn([eltype,] nep [,mintegrator];[tol,][logger,][œÉ,][radius,][linsolvercreator,][N,][neigs,][k])\n\nThe function computes eigenvalues using Beyn's contour integral approach, using an ellipse centered at œÉ with radii given in radius, or if only one radius is given, the contour is a circle. The numerical quadrature method is specified in mintegrator, which is a type inheriting from MatrixIntegrator, by default MatrixTrapezoidal. For a parallell implementation of the integrator use MatrixTrapezoidalParallel.  The integer k specifies size of the probe subspace. N corresponds to the number of quadrature points. Ellipses are the only supported contours. The linsolvercreator must create a linsolver that can handle (rectangular) matrices as right-hand sides, not only vectors. We integrate in complex arithmetic so eltype must be complex type.\n\nThe kwargs neigs specifies the number of wanted eigvals, and k is the number of columns in the matrix to be integrated (default k=neigs+1). If you give the k parameter and set neigs=typemax(Int) all found eigenvalues will be returned. The kwarg sanity_check decides if sorting and checking (and removal) of eigpairs should be done. If disabled, the method returns k (potentially inaccurate) eigpairs. The parameters errmeasure and tol and rank_drop_tol are used for the sanity check, to extract accurate eigenvalues.\n\nExample\n\njulia> using LinearAlgebra\njulia> nep=nep_gallery(\"dep0\");\njulia> # Look for two eigvals in unit disk\njulia> Œªv,V=contour_beyn(nep,radius=1,neigs=2);\njulia> norm(compute_Mlincomb(nep,Œªv[1],V[:,1])) # Eigenpair 1\n5.778617503485546e-15\njulia> norm(compute_Mlincomb(nep,Œªv[2],V[:,2])) # Eigenpair 2\n3.095638020248726e-14\n\nReferences\n\nWolf-J√ºrgen Beyn, An integral method for solving nonlinear eigenvalue problems, Linear Algebra and its Applications 436 (2012) 3839‚Äì3863\n\n\n\n\n\n","category":"function"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.contour_block_SS","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.contour_block_SS","text":"contour_block_SS([eltype,] nep [,mintegrator];[tol,][logger,][œÉ,][radius,][linsolvercreator,][N,][neigs,][k,][L])\n\nThis is an implementation of the block_SS contour integral method which is based on the computation of higher order moments. The contour is an ellipse centered at œÉ with radii given in radius, or if only one radius is given, the contour is a circle. The numerical quadrature method is specified in mintegrator, which is a type inheriting from MatrixIntegrator, by default MatrixTrapezoidal. For a parallell implementation of the integrator use MatrixTrapezoidalParallel.  The integer k specifies size of the probe subspace. N corresponds to the number of quadrature points. The integer L specifies the number of moments. Ellipses are the only supported contours. The linsolvercreator must create a linsolver that can handle (rectangular) matrices as right-hand sides, not only vectors. We integrate in complex arithmetic so eltype must be complex type.\n\nExample\n\njulia> nep=SPMF_NEP([[0 1 ; 1 1.0], [1 0 ; 0 0]], [s->one(s),s->exp(1im*s^2)]);\njulia> Œª,V=contour_assu(nep,radius=3,neigs=6)\njulia> @show Œª\n6-element Array{Complex{Float64},1}:\n  4.496403249731884e-15 + 2.506628274630998im\n        -2.506628274631 - 2.8727020762175925e-15im\n  3.219972424519104e-16 - 2.5066282746310034im\n     2.5066282746310096 - 1.1438072192922029e-15im\n -2.3814273710772784e-7 - 7.748469160458366e-8im\n   2.381427350935646e-7 + 7.748467479992284e-8im\n\nReferences\n\nAsakura, Sakurai, Tadano, Ikegami, Kimura, A numerical method for nonlinear eigenvalue problems using contour integrals, JSIAM Letters, 2009 Volume 1 Pages 52-55\nVan Beeumen,  Meerbergen, Michiels. Connections between contour integration and rational Krylov methods for eigenvalue problems, 2016, TW673, https://lirias.kuleuven.be/retrieve/415487/\n\n\n\n\n\n","category":"function"},{"location":"methods/#Arnoldi-and-Krylov-based-methods-1","page":"NEP-Solvers","title":"Arnoldi and Krylov based methods","text":"","category":"section"},{"location":"methods/#IAR-1","page":"NEP-Solvers","title":"IAR","text":"","category":"section"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"The Infinite ARnoldi method.","category":"page"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"iar","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.iar","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.iar","text":"iar(nep,[maxit=30,][œÉ=0,][Œ≥=1,][linsolvecreator=DefaultLinSolverCreator(),][tol=eps()*10000,][neigs=6,][errmeasure,][v=rand(size(nep,1),1),][logger=0,][check_error_every=1,][orthmethod=DGKS,][proj_solve=false,][inner_solver_method=DefaultInnerSolver(),][inner_logger=0])\n\nRun the infinite Arnoldi method on the nonlinear eigenvalue problem stored in nep.\n\nThe target œÉ is the center around which eiganvalues are computed. The value Œ≥ corresponds to scaling and specifying a shift and scaling is effectively the same as the transformation Œª=Œ≥s+œÉ where s is now the eigenvalue parameter. If you want eigenvalues in a disk centered, select œÉ as the center of the disk and Œ≥ as the radius. The vector v is the starting vector for constructing the Krylov space. The orthogonalization method, used in contructing the orthogonal basis of the Krylov space, is specified by orthmethod, see the package IterativeSolvers.jl. The iteration is continued until neigs Ritz pairs have converged. This function throws a NoConvergenceException if the wanted eigenpairs are not computed after maxit iterations. However, if neigs is set to Inf the iteration is continued until maxit iterations without an error being thrown. The parameter proj_solve determines if the Ritz paris are extracted using the Hessenberg matrix (false), or as the solution to a projected problem (true). If true, the method is descided by inner_solver_method, and the logging of the inner solvers are descided by inner_logger, which works in the same way as logger.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> using NonlinearEigenproblems, LinearAlgebra\njulia> nep=nep_gallery(\"dep0\",100);\njulia> v0=ones(size(nep,1));\njulia> Œª,v=iar(nep;v=v0,tol=1e-5,neigs=3);\njulia> norm(compute_Mlincomb!(nep,Œª[1],v[:,1])) # Is it an eigenvalue?\njulia> Œª    # print the computed eigenvalues\n3-element Array{Complex{Float64},1}:\n -0.15606211475666945 - 0.12273439802763578im\n -0.15606211475666862 + 0.12273439802763489im\n  0.23169243065648365 - 9.464790582509696e-17im\n\nReferences\n\nAlgorithm 2 in Jarlebring, Michiels Meerbergen, A linear eigenvalue algorithm for the nonlinear eigenvalue problem, Numer. Math, 2012\n\n\n\n\n\n","category":"function"},{"location":"methods/#IAR-Chebyshev-1","page":"NEP-Solvers","title":"IAR Chebyshev","text":"","category":"section"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"A Chebyshev version of the IAR method.","category":"page"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"iar_chebyshev","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.iar_chebyshev","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.iar_chebyshev","text":"iar_chebyshev(nep,[maxit=30,][œÉ=0,][Œ≥=1,][linsolvecreator=DefaultLinSolverCreator(),][tolerance=eps()*10000,][neigs=6,][errmeasure,][v=rand(size(nep,1),1),][logger=0,][check_error_every=1,][orthmethod=DGKS][a=-1,][b=1,][compute_y0_method=ComputeY0ChebAuto])\n\nRun the infinite Arnoldi method (Chebyshev version) on the nonlinear eigenvalue problem stored in nep.\n\nThe target œÉ is the center around which eiganvalues are computed. A Ritz pair Œª and v is flagged a as converged (to an eigenpair) if errmeasure is less than tol. The vector v is the starting vector for constructing the Krylov space. The orthogonalization method, used in contructing the orthogonal basis of the Krylov space, is specified by orthmethod, see the package IterativeSolvers.jl. The iteration is continued until neigs Ritz pairs converge. This function throws a NoConvergenceException if the wanted eigenpairs are not computed after maxit iterations. However, if neigs is set to Inf the iteration is continued until maxit iterations without an error being thrown. The kwarg compute_y0_method specifying how the next vector of the Krylov space (in Chebyshev format) can be computed. See compute_y0_cheb in the module NEPSolver with the command ?NEPSolver.compute_y0_cheb.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> using NonlinearEigenproblems, LinearAlgebra\njulia> nep=nep_gallery(\"dep0\",100);\njulia> v0=ones(size(nep,1));\njulia> Œª,v=iar_chebyshev(nep;v=v0,tol=1e-5,neigs=3);\njulia> norm(compute_Mlincomb!(nep,Œª[1],v[:,1])) # Is it an eigenvalue?\njulia> Œª    # print the computed eigenvalues\n3-element Array{Complex{Float64},1}:\n  -0.1560621117389876 - 0.12273439561483537im\n -0.15606211173898707 + 0.12273439561483517im\n  0.23169252042880578 - 7.86196165647416e-17im\n\nReferences\n\nAlgorithm 2 in Jarlebring, Michiels Meerbergen, A linear eigenvalue algorithm for the nonlinear eigenvalue problem, Numer. Math, 2012\n\n\n\n\n\n","category":"function"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"For the iar_chebyshev the following compute_y0_cheb method is needed, in order to avoid explicit conversions between the Chebyshev basis and the monimial basis.","category":"page"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"NEPSolver.compute_y0_cheb","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.compute_y0_cheb","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.compute_y0_cheb","text":"y0 = compute_y0_cheb([eltype],nep::NEPTypes.DEP,::Type{ComputeY0ChebPEP},X,Y,M0inv,precomp::AbstractPrecomputeData)\n\nComputes the vector y0 used in iar_chebyshev given by\n\n y_0 = sum_i=1^N T_i-1(Œ≥) x_i - sum_j=1^m A_j left( sum_i=1^N+1 T_i-1(-œÅ tau_j+Œ≥) y_i right )\n\nwhere T(c) is the vector containing T_i(c) as coefficients, where T_i is the i-th Chebyshev polynomial of the first kind.\n\n\n\n\n\ny0 = compute_y0_cheb([eltype],nep::NEPTypes.PEP,::Type{ComputeY0ChebPEP},X,Y,M0inv,precomp::AbstractPrecomputeData)\n\nComputes the vector y0 used in iar_chebyshev given by\n\n y_0 = sum_j=0^d-1 A_j+1 x D^j T(c) - y T(c)\n\nwhere T(c) is the vector containing T_i(c) as coefficients, where T_i is the i-th Chebyshev polynomial of the first kind and D is the derivation matrix in Chebyshev basis.\n\n\n\n\n\ny0 = compute_y0_cheb([eltype],nep::NEPTypes.SPMF_NEP,::Type{ComputeY0ChebPEP},X,Y,M0inv,precomp::AbstractPrecomputeData)\n\nComputes the vector y0 used in iar_chebyshev given by\n\n y_0= sum_j=0^m M^(j)(mu) X b_j left( D_N right) T_N(c) - Y T_N(c)\n\nwhere T(c) is the vector containing T_i(c) as coefficients, where T_i is the i-th Chebyshev polynomial of the first kind and b_j(lambda)=(f_j(0)-f_j(lambda))lambda=flambda0 are divided differences.\n\n\n\n\n\ny0 = compute_y0_cheb([eltype],nep::NEPTypes.NEP,::Type{ComputeY0ChebNEP},X,Y,M0inv,precomp::AbstractPrecomputeData)\n\nComputes the vector y0 used in iar_chebyshev defined as\n\n y_0 =left( sum_i=0^N-1 B left( fracdd theta right) hat T_i(theta) x_i right)(0) - sum_i=0^N T_i(c) y_i\n\nwhere T_i is the i-th Chebyshev polynomial of the first kind, $ \\ hat T_i$ is the i-th Chebyshev polynomial of the first kind for the interval [a,b]. For a generic nep, this quantity is computed by converting polynomials in monomial basis. This procedure may be numerical unstable if many iterations are required. If for the specific nep a closed formula is available, we suggest to overload this function.\n\n\n\n\n\n","category":"function"},{"location":"methods/#TIAR-1","page":"NEP-Solvers","title":"TIAR","text":"","category":"section"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"The Tensor Infinite ARnoldi method.","category":"page"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"tiar","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.tiar","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.tiar","text":"tiar(nep,[maxit=30,][œÉ=0,][Œ≥=1,][linsolvecreator=DefaultLinSolverCreator(),][tolerance=eps()*10000,][neigs=6,][errmeasure,][v=rand(size(nep,1),1),][logger=0,][check_error_every=1,][orthmethod=DGKS,][proj_solve=false,][inner_solver_method=DefaultInnerSolver(),][inner_logger=0])\n\nRun the tensor infinite Arnoldi method on the nonlinear eigenvalue problem stored in nep. This is equivalent to iar, but handles orthogonalization with a tensor representation.\n\nThe target œÉ is the center around which eiganvalues are computed. The value Œ≥ corresponds to scaling and specifying a shift and scaling is effectively the same as the transformation Œª=Œ≥s+œÉ where s is now the eigenvalue parameter. If you want eigenvalues in a disk centered, select œÉ as the center of the disk and Œ≥ as the radius. The vector v is the starting vector for constructing the Krylov space. The orthogonalization method, used in contructing the orthogonal basis of the Krylov space, is specified by orthmethod, see the package IterativeSolvers.jl. The iteration is continued until neigs Ritz pairs have converged. This function throws a NoConvergenceException if the wanted eigenpairs are not computed after maxit iterations. However, if neigs is set to Inf the iteration is continued until maxit iterations without an error being thrown. The parameter proj_solve determines if the Ritz paris are extracted using the Hessenberg matrix (false), or as the solution to a projected problem (true). If true, the method is descided by inner_solver_method, and the logging of the inner solvers are descided by inner_logger, which works in the same way as logger.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> using NonlinearEigenproblems, LinearAlgebra\njulia> nep=nep_gallery(\"dep0\",100);\njulia> v0=ones(size(nep,1));\njulia> Œª,v=tiar(nep;v=v0,tol=1e-5,neigs=3);\njulia> norm(compute_Mlincomb!(nep,Œª[1],v[:,1])) # Is it an eigenvalue?\njulia> Œª    # print the computed eigenvalues\n3-element Array{Complex{Float64},1}:\n -0.1560621147566685 + 0.12273439802763504im\n -0.1560621147566693 - 0.1227343980276357im\n 0.23169243065648332 - 4.699260229885766e-17im\n\n\nReferences\n\nAlgorithm 2 in Jarlebring, Mele, Runborg, The Waveguide Eigenvalue Problem and the Tensor Infinite Arnoldi Method, SIAM J. Scient. computing, 39 (3), A1062-A1088, 2017\n\n\n\n\n\n","category":"function"},{"location":"methods/#Infinite-Lanczos-based-methods-1","page":"NEP-Solvers","title":"Infinite Lanczos based methods","text":"","category":"section"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"The Infinite Bi-Lanczos method.","category":"page"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"infbilanczos","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.infbilanczos","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.infbilanczos","text":"Œªv,V,U=infbilanczos([eltype],nep, nept,[linsolvecreator,][linsolvertcreator,][v,][u,][œÉ,][Œ≥,][tol,][neigs,][errmeasure,][logger,][maxit,][check_error_every])\n\nExecutes the Infinite Bi-Lanczos method on the problem defined by nep::NEP and nept::NEP. nep:NEP is the original nonlinear eigenvalue problem and nept::NEP is its (hermitian) transpose: M(Œª^*)^H.  v and u are starting vectors, œÉ is the shift and Œ≥ the scaling. The iteration is continued until neigs Ritz pairs have converged. This function throws a NoConvergenceException if the wanted eigenpairs are not computed after maxit iterations. However, if neigs is set to Inf the iteration is continued until maxit iterations without an error being thrown. See augnewton for other parameters.\n\nExample:\n\njulia> nep=nep_gallery(\"dep0\");\njulia> A=get_Av(nep); fv=get_fv(nep);\njulia> At=[copy(A[1]'),copy(A[2]'),copy(A[3]')]\njulia> nept=SPMF_NEP(At,fv); # Create the transposed NEP\njulia> Œªv,V=infbilanczos(nep,nept,neigs=3)\njulia> norm(compute_Mlincomb(nep,Œªv[1],V[:,1]))\n\nReferences:\n\nThe infinite bi-Lanczos method for nonlinear eigenvalue problems, S. W. Gaaf and E. Jarlebring, SIAM J. Sci. Comput. 39:S898-S919, 2017, preprint\n\n\n\n\n\n","category":"function"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"The Infinite Lanczos method, for symmetric NEPs","category":"page"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"ilan","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.ilan","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.ilan","text":"ilan(nep,[maxit=30,][œÉ=0,][Œ≥=1,][linsolvecreator=DefaultLinSolverCreator(),][tolerance=eps()*10000,][neigs=6,][errmeasure,][v=rand(size(nep,1),1),][logger=0,][check_error_every=30,][orthmethod=DGKS])\n\nRun the infinite Lanczos method on the symmetric nonlinear eigenvalue problem stored in nep.\n\nThe target œÉ is the center around which eiganvalues are computed. The kwarg errmeasure is a function handle which can be used to specify how the error is measured to be used in termination (default is absolute residual norm). A Ritz pair Œª and v is flagged a as converged (to an eigenpair) if errmeasure is less than tol. The vector v is the starting vector for constructing the Krylov space. The orthogonalization method, used in contructing the orthogonal basis of the  Krylov space, is specified by orthmethod, see the package IterativeSolvers.jl. The iteration is continued until neigs Ritz pairs have converged. This function throws a NoConvergenceException if the wanted eigenpairs are not computed after maxit iterations. However, if neigs is set to Inf the iteration is continued until maxit iterations without an error being thrown.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> using NonlinearEigenproblems, LinearAlgebra\njulia> nep=nep_gallery(\"dep_symm_double\",10);\njulia> v0=ones(size(nep,1));\njulia> Œª,v=ilan(nep;v=v0,tol=1e-5,neigs=3);\njulia> norm(compute_Mlincomb!(nep,Œª[1],v[:,1])) # Is it an eigenvalue?\njulia> Œª    # print the computed eigenvalues\n3-element Array{Complex{Float64},1}:\n 0.04103537900075572 - 1.6342212662372832e-19im\n 0.04103537900077957 - 2.5916996904875994e-19im\n 0.04114919035623714 - 7.9738202040662040e-20im\n\nReferences\n\nAlgorithm 2 in Mele, The infinite Lanczos method for symmetric nonlinear eigenvalue problems, https://arxiv.org/abs/1812.07557, 2018\n\n\n\n\n\n","category":"function"},{"location":"methods/#NLEIGS-1","page":"NEP-Solvers","title":"NLEIGS","text":"","category":"section"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"nleigs","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.nleigs","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.nleigs","text":"nleigs(nep::NEP, Œ£::AbstractVector{Complex{T}})\n\nFind a few eigenvalues and eigenvectors of a nonlinear eigenvalue problem, using the nleigs algorithm.\n\nArguments\n\nnep: An instance of a nonlinear eigenvalue problem.\nŒ£: A vector containing the points of a polygonal target set in the complex plane.\nŒû: A vector containing a discretization of the singularity set.\nlogger: Level of display (0, 1, 2).\nmaxdgr: Max degree of approximation.\nminit: Min number of iterations after linearization is converged.\nmaxit: Max number of total iterations.\ntol: Tolerance for residual.\ntollin: Tolerance for convergence of linearization.\nv: Starting vector.\nerrmeasure: Function for error measure (residual norm). Called with arguments (Œª,v).\nisfunm : Whether to use matrix functions.\nstatic: Whether to use static version of NLEIGS.\nleja: Use of Leja-Bagby points (0 = no, 1 = only in expansion phase, 2 = always).\nnodes: Prefixed interpolation nodes (only when leja is 0 or 1).\nreusefact: Reuse of matrix factorizations (0 = no, 1 = only after converged linearization, 2 = always).\nblksize: Block size for pre-allocation.\nreturn_details: Whether to return solution details (see NleigsSolutionDetails).\ncheck_error_every: Check for convergence / termination every this number of iterations.\n\nSee augnewton for other parameters.\n\nReturn values\n\nŒª: Vector of eigenvalues of the nonlinear eigenvalue problem NLEP inside the target set Œ£.\nX: Corresponding matrix of eigenvectors.\nres: Corresponding residuals.\ndetails: Solution details, if requested (see NleigsSolutionDetails).\n\nExample\n\njulia> nep=nep_gallery(\"dep0\");\njulia> unit_square = float([1+1im, 1-1im, -1-1im,-1+1im])\njulia> (Œª,v)=nleigs(nep,unit_square);\njulia> norm(compute_Mlincomb(nep,Œª[1],v[:,1]))\n2.4522684986758914e-12\njulia> norm(compute_Mlincomb(nep,Œª[2],v[:,2]))\n2.7572460495529512e-12\n\nReferences\n\nS. Guettel, R. Van Beeumen, K. Meerbergen, and W. Michiels. NLEIGS: A class of fully rational Krylov methods for nonlinear eigenvalue problems. SIAM J. Sci. Comput., 36(6), A2842-A2864, 2014.\nNLEIGS Matlab toolbox\n\n\n\n\n\n","category":"function"},{"location":"methods/#Class-specific-methods-1","page":"NEP-Solvers","title":"Class specific methods","text":"","category":"section"},{"location":"methods/#Companion-linearizations-1","page":"NEP-Solvers","title":"Companion linearizations","text":"","category":"section"},{"location":"methods/#","page":"NEP-Solvers","title":"NEP-Solvers","text":"companion\npolyeig","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.companion","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.companion","text":"E,A = companion(nep::PEP);\n\nLinearizes a  polynomial eigenvalue problem (PEP) a to the companion form, as in the paper by Mehrmann and Voss. More precisely, for a k-th degree PEP with n-by-n coefficient matrices, this returns matrices E and A, both kn-by-kn, corresponding to the linearized problem\n\nAx = ŒªEx\n\nExample\n\njulia> pep = nep_gallery(\"pep0\");\njulia> E,A = companion(pep);\njulia> Œª, V = eigen(A,E);\njulia> minimum(svd(compute_Mder(pep,Œª[1])).S)\n2.703104679937224e-12\n\nReferences\n\nV. Mehrmann and H. Voss, Non-linear eigenvalue problems, a challenge for modern eigenvalue methods, GAMM‚ÄêMitteilungen (2004)\n\n\n\n\n\n","category":"function"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.polyeig","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.polyeig","text":"Œª,v = polyeig([eltype],nep::PEP,[eigsolvertype,])\n\nLinearizes a  polynomial eigenvalue problem (PEP) a to the companion form and solves the corresponding linear eigenvalue problem; see companion. The eigsolvertype is optinal can be used to specify how the linear problem is solved; see eig_solve, and EigSolver.\n\nExample\n\njulia> pep = nep_gallery(\"pep0\");\njulia> Œª,V = polyeig(pep);\njulia> minimum(svd(compute_Mder(pep,Œª[1])).S)\n2.1724582040065456e-14\njulia> norm(compute_Mlincomb(pep,Œª[2],vec(V[:,2])))\n1.2210363164200074e-12\n\n\n\n\n\nŒª,v = polyeig([eltype],nep::ChebPEP)\n\nComputes a companion linearization for the NEP represented in a Chebyshev basis, and returns eigenpairs.\n\nExample\n\njulia> using LinearAlgebra\njulia> nep=nep_gallery(\"dep0\");\njulia> chebpep=ChebPEP(nep,9,-3,1,cosine_formula_cutoff=5);\njulia> (Œªv,V)=polyeig(chebpep);\njulia> ii=argmin(abs.(Œªv));\njulia> Œª=Œªv[ii];\njulia> v=V[:,ii];\njulia> norm(compute_Mlincomb(chebpep,Œª,v))\n1.3543968603949142e-14\njulia> # Actually, it's not a bad approx to the original NEP either\njulia> norm(compute_Mlincomb(nep,Œª,v))\n4.326355966047557e-6\n\nSee also ChebPEP.\n\nReferences:\n\nAmiraslani, A., Corless, R. M. & Lancaster, P. \"Linearization of matrix polynomials expressed in poly-nomial bases\" IMA J. Numer. Anal.,29 (2009): 141‚Äì157.\nEffenberger and Kressner. \"Chebyshev interpolation for nonlinear eigenvalue problems.\" BIT Numerical Mathematics 52.4 (2012): 933-951.\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Transformations-1","page":"Transformations","title":"Transformations","text":"","category":"section"},{"location":"transformations/#","page":"Transformations","title":"Transformations","text":"Due to the object oriented way of handle NEPs in NEP-PACK, a NEP-object can be transformed to another NEP-object in a number of ways. There is support for:","category":"page"},{"location":"transformations/#","page":"Transformations","title":"Transformations","text":"variable transformations,\nexpansions, and\ndeflation.","category":"page"},{"location":"transformations/#Change-of-variables-1","page":"Transformations","title":"Change of variables","text":"","category":"section"},{"location":"transformations/#","page":"Transformations","title":"Transformations","text":"shift_and_scale","category":"page"},{"location":"transformations/#NonlinearEigenproblems.NEPTypes.shift_and_scale","page":"Transformations","title":"NonlinearEigenproblems.NEPTypes.shift_and_scale","text":"shift_and_scale(orgnep::NEP;shift=0,scale=1)\n\nTransforms the orgnep by defining a new NEP from the relation T(Œª)=M(scale * Œª+shift) where M is the orgnep. This function tries  to preserve the NEP type, e.g., a shiftandscale operation on an SPMF-object, return an SPMF object. If it cannot preserve the type, it will return a nep of the struct ShiftScaledNEP.\n\nExample\n\njulia> nep0=nep_gallery(\"pep0\")\njulia> œÉ=3; Œ±=10;\njulia> nep1=shift_and_scale(nep0,shift=œÉ,scale=Œ±)\njulia> opnorm(compute_Mder(nep0,Œ±*(4+4im)+œÉ)-compute_Mder(nep1,4+4im))\n8.875435870738592e-12\n\n\n\n\n\n","category":"function"},{"location":"transformations/#","page":"Transformations","title":"Transformations","text":"mobius_transform","category":"page"},{"location":"transformations/#NonlinearEigenproblems.NEPTypes.mobius_transform","page":"Transformations","title":"NonlinearEigenproblems.NEPTypes.mobius_transform","text":"mobius_transform(orgnep::NEP,[,a=1][,b=0][,c=0][,d=1])\n\nTransforms a nep (orgnep) M(Œª)v to a new nep T(Œª)=M((aŒª+b)(cŒª+d)). This function tries to preserve the type such that T and M are of the same NEP-type (see shift_and_scale()). If it cannot be preserved it will return a MobiusTransformedNEP. It is in general advised to try to preserve the type, and the use of MobiusTransformedNEP can considerably slow down NEP-access.\n\nExample\n\njulia> nep0=nep_gallery(\"pep0\")\njulia> a=1; b=3; c=4; d=5;\njulia> nep1=mobius_transform(nep0,a=a,b=b,c=c,d=d);\njulia> s=3;\njulia> opnorm(compute_Mder(nep0,(a*s+b)/(c*s+d))-compute_Mder(nep1,s))\n0.0\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Expansions-1","page":"Transformations","title":"Expansions","text":"","category":"section"},{"location":"transformations/#","page":"Transformations","title":"Transformations","text":"** TODO: This should be renamed, e.g. taylor_exp **","category":"page"},{"location":"transformations/#","page":"Transformations","title":"Transformations","text":"transform_to_pep","category":"page"},{"location":"transformations/#NonlinearEigenproblems.NEPTypes.transform_to_pep","page":"Transformations","title":"NonlinearEigenproblems.NEPTypes.transform_to_pep","text":"transform_to_pep(orgnep::NEP[,d=2])\n\nCompute the truncated (with d terms) Taylor series of the NEP. The output is a PEP.\n\n\n\n\n\n","category":"function"},{"location":"transformations/#","page":"Transformations","title":"Transformations","text":"interpolate","category":"page"},{"location":"transformations/#NonlinearEigenproblems.NEPTypes.interpolate","page":"Transformations","title":"NonlinearEigenproblems.NEPTypes.interpolate","text":"interpolate([T=ComplexF64,] nep::NEP, intpoints::Array)\n\nInterpolates a NEP in the points intpoints and returns a PEP, i.e., a polynomial eigenvalue problem in a monomial basis. See ChebPEP for Chebyshev interpolation. The optional argument T is the type in which the matrices of the PEP should be defined.\n\nSee also ChebPEP.\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Deflation-1","page":"Transformations","title":"Deflation","text":"","category":"section"},{"location":"transformations/#","page":"Transformations","title":"Transformations","text":"A NEP can be transformed to another NEP by extending the problem in a way that it essentially removes eigenvalues. This type of deflation is described on the manual page for deflation.","category":"page"},{"location":"linsolvers/#Linear-solvers-1","page":"Linear solvers","title":"Linear solvers","text":"","category":"section"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"Most NEP-solvers require","category":"page"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"the solution of linear system of equations, or\nthe solution of a standard eigenvalue problem.","category":"page"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"The user can specify which linear solver or eigenvalue solver he/she wants to use. It is also possible to use external or user-defined solvers.","category":"page"},{"location":"linsolvers/#Linear-system-of-equations-1","page":"Linear solvers","title":"Linear system of equations","text":"","category":"section"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"As a user, you can provide a creator object to many NEP-solvers via the keyword argument linsolvercreator. The creator object corresponds to one (or several) linear system solvers. By default, DefaultLinSolverCreator is used which tries to determine an appropriate linear solver based on the NEP-type. In the next section, we list the default linear solvers.","category":"page"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"If you wish to define your own linear solver, you need to define your own type inheriting from LinSolver as well as a LinSolverCreator. See the documenation for LinSolver and the tutorial on linear solvers.","category":"page"},{"location":"linsolvers/#LinSolver-objects-and-creators-1","page":"Linear solvers","title":"LinSolver-objects and creators","text":"","category":"section"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"FactorizeLinSolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.FactorizeLinSolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.FactorizeLinSolver","text":"struct FactorizeLinSolver <: LinSolver\n\nThis represents the linear solver associated with julia factorize(). See LinSolver and FactorizeLinSolverCreator for examples.\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"FactorizeLinSolverCreator","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.FactorizeLinSolverCreator","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.FactorizeLinSolverCreator","text":"FactorizeLinSolverCreator(;umfpack_refinements,max_factorizations,nep,precomp_values)\n\nFactorizeLinSolverCreator-objects can instantiate FactorizeLinSolver objects via the create_linsolver function.\n\nThe FactorizeLinSolver is based on factorize-calls. The time point of the call to factorize can be controlled by parameters to FactorizeLinSolverCreator:\n\nBy default, the factorize call is carried out by the instantiation of the FactorizeLinSolver, i.e., when the NEP-solver calls create_linsolver.\nYou can also precompute the factorization, at the time point when you instantiate FactorizeLinSolverCreator. If you set precomp_values::Vector{Number} to a non-empty vector, and set nep kwarg, the factorization (of all Œª-values in the precomp_values) will be computed  when the FactorizeLinSolverCreator is instantiated. If the NEP-solver calls a create_linsolver with a Œª-value from that vector, the factorization will be used (otherwise it will be computed).\n\nFurther recycling is possible. If the variable max_factorizations is set to a positive value, the object will store that many factorizations for possible reuse. Every lin_solve-call then computes a factorization, unless a lin_solve-call for that Œª has been computed earlier. This procedure can at most store max_factorization (which can be set Inf).\n\nSee also: FactorizeLinSolver, create_linsolver\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"BackslashLinSolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.BackslashLinSolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.BackslashLinSolver","text":"struct BackslashLinSolver <: LinSolver\n\nThis represents a linear solver corresponding to the backslash operator (no pre-factorization).\n\nSee also: LinSolver and BackslashLinSolverCreator\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"BackslashLinSolverCreator","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.BackslashLinSolverCreator","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.BackslashLinSolverCreator","text":"struct BackslashLinSolverCreator <: LinSolverCreator\n\nCreator to for the BackslashLinSolver, i.e., usage of backslash to make linear solves. Specify objects of this type if you want the solver to use backslash.\n\nSee also: BackslashLinSolver, create_linsolver\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"GMRESLinSolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.GMRESLinSolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.GMRESLinSolver","text":"struct GMRESLinSolver <: LinSolver\n\nThis represents a solver done with the julia GMRES implementation.\n\nSee also: LinSolver, GMRESLinSolverCreator\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"GMRESLinSolverCreator","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.GMRESLinSolverCreator","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.GMRESLinSolverCreator","text":"GMRESLinSolverCreator(;kwargs...)\n\nThis is the creator for the GMRES-method. Instantiate this object if you want to use GMRES as your linear system solver. The kwargs are stored and used as keyword arguments in the call to gmres. See list of keyword in the IterativeSolvers.jl manual.\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"DefaultLinSolverCreator","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.DefaultLinSolverCreator","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.DefaultLinSolverCreator","text":"DefaultLinSolverCreator\n\nThis is the default linear solver if no other is specified (for most methods). It is a FactorizeLinSolverCreator.\n\nSee also: LinSolver, create_linsolver, lin_solve, FactorizeLinSolverCreator, FactorizeLinSolver\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/#Advanced-usage-1","page":"Linear solvers","title":"Advanced usage","text":"","category":"section"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"LinSolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.LinSolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.LinSolver","text":"abstract type LinSolver\n\nStructs inheriting from this type are able to solve linear systems associated with a NEP, for a specific Œª-value. The most common are direct solvers such as FactorizeLinSolver, BackslashLinSolver and iterative solvers such as GMRESLinSolver.\n\nThe LinSolver objects are usually created by the NEP-algorithms through creator functions, which are passed as parameters.\n\nExample\n\nThe most common usecase is that you want to pass a linsolvercreator-function as a parameter to the NEP-algorithm. This example shows how you can use solvers based on backslash or factorize(). In the example, BackslashLinSolver does not exploit that the system matrix remains the same throughout the algorithm and is therefore slower.\n\njulia> nep=nep_gallery(\"qdep0\");\njulia> using BenchmarkTools\njulia> v0=ones(size(nep,1));\njulia> @btime Œª,v=quasinewton(nep,Œª=-1,v=v0, linsolvercreator=DefaultLinSolverCreator());\n  199.540 ms (4929 allocations: 59.83 MiB)\njulia> @btime Œª,v=quasinewton(nep,Œª=-1,v=v0, linsolvercreator=BackslashLinSolverCreator());\n  1.632 s (6137 allocations: 702.85 MiB)\n\nExample\n\nThe LinSolvers are constructed for extendability. This example creates our own LinSolver which uses an explicit formula for the inverse if the NEP has dimension 2x2.\n\nCreate the types and a creator.\n\njulia> using LinearAlgebra\njulia> struct MyLinSolver <: LinSolver\n   M::Matrix{ComplexF64}\nend\njulia> function my_linsolvercreator(nep,Œª)\n   M=compute_Mder(nep,Œª);\n   return MyLinSolver(M);\nend\n\nExplicit import lin_solve to show how to solve a linear system.\n\njulia> import NonlinearEigenproblems.LinSolvers.lin_solve;\njulia> function lin_solve(solver::MyLinSolver,b::AbstractVecOrMat;tol=0)\n   M=solver.M;\n   invM=(1/(det(M)))*[M[2,2] -M[1,2];-M[2,1] M[1,1]]\n   return invM*b\nend\njulia> nep=SPMF_NEP([[1.0 3.0; 4.0 5.0], [2.0 1.0; -1 2.0]], [S->S^2,S->exp(S)])\njulia> Œª,v=quasinewton(nep,Œª=-1,v=[1;1],linsolvercreator=my_linsolvercreator);\n\nSee also: lin_solve, FactorizeLinSolver, FactorizeLinSolver, DefaultLinSolverCreator, BackslashLinSolver, BackslashLinSolverCreator, GMRESLinSolver, GMRESLinSolverCreator\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"lin_solve","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.lin_solve","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.lin_solve","text":"lin_solve(solver::LinSolver, b::AbstractVecOrMat; tol=0)\n\nThis function solves the linear system represented in solver::LinSolver with a right-hand side b. The tol kwarg is controlling how accurate the linear system needs to be solved. A NEP-algorithm will call this solver every time a linear system associated with M(Œª) needs to be solved.\n\nThis function must be overloaded if a user wants to define their own way of solving linear systems. See LinSolver for examples.\n\n\n\n\n\n","category":"function"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"create_linsolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.create_linsolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.create_linsolver","text":"create_linsolver(creator::LinSovlerCreator,nep,Œª)\n\nCreates a LinSolver instance for the nep corresponding which is evaluated in Œª. The type of the output is decided by dispatch and the type of the LinSolverCreator.\n\nSee also: LinSolver, FactorizeLinSolverCreator, BackslashLinSolverCreator, DefaultLinSolverCreator, GMRESLinSolverCreator.\n\n\n\n\n\n","category":"function"},{"location":"linsolvers/#Standard-eigenvalue-problems-1","page":"Linear solvers","title":"Standard eigenvalue problems","text":"","category":"section"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"Some NEP-algorithms need to solve an associated linear eigenvalue problem, associated with M(Œª). We provide the possibility to use Julia-native eigenvalue solvers, and an interface which allows you to define your own solver. By default, DefaultEigSolver is specified, which tries to determine an appropriate eigenvalue solver based on the NEP-type.","category":"page"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"tip: Tip\nThe NEP-solvers mslp and sgiter require eigenvalue solvers and take the keyword argument eigsolver.","category":"page"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"DefaultEigSolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.DefaultEigSolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.DefaultEigSolver","text":"struct DefaultEigSolver <: EigSolver\n\nA linear eigenvalueproblem solver that calls checks for sparsity and accordingly assigns an appropriate solver.\n\nSee also: EigSolver, eig_solve, NativeEigSolver, NativeEigSSolver\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"EigenEigSolver","category":"page"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"ArnoldiEigSolver","category":"page"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"EigSolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.EigSolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.EigSolver","text":"abstract type EigSolver\n\nStructs inheriting from this type are able to solve linear eigenvalue problems arising in certain methods, such as, e.g., mslp, sgiter, and polyeig.\n\nThe EigSolver objects are passed as types to the NEP-algorithms, which uses it to dispatch the correct version of the function eig_solve.\n\nExample\n\nThe most common usecase is that you do not want to specify anything in particular, since the DefaultEigSolver will use a dense or a sparse method depending on you problem. However, this example shows how you can force mslp to use the sparse solver.\n\njulia> nep=nep_gallery(\"qdep0\");\njulia> Œª,v = mslp(nep, eigsolvertype=NativeEigSSolver);\njulia> norm(compute_Mlincomb(nep,Œª,v))\n1.0324139764567768e-15\n\nExample\n\nThe EigSolvers are constructed for extendability. As an illustartion this example creates a naive EigSolver which casts the problem to a standard linear eigenproblem and calls the built-in function to solve it.\n\nCreate the types and a creator.\n\njulia> struct MyEigSolver <: EigSolver\n   A\n   E\n   function MyEigSolver(A,E)\n      return new(A,E)\n   end\nend\n\njulia> import NonlinearEigenproblems.LinSolvers.eig_solve;\njulia> function eig_solve(solver::MyEigSolver;nev = 1, target = 0)\n   M = solver.E \\ solver.A\n   eig = eigen(M)\n   i = argmin(abs.(eig.values))\n   return eig.values[i], eig.vectors[:,i]\nend\njulia> nep=nep_gallery(\"dep0\", 50);\njulia> Œª,v = mslp(nep, eigsolvertype=MyEigSolver, tol=1e-5);\njulia> norm(compute_Mlincomb(nep,Œª,v))\n3.0777795031319117e-10\n\nSee also: eig_solve, DefaultEigSolver, NativeEigSolver, NativeEigSSolver, eig_solve\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/#","page":"Linear solvers","title":"Linear solvers","text":"eig_solve","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.eig_solve","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.eig_solve","text":"eig_solve(solver::EigSolver; [nev,] [target,])\n\nThis function solves the linear eigenvalue problem represented in solver::EigSolver. The nev kwarg is controlling the number of eigenvalues aimed for, and target specifies around which point the eigenvalues are computed. The former has a defalut value equalt to the seize of the problem, and the latter has a defalut value 0.\n\nReturn values are of the form (Vector, Matrix) where the former contains the eigenvalues and the latter the eigenvectors.\n\nThis function must be overloaded if a user wants to define their own way of solving linear eigenvalue problems. See EigSolver for examples.\n\n\n\n\n\n","category":"function"},{"location":"tutorial_nano1/#Tutorial:-Problem-from-nanophotonics-1","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial: Problem from nanophotonics","text":"","category":"section"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"One of the key challanges within the field of nanophotonics is the need to be able to compute the modes of frequency-despersive structures in a reliable and efficient way. The frequency (i.e. eigenvalue) dependency can be viewed as a nonlinearity and therefore naturally leads to nonlinear eigenvalue problems.","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"This tutorial is based on a research preprint where a model is set up and solved with SLEPc. An associated repository of code is available which should be used in combination with gmsh and onelab. Credit for the discretization and application should go to the authors of the paper, in particular Guillaume Dem√©sy for providing the model files online.","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"We will use the model files and onelab for that simulation and reproduce computational results using NEP-PACK. ","category":"page"},{"location":"tutorial_nano1/#Part-1:-Setup-the-matrices-1","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Part 1: Setup the matrices","text":"","category":"section"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"You need to download the code with the model of the frequency-dispersive media here. You also need to install ONELAB from http://onelab.info/.","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"We need the matrices generated by this model, which are not saved to disk by default. A small modification of one of the project files is needed. You need to modify the NonLinearEVP.pro: On the line before the EigenSolve specification for the res_NEP_E:","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"Print[M1] // Add this line\nEigenSolve[M1,neig,eig_target_re,eig_target_im,EigFilter[],\n     { {1}, {-eps_oo_1,gam_1*eps_oo_1, -om_d_1^2,0}, {-1,0,0} },\n     { {1}, {1,-gam_1},                              {1} } ];","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"That is, you should add the text Print[M1] (in the current version) before line 354.","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"After you do this modification, load the model and click \"run\" in the Gmsh tool, you will obtain files in the current directory containing the FEM-discretizations needed to set up the problem (file_mat_MX.m.bin).","category":"page"},{"location":"tutorial_nano1/#Part-2:-Implementation-in-NEP-PACK-1","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Part 2: Implementation in NEP-PACK","text":"","category":"section"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"The NEP in this problem has the structure","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"M(Œª)=A_1+frac-varepsilon_inftyŒª^3+varepsilon_inftygamma_d Œª^2-omega_d^2ŒªŒª-gamma_dA_2-Œª^2A_3","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"The constants are given in the project file and we set them in our julia code:","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"a_lat=50;\ncel      = a_lat/(2*pi);\nnrm     = a_lat/(2*pi*cel);\nom_d_1         = om_d_1        / nrm;\ngam_1          = gam_1         / nrm;","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"The NEP in this example can be conveniently expressed as a SPMF_NEP, where the first function is constant, the second term is a rational function and the third is a quadratic term. We define them in a matrix function sense:","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"f1=s-> one(s) #\nf2=s-> (s-gam_1*one(s))\\(-eps_oo_1*s^3+gam_1*eps_oo_1*s^2-om_d_1^2*s)\nf3=s-> -s^2","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"If you have carried out Part 1, you should have the sparse discretization matrices available. They are stored in the PETSc-binary format. NEP-PACK contains functionality to load some PETSc binary files (see also PETScBinary). Most importantly the function Gallery.naive_petsc_read which gives us a sparse matrix.","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"Suppose gmsh_files is a path to the bin-files. These commands load the matrices","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"julia> A3=Gallery.naive_petsc_read(joinpath(gmsh_files,\"file_mat_M15.m.bin\")); # Switched order is intentional\njulia> A2=Gallery.naive_petsc_read(joinpath(gmsh_files,\"file_mat_M16.m.bin\"));\njulia> A1=Gallery.naive_petsc_read(joinpath(gmsh_files,\"file_mat_M17.m.bin\"));","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"The SPMF is created directly","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"julia> nep=SPMF_NEP([A1,A2,A3], [f1,f2,f3]);","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"We can now directly apply a method of choice. In this case we solve it with the tensor infinite Arnoldi method (tiar)  with a shift/target the same as in the project files","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"julia> (Œª,V)=tiar(nep,œÉ=0.00243604+0.366703im,logger=1,neigs=10,maxit=100);\n-\n--\n=--\n+---\n+----\n+-----\n+------\n+-------\n+--------\n+---------\n+----------\n+==---------\n+++----------\n+++=----------\n++++-----------\n++++------------\n++++-------------\n++++--------------\n++++---------------\n++++----------------\n++++==---------------\n++++++----------------\n++++++-----------------\n++++++=-----------------\n++++++=------------------\n+++++++-------------------\n+++++++--------------------\n+++++++---------------------\n+++++++----------------------\n+++++++==---------------------\n+++++++==----------------------\n+++++++++=----------------------\n+++++++++=-----------------------\n++++++++++------------------------\njulia> Œª\n10-element Array{Complex{Float64},1}:\n 0.002436044429913607 + 0.3667026531004412im\n 0.001175454247612957 + 0.3748476897696621im\n 0.006531655269175296 + 0.3736695833524133im\n 0.013279531609677153 + 0.37899563698023087im\n  0.04259449677920191 + 0.38730647107316im\n  0.04388349538759248 + 0.39266023012447837im\n 0.007774845736605659 + 0.25923501436468327im\n  0.09285578050590135 + 0.41819550232817293im\n  0.09374197960056296 + 0.41522753073470614im\n  0.01578630143214552 + 0.49172628247971106im","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"Each row in the logger printout of tiar corresponds to an iteration. The sign - corresponds to an unconverged eigenvalue, + corresponds to a converged eigenvalue and = corresponds to an eigenvalue which is almost converged (interpreted as a factor 10 from the convergence criteria). The eigenvalue  0.007774845736605659 + 0.25923501436468327im which can be found in the printout above, is reported by the default setting in the gmsh tool applied to the model files.","category":"page"},{"location":"tutorial_nano1/#","page":"Tutorial 8 (gmsh + nanophotonics)","title":"Tutorial 8 (gmsh + nanophotonics)","text":"(Image: To the top)","category":"page"},{"location":"tutorial_matlab1/#Tutorial:-Solving-NEP-defined-in-MATLAB-1","page":"Tutorial 6 (MATLAB)","title":"Tutorial: Solving NEP defined in MATLAB","text":"","category":"section"},{"location":"tutorial_matlab1/#A-problem-defined-in-MATLAB-1","page":"Tutorial 6 (MATLAB)","title":"A problem defined in MATLAB","text":"","category":"section"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"MATLAB is the de-facto standard language for many tasks in scientific computing. If you have a NEP defined in MATLAB, you can quite easily use the NEP-solvers of this package. Below is a description of two ways to solve nonlinear eigenvalue problems defined in MATLAB. There is a cost in terms of efficiency to define your problem in MATLAB, due to overhead associated with communication between the MATLAB and Julia processes. Very large scale problems are recommended to be defined directly in Julia.","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"note: Note\nTo work with NEPs defined in MATLAB you need to have MATLAB installed on your computer. We use the MATLAB interoperability package to link Julia execution with MATLAB execution.","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"Suppose you have the following NEP in MATLAB","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"M(lambda)=A_0+lambda A_1+exp(lambda A_2)","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"where A_1A_2A_3 are martices and exp the matrix exponential. The problem can be defined in MATLAB as follows. This is the contents of the file compute_derivative_k.m:","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"function Z=compute_derivative_k(s,k)\n     randn('seed',0);\n     n=10;\n     A0=randn(n,n); A1=randn(n,n);\n     Z=zeros(n,n);\n     if (k==0)\n         Z=A0+s*A1;\n     end\n     if (k==1)\n         Z=A1;\n     end\n     Z=Z+(A1^k)*expm(s*A1);\nend","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"The function which computes derivative k evaluted in the point s. We assume in the following that the file compute_derivative_k.m is located in the current directory.","category":"page"},{"location":"tutorial_matlab1/#Approach-1:-Implementation-in-NEP-PACK-(using-Mder_NEP)-1","page":"Tutorial 6 (MATLAB)","title":"Approach 1: Implementation in NEP-PACK (using Mder_NEP)","text":"","category":"section"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"The easiest way to create a NEP which is only defined by its derivative computation is by the helper type Mder_NEP.","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"using NonlinearEigenproblems, MATLAB\nnep=Mder_NEP(10,(s,der) -> mat\"compute_derivative_k($s,double($der))\");","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"The NEP can now be approached with many of the methods in the package, e.g., with a contour integral method:","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"julia> (Œª,V)=contour_beyn(nep, radius=0.6, k=8);\njulia> Œª\n2-element Array{Complex{Float64},1}:\n 0.1711954796771912 - 6.401495587242332e-15im\n 0.1547216302712358 - 0.16631220583083045im   ","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"The first argument of the Mder_NEP instantiation is the size of the NEP. The instantiation of the Mder_NEP creates a NEP-object only defined by its matrix derivative functions, given in the call-back function specified by the second argument. In this case, the the function calls a MATLAB process (running in the background completely hidden from the Julia user) and requests a execution of compute_derivate_k with the given arguments. After executing the MATLAB-call, the MATLAB-process sends the matrix back to Julia. In other words, we have coupled the derivative computation of the NEP with a call to MATLAB. More precisely, every call to the compute_Mder function leads to a call to the created MATLAB function. Compare:","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"julia> compute_Mder(nep,0.1+0.2im)\n10√ó10 Array{Complex{Float64},2}:\n   2.15543-0.101289im     -1.4933-0.0817057im  ‚Ä¶    0.220658-0.313894im    0.371533+0.544535im\n  0.751339+0.213974im    0.532557+0.359256im         0.58971-0.135805im    -2.65352-0.308557im\n -0.177809-0.383021im     1.46944+0.374974im        0.965219+0.140168im    0.979515-0.603281im\n  0.204312-0.300014im   -0.576669+0.630099im         1.94032+0.43922im    -0.803364+0.652243im\n -0.378807+0.511258im    0.590185+0.0812181im      -0.381726-0.138047im     1.30005+0.562022im\n   1.58041-0.266624im   -0.347895+0.292268im   ‚Ä¶  -0.0826327+0.155039im   -0.691359+0.340299im\n  0.105255+0.0940046im  -0.338352-0.443379im        0.546516-0.062307im    0.445814-0.648929im\n   1.47467-0.646341im    -1.36607-0.195403im         1.02226-0.0228401im    1.14153+0.576545im\n  0.182295-0.143594im    -1.06099+0.492347im        -0.41297-0.409332im   -0.322912-0.219094im\n  0.658504-0.190844im     1.21896+0.280606im       -0.563413-0.073228im     1.25092-0.418521im","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"with the MATLAB call:","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":">> M=compute_derivative_k(0.1+0.2i,0);\n>> M(1:3,1:3) % I don't want to see the whole matrix\nans =\n   2.1554 - 0.1013i  -1.4933 - 0.0817i   0.1131 + 0.0836i\n   0.7513 + 0.2140i   0.5326 + 0.3593i  -1.0211 - 0.5134i\n  -0.1778 - 0.3830i   1.4694 + 0.3750i   0.2180 + 0.1720i","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"You can verify that the output of the call to the contour_beyn-method is a solution directly in MATLAB:","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":">> s = 0.1547216302712358 - 0.16631220583083045i; % copied from the output above (remember: 1im -> 1i)\n>> M=compute_derivative_k(s,0);\n>> min(svd(M)) % Matrix is singular if s is a solution\nans =\n   1.5239e-15","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"NEP-objects in NEP-PACK are defined from compute-functions (as we describe in NEPTypes) and in this case we only defined the derivative computation function compute_Mder. Note that the Mder_NEP-type provides default implementations of compute_Mlincomb as well as compute_MM (by wrapping calls to compute_Mder) in a way that is hidden from the user, such that we can still use algorithms based on those compute functions. More efficiency can be obtained if these compute functions are also implemented, e.g., by a different MATLAB-function.","category":"page"},{"location":"tutorial_matlab1/#Approach-2:-Implementation-in-NEP-PACK-(using-new-type)-1","page":"Tutorial 6 (MATLAB)","title":"Approach 2: Implementation in NEP-PACK (using new type)","text":"","category":"section"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"We illustrate the extendability of the package by defining our own type, which again uses the MATLAB-package in the background.","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"note: Note\nThe process is also described in the BEM tutorial.","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"The size is hardcoded in this example, so we can define a new type of the specific size:","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"struct MATLABNEP <: NEP\nend\nBase.size(nep::MATLABNEP) = (10,10)\nBase.size(nep::MATLABNEP,::Int) = 10","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"Initiate the MATLAB package and prepare to integrate with NEP-PACK:","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"using MATLAB; # requires MATLAB to be installed\nmat\"addpath('.')\" # Add path to your m-file\nimport NonlinearEigenproblems.compute_Mder;\nimport NonlinearEigenproblems.compute_Mlincomb;\nimport NonlinearEigenproblems.compute_Mlincomb_from_Mder;","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"In this example, the problem is only provided by a function to compute derivatives of M, which we specify by defining a  compute_Mder function. We also specify that linear combinations of derivatives should be computed by calling compute_Mder in the naive way:","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"function compute_Mder(::MATLABNEP,s::Number,der::Integer=0)\n    return mat\"compute_derivative_k(double($s),double($der))\"\nend\ncompute_Mlincomb(nep::MATLABNEP,Œª::Number,V::AbstractVecOrMat, a::Vector) = compute_Mlincomb_from_Mder(nep,Œª,V,a)\ncompute_Mlincomb(nep::MATLABNEP,Œª::Number,V::AbstractVecOrMat) = compute_Mlincomb(nep,Œª,V, ones(eltype(V),size(V,2)))","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"Now you can instantiate the NEP and use your favorite NEP-solver, in this case we use newtonqr.","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"julia> nep=MATLABNEP();\njulia> (Œª,v)=newtonqr(nep,Œª=-3,logger=1,maxit=30,v=ones(10));\niter 1 err:1.033593309412195 Œª=-3.0 + 0.0im\niter 2 err:0.3059246224011592 Œª=0.83641207310996 + 0.0im\niter 3 err:0.6000405834026614 Œª=-1.7728647881500432 + 0.0im\niter 4 err:0.07375061614602237 Œª=-0.7800560594951582 + 0.0im\niter 5 err:0.0093516562758152 Œª=-0.8707521093182906 + 0.0im\niter 6 err:8.954564848847882e-5 Œª=-0.8840785307305598 + 0.0im\niter 7 err:7.446596609664408e-9 Œª=-0.88420751056806 + 0.0im\niter 8 err:1.0942739518352825e-15 Œª=-0.884207521294992 + 0.0im","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"The residual is small and we have a solution","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"julia> using LinearAlgebra\njulia> norm(compute_Mlincomb(nep,Œª,v))/norm(v)\n1.0942739518352825e-15","category":"page"},{"location":"tutorial_matlab1/#","page":"Tutorial 6 (MATLAB)","title":"Tutorial 6 (MATLAB)","text":"(Image: To the top)","category":"page"},{"location":"gallery/#Gallery-1","page":"Gallery","title":"Gallery","text":"","category":"section"},{"location":"gallery/#","page":"Gallery","title":"Gallery","text":"NEP-PACK provides a way to access applications in order to easily improve and compare algorithms on realistic problems. Below you will find a description of:","category":"page"},{"location":"gallery/#","page":"Gallery","title":"Gallery","text":"Standard native gallery. This gallery provides are accessed typically through the function call nep=nep_gallery(str::String) and returns a NEP-object with efficient compute-functions. The str is an identifier for the problem.\nBerlin-Manchester problem collection. You can access problems from this MATLAB-collection by the call nep=nep_gallery(NLEVP_NEP,str::String), where str is the identified in the MATLAB-package. This requires that you have MATLAB and the problem collection installed.\nExtra problems. We provide careful implementations of certain large-scale problems which are too large to include in the main gallery.","category":"page"},{"location":"gallery/#","page":"Gallery","title":"Gallery","text":"julia> nep=nep_gallery(\"dep0\")\njulia> Œª,v=newton(nep)\n(-0.3587189459686265 + 0.0im, Complex{Float64}[0.284742+0.0im, -0.143316+0.0im, 0.278378+0.0im, -0.5009+0.0im, -0.613634+0.0im])\njulia> norm(compute_Mlincomb(nep,Œª,v))\n4.718447854656915e-16","category":"page"},{"location":"gallery/#Standard-native-gallery-1","page":"Gallery","title":"Standard native gallery","text":"","category":"section"},{"location":"gallery/#","page":"Gallery","title":"Gallery","text":"nep_gallery(::String)","category":"page"},{"location":"gallery/#NonlinearEigenproblems.Gallery.nep_gallery-Tuple{String}","page":"Gallery","title":"NonlinearEigenproblems.Gallery.nep_gallery","text":" nep=nep_gallery(name)\n nep=nep_gallery(name,params)\n nep=nep_gallery(name,params;kwargs)\n\nCollection of nonlinear eigenvalue problems. Returns a NEP object from a gallery of examples of nonlinear eigenvalue problems. The parameter name decides which NEP.\n\nSupported problems:\n\nThe following list describes the NEP with a certain name and the associated parameters (params) and keyword arguments (kwargs), if any.\n\n\ndep0   Create a random delay eiganvalue problem with one delay tau = 1.\n  One optional params determining the size (default = 5)\ndep0_sparse\n  Create a random delay eiganvalue problem with sparse matrices and one delay tau = 1.\n  Two optional params determining the size (default = 5) and the fill (default = 0.25)\ndep0_tridiag\n  Create a random delay eiganvalue problem with sparse tridiaognal matrices and one delay tau = 1.\n  One optional params determining the size (default = 100)\ndep_symm_double\n  Create delay eiganvalue problem with double eigenvalues and sparse symmetric matrices and one delay tau = 1.\n  Examle from H. Voss and M. M. Betcke, Restarting iterative projection methods for Hermitian nonlinear eigenvalue problems with minmax property, Numer. Math., 2017\n  One optional params determining the size (default = 100)\ndep_double\n  Create problem with a double non-semisimple eigenvalue in Œª=3œÄi.\n  Example from E. Jarlebring, Convergence factors of Newton methods for nonlinear eigenvalue problems, LAA, 2012\ndep1\n  A delay eigenvalue problem with one eigenvalue equal to one.\npep0\n  Create a random polynomial eigenvalue problem.\n  One optional params determining the size (default = 200)\npep0_sym\n  Creates a random symmetric polynomial eigenvalue problem.\n  One optional params determining the size (default = 200)\npep0_sparse\n  Creates a random polynomial eigenvalue problem with sparse matrices.\n  Two optional params determining the size (default = 200) and the fill (default = 0.03)\nreal_quadratic\n  Creates a quadratic problem with real eigenvalues.\n        Four smallest eigenvalues of the problem:\n        -2051.741417993845\n        -182.101627437811\n        -39.344930222838\n        -4.039879577113\ndep_distributed\n  Creates the NEP associated with example in E. Jarlebring and W. Michiels and K. Meerbergen,   The infinite Arnoldi method and an application to time-delay systems with distributed delays,   Delay Systems - Methods, Applications and New Trends, 2012.\n       Some correct eigenvalues:        -0.400236388049641 + 0.970633098237807i,\n       -0.400236388049641 - 0.970633098237807i,\n       2.726146249832675 + 0.000000000000000i,\n       -1.955643591177653 + 3.364550574688863i,\n       -1.955643591177653 - 3.364550574688863i,\n       4.493937056300693 + 0.000000000000000i,\n       -1.631513006819252 + 4.555484848248613i,\n       -1.631513006819252 - 4.555484848248613i,\n       -1.677320660400946 + 7.496870451838560i,\n       -1.677320660400946 - 7.496870451838560i\nqdep0 \n  Quadratic delay eigenvalue problem in S. W. Gaaf and E. Jarlebring, The infinite Bi-Lanczos method for   nonlinear eigenvalue problems, SIAM J. Sci. Comput., 2017\nqdep1 \n  Quadratic delay eigenvalue problem in E. Jarlebring and W. Michiels and K. Meerbergen,   A linear eigenvalue algorithm for the  nonlinear eigenvalue problem, Numer. Math., 2011\nqep_fixed_eig\n  A quadratic eigenvalue problem with chosen eigenvalues.\n  Two optional params determining the size (default = 5)   and a vector containing the eigenvalues (default = randn)\nneuron0\n  A DEP that stems from L. P. Shayer and S. A. Campbell, Stability, bifurcation and multistability   in a system of two coupled neurons with multiple time delays,   SIAM J. Applied Mathematics, 2000. It is also a benchmark example in DDE-BIFTOOL\nschrodinger_movebc \n  This NEP stems from the discretization of a Schr√∂dinger equation as described in the NEP-PACK online tutorial. The nonlinearity contains sinh(), cosh() and sqrt(). The optional parameters are size of discretization n  and domain and potential description L0,L1,Œ± and V0.\nbeam\n  The DEP modelling a beam with delayed stabilizing feedback described in R. Van Beeumen, E. Jarlebring, and W. Michiels,   A rank-exploiting infinite Arnoldi algorithm for nonlinear eigenvalue problems, 2016.\n  The A1-term has rank one.\n  One optional params which is the size of the matrix (defalut = 100)\nsine \n  The NEP formed by the sum of a polynomial and a sine-function in \"A rank-exploiting infinite Arnoldi   algorithm for nonlinear eigenvalue problems\", R. Van Beeumen, E. Jarlebring and W. Michiels, 2016. The sine-term has rank one.\nThe MATLAB-package \"NLEVP: A Collection of Nonlinear Eigenvalue Problems, ACM Transactions on Mathematical Software 39(2), January 2011,   T. Betcke, N. J. Higham, V. Mehrmann, Ch. Schr√∂der, F. Tisseur\" provides a number of benchmark problems for NEPs.   These are available in NEP-PACK in two different ways. We have native implementations of some problems (referred to as nlevp_native_)   and the separate GalleryNLEVP. The native implementation is preferred since the GalleryNLEVP   interfaces with MATLAB and is therefore considerably slower.\nnlevp_native_gun\n  The benchmark problem from the NLEVP-collection called \"gun\", represented in the native NEP-PACK format.   B.-S. Liao, Z. Bai, L.-Q. Lee, and K. Ko. Nonlinear Rayleigh-Ritz iterative method for solving large scale   nonlinear eigenvalue problems.  Taiwan. Journal of Mathematics, 14(3):869‚Äì883, 2010\nnlevp_native_cd_player\n  The benchmark problem from the NLEVP-collection called \"cd_player\", represented in the native NEP-PACK format.   Y. Chahlaoui, and P. M. Van Dooren, Benchmark examples for model reduction of linear time-   invariant dynamical systems. In Dimension Reduction of Large-Scale Systems, P. Benner, V. Mehrmann,   and D. C. Sorensen, Eds. Lecture Notes in Computational Science and Engineering Series, vol. 45.   Springer-Verlag, Berlin, 380‚Äì392, 2005.\n  and\n  P. M. R. Wortelboer, M. Steinbuch, and  O. H. Bosgra, Closed-loop balanced reduction with   application to a compact disc mechanism. In Selected Topics in Identification, Modeling and Control.   Vol. 9. Delft University Press, 47‚Äì58, 1996.\n  and\n  W. Draijer, M. Steinbuch, and  O. H. Bosgra, Adaptive control of the radial servo system of a   compact disc player. Automatica 28, 3, 455‚Äì462. 1992.\nnlevp_native_fiber  \n  The benchmark problem from the NLEVP-collection called \"fiber\", represented in the native NEP-PACK format.   One of terms in this problem is approximated by interpolation, and may not always coincide with the benchmark.   L. Kaufman, Eigenvalue problems in fiber optic design. SIAM J. Matrix Anal. Appl. 28, 1, 105‚Äì117, 2006.\n  and\n  X. Huang, Z. Bai, and Y. Su, Nonlinear rank-one modification of the symmetric eigenvalue problem. J. Comput. Math. 28, 2, 218‚Äì234, 2010\nnlevp_native_hadeler\n  The benchmark problem from the NLEVP-collection called \"hadeler\", represented in the native NEP-PACK format. The problem is of the form M(Œª)=(e^Œª-1)B+A0+A2Œª^2. \n  Hadeler K.  P.  1967.  Mehrparametrige  und  nichtlineare  Eigenwertaufgaben. Arch.  Rational  Mech. Anal. 27, 4, 306‚Äì328.\nnlevp_native_pdde_stability\n  The benchmark problem from the NLEVP-collection called \"pdde_stability\", represented in the native NEP-PACK format.   This problem is a quadratic eigenvalue with arbitrary given size n. See   E. Jarlebring, The Spectrum of Delay-Differential Equations:   Numerical Methods, Stability and Perturbation, PhD thesis,   TU Braunschweig, Institut Computational Mathematics, Germany, 2008 and \n  H. Fassbender, N. Mackey, D. S. Mackey and C. Schroeder, Structured   Polynomial Eigenproblems Related to Time-Delay Systems, ETNA, 2008, vol 31, pp 306-330\nnlevp_native_loaded_string\n  The benchmark problem from the NLEVP-collection called \"pdde_stability\", represented in the native NEP-PACK format. The parameters are (n,kappa,m) where n is the size, and the NEP is a SPMF with rational terms and the coefficient matrices are rank one modifications of Toeplitz matrices.\n S. I. Solov\"ev. Preconditioned iterative methods for a class of nonlinear eigenvalue problems. Linear Algebra Appl., 415 (2006), pp.210-229.\nbem_fichera\n  Represents a boundary element discretization of Helmholtz equation for a domain consisting of the unit cube, except one removed corner (Fichera corner). The mesh is hardcoded. The parameter N determines the size of the problem (default N = 5). The model stems from the model in these papers:\n Steinlechner, A boundary element method for solving PDE eigenvalue problems, M. Steinlechner, bachelor thesis, ETH Z√ºrich, 2010\n Effenberger and Kressner, Chebyshev interpolation for nonlinear eigenvalue problems, BIT Numerical Mathematics, December 2012, Volume 52, Issue 4, pp 933‚Äì951\ndtn_dimer\n NEP described in J. Araujo-Cabarcas, C. Engstr√∂m and E. Jarlebring, Efficient resonance computations for Helmholtz problems based on a Dirichlet-to-Neumann map, J. Comput. Appl. Math., 330:177-192, 2018  (http://arxiv.org/pdf/1606.09547) where the nonlinearity stems from the application of Dirichlet-to-Neumann map. The problem contains quotients of Bessel functions and derivatives of Bessel functions. This NEP takes two parameters: data_dir::String and l::Int. The data_dir specifies the directory of the dowloaded FEM-matrices (available here https://umu.app.box.com/s/b52yux3z9rcl8y0l7la22k0vi062cvu5). The integer l specifies the number of DtN-terms: 2*l+1.   \n J. Araujo-Cabarcas, C. Engstr√∂m and E. Jarlebring, Efficient resonance computations for Helmholtz problems based on a Dirichlet-to-Neumann map, J. Comput. Appl. Math., 330:177-192, 2018  (http://arxiv.org/pdf/1606.09547).\n\nExample\n\njulia> nep=nep_gallery(\"dep0\",100);\njulia> norm(compute_Mlincomb(nep,1.0+1.0im,ones(size(nep,1))))\n104.76153002802755\n\nSee also the following galleries:\n\nGalleryNLEVP\nGalleryWaveguide\n\n\n\n\n\n","category":"method"},{"location":"gallery/#Berlin-Manchester-collection-1","page":"Gallery","title":"Berlin-Manchester collection","text":"","category":"section"},{"location":"gallery/#","page":"Gallery","title":"Gallery","text":"If MATLAB and the Berlin-Manchester collection are installed, you can access the Berlin-Manchester collection problems with the GalleryNLEVP. This is a wrapper, which makes  MATLAB-calls (via Julias MATLAB interoperability package) for every compute-function call. This can be very inefficient due to overhead. You may want to convert your NEP to a native type, e.g., ChebPEP.","category":"page"},{"location":"gallery/#","page":"Gallery","title":"Gallery","text":"julia> using GalleryNLEVP\njulia> nlevp_path=\"/home/user/myname/work/src/nlevp\";\njulia> nep=nep_gallery(NLEVP_NEP,\"hadeler\",nlevp_path);\njulia> Œª,v=quasinewton(nep,Œª=0.2,logger=1,maxit=20,tol=1e-10);\njulia> norm(compute_Mlincomb(nep,Œª,v))/norm(v)\n9.698206079849311e-11","category":"page"},{"location":"gallery/#","page":"Gallery","title":"Gallery","text":"Problems loaded from the Berlin-Manchester collection are NEP-objects where every call to access a function generates a call to an underlying MATLAB-session. Some problems in the Berlin-Manchester collection have native support in NEP-PACK, i.e., avoiding a MATLAB-access in every call; see nep_gallery above.","category":"page"},{"location":"gallery/#Extra-gallery-problems-1","page":"Gallery","title":"Extra gallery problems","text":"","category":"section"},{"location":"gallery/#","page":"Gallery","title":"Gallery","text":"Stand-alone implementation of certain larger problems can be accessed in a similar way to the standard native gallery. A native implementation of a waveguide eigenvalue problem can be accessed as.","category":"page"},{"location":"gallery/#","page":"Gallery","title":"Gallery","text":"julia> using GalleryWaveguide\njulia> nep=nep_gallery(WEP,benchmark_problem=\"TAUSCH\");","category":"page"},{"location":"logger/#Logger-1","page":"Logger","title":"Logger","text":"","category":"section"},{"location":"logger/#Basic-usage-1","page":"Logger","title":"Basic usage","text":"","category":"section"},{"location":"logger/#","page":"Logger","title":"Logger","text":"NEP-PACK provides considerable functionality to control the printouts and information of the NEP-solvers. All NEP-solvers take the keyword argument logger which specifies if things should be stored in a logger and/or printed. The main loggers are the PrintLogger which only provides printouts, and ErrorLogger which stores error information.","category":"page"},{"location":"logger/#","page":"Logger","title":"Logger","text":"We illustrate with a combination with the error measure. This example shows how to plot the eigenvalue error of a NEP-solver by using a reference solution.","category":"page"},{"location":"logger/#","page":"Logger","title":"Logger","text":"First let us only user logger=1 in combination with a EigvalReferenceErrmeasure.","category":"page"},{"location":"logger/#","page":"Logger","title":"Logger","text":"julia> A0=[3.0 4 ; 5 6]; A1=[-1.0 0 ; 3.0 1.0];\njulia> nep=DEP([A0,A1]); # Delay eigenvalue problem\njulia> (Œªref,_)=resinv(nep,v=[1;1],Œª=8,tol=1e-16); # Compute a reference solution\njulia> resinv(nep,v=[1;1],Œª=8,logger=1,errmeasure=EigvalReferenceErrmeasure(nep,Œªref));\nPrecomputing linsolver\niter 1 err:1.2171484853011378 Œª=8.0 + 0.0im\niter 2 err:0.21696340485295096 Œª=9.000185080448187 + 0.0im\niter 3 err:0.032989925133875886 Œª=9.250138410435014 + 0.0im\niter 4 err:0.004864643426348181 Œª=9.21228384187479 + 0.0im\niter 5 err:0.0007206309370317854 Œª=9.21786911623817 + 0.0im\niter 6 err:0.00010667933045382938 Œª=9.217041805970684 + 0.0im\niter 7 err:1.579396864670457e-5 Œª=9.217164279269785 + 0.0im\niter 8 err:2.3382761789036977e-6 Œª=9.217146147024959 + 0.0im\niter 9 err:3.461794584325162e-7 Œª=9.217148831480596 + 0.0im\niter 10 err:5.1251506150151727e-8 Œª=9.217148434049632 + 0.0im\niter 11 err:7.587733108493921e-9 Œª=9.217148492888871 + 0.0im\niter 12 err:1.1233556307388426e-9 Œª=9.217148484177782 + 0.0im\niter 13 err:1.6631140908884845e-10 Œª=9.21714848546745 + 0.0im\niter 14 err:2.4622082150926872e-11 Œª=9.217148485276516 + 0.0im\niter 15 err:3.645084234449314e-12 Œª=9.217148485304783 + 0.0im\niter 16 err:5.400124791776761e-13 Œª=9.217148485300598 + 0.0im\niter 17 err:7.993605777301127e-14 Œª=9.217148485301218 + 0.0im\niter 18 err:1.0658141036401503e-14 Œª=9.217148485301127 + 0.0im","category":"page"},{"location":"logger/#","page":"Logger","title":"Logger","text":"The displayed err are eigenvalue errors and we now wish to plot them:","category":"page"},{"location":"logger/#","page":"Logger","title":"Logger","text":"julia> logger=ErrorLogger();\njulia> resinv(nep,v=[1;1],Œª=8,\n    errmeasure=EigvalReferenceErrmeasure(nep,Œªref),logger=logger);\njulia> errvec=logger.errs[1:17,1]; # This contains the iteration error","category":"page"},{"location":"logger/#","page":"Logger","title":"Logger","text":"We use Plots for plotting:","category":"page"},{"location":"logger/#","page":"Logger","title":"Logger","text":"julia> using Plots;\njulia> plot(errvec,yaxis=:log,marker=:star,xlabel=\"iteration\",ylabel=\"eigval error\")","category":"page"},{"location":"logger/#","page":"Logger","title":"Logger","text":"The theory predicts linear convergence, which we also observe.","category":"page"},{"location":"logger/#","page":"Logger","title":"Logger","text":"<br>\n<img src=\"https://nep-pack.github.io/NonlinearEigenproblems.jl/logger_resinv_conv.png\" height=300>","category":"page"},{"location":"logger/#Logger-types-1","page":"Logger","title":"Logger types","text":"","category":"section"},{"location":"logger/#","page":"Logger","title":"Logger","text":"Logger\nPrintLogger\nErrorLogger","category":"page"},{"location":"logger/#NonlinearEigenproblems.NEPSolver.Logger","page":"Logger","title":"NonlinearEigenproblems.NEPSolver.Logger","text":"abstract type Logger ; end\n\nThe type represents a way to log information throughout the algorithms. Error history and other properties can be stored in the logger. The most common Loggers are PrintLogger and ErrorLogger.\n\nAs a method developer you want to use push_info! and push_iteration_info!\n\nSee also: PrintLogger and ErrorLogger.\n\n\n\n\n\n","category":"type"},{"location":"logger/#NonlinearEigenproblems.NEPSolver.PrintLogger","page":"Logger","title":"NonlinearEigenproblems.NEPSolver.PrintLogger","text":"struct PrintLogger <: Logger ;\nfunction PrintLogger(displaylevel)\n\nWhen you use this logger, you will obtain printouts in stdout, no other logging. The displaylevel parameter specifies how much should be printed. The higher the value, the more is printed. Zero means no printouts.\n\n\n\n\n\n","category":"type"},{"location":"logger/#NonlinearEigenproblems.NEPSolver.ErrorLogger","page":"Logger","title":"NonlinearEigenproblems.NEPSolver.ErrorLogger","text":"struct ErrorLogger <: Logger\nErrorLogger(nof_eigvals=100,nof_iters=100,displaylevel=1)\n\nUse this object if you want to save the error history in a method. The displaylevel is interpreted as in PrintLogger. The kwargs nof_eigvals and nof_iters is used to preallocate memory used for saving.\n\nWhen you use this logger, the error of push_iteration_info!-calls will be stored in logger.errs.\n\n\n\n\n\n","category":"type"},{"location":"logger/#Advanced-usage-1","page":"Logger","title":"Advanced usage","text":"","category":"section"},{"location":"logger/#","page":"Logger","title":"Logger","text":"The logging functionality can be extended in case you want to collect (or throw away) some of the information. You need to create a new type which implements the following methods.","category":"page"},{"location":"logger/#","page":"Logger","title":"Logger","text":"push_info!\npush_iteration_info!","category":"page"},{"location":"logger/#NonlinearEigenproblems.NEPSolver.push_info!","page":"Logger","title":"NonlinearEigenproblems.NEPSolver.push_info!","text":"function push_info!(logger, [level,] v; continues::Bool=false)\n\nPushes a string v to the logger. If continues=true, the next push_info! (or push_iteration_info!) is connected to this, e.g. line-feed will be omitted.\n\n\n\n\n\n","category":"function"},{"location":"logger/#NonlinearEigenproblems.NEPSolver.push_iteration_info!","page":"Logger","title":"NonlinearEigenproblems.NEPSolver.push_iteration_info!","text":"function push_iteration_info!(logger, [level,] iter; kwargs)\n\nPushes information about a specific iteration iter. Standardized keywords are Œª, err and v.\n\n\n\n\n\n","category":"function"},{"location":"deflation/#Deflation-1","page":"Deflation","title":"Deflation","text":"","category":"section"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"Several NEP-algorithms are able to find one eigenvalue, but may have difficulties finding several eigenvalues. Deflation is a transformation technique which can transform a NEP by effectively removing computed eigenvalues, and allowing several eigenvalues to be computed by repeated application of the same NEP-algorithm.","category":"page"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"NEP-PACK provides a solver-independent implementation of deflation which can be combined (essentially) with any NEP-solver.  NEP-PACK also has some NEP-solver deflation techniques and reconvergence avoidance techniques  incoprorated directly in the solver, e.g., in the nonlinear Arnoldi method (nlar), the Jacobi-Davidson method (jd_betcke) and Broyden's method (broyden).","category":"page"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"The technique takes a NEP and a solution and creates a bigger NEP with one dimension larger but where the eigenvalue is removed from the solution set. Due to the abstraction of NEP-objects in NEP-PACK, the deflated NEP is again a NEP and we can apply the NEP-solver to the deflated NEP.","category":"page"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"Given a NEP (which can be a deflated NEP) nep and an eigenpair (Œª,v) you can compute a deflated NEP by calling dnep=deflate_eigpair(nep,Œª,v) and dnep will essentially have the same eigenvalues as nep, except Œª.\nThe transformation changes the eigenvectors such that the eigenvectors of nep and dnep will be different. To extract the eigenvectors (and the eigenvalues) you can call get_deflated_eigpairs(dnep).","category":"page"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"note: Note\nMore elaborate deflation examples can be found in the tutorial on deflation.","category":"page"},{"location":"deflation/#Theory-1","page":"Deflation","title":"Theory","text":"","category":"section"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"The theory follows the presentation of the technique in the PhD thesis of Cedric Effenberger. In a somewhat simplified form, it can be summarized as follows (for the index one case). The deflation is based on a theory for NEP essentially stating that if (sx) is an eigenpair, then the extended nonlinear eigenvalue problem","category":"page"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"T(Œª)=beginbmatrixM(Œª)M(Œª)x(s-Œª)^-1 x^T  0endbmatrix","category":"page"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"has the same eigenvalues as the original problem except for the eigenvalue s, under certain quite general conditions which are assumed to be satisfied. More eigenpairs can be deflated with techniques of partial Schur factorizations, which the user does not need to be aware of, due to the abstract provided by the functions below. When we create a deflated NEP, we create the NEP T.","category":"page"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"There are several ways to represent the T, which is why deflation has several modes. If you run","category":"page"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"julia> dnep=deflate_eigpair(nep,Œª1,v1,mode=:SPMF)","category":"page"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"the dnep will be of the type AbstractSPMF. More precisely, if","category":"page"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"M(Œª)=A_1f_1(Œª)+cdots+A_mf_m(Œª)","category":"page"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"the deflated NEP will be","category":"page"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"T(Œª)=\nbeginbmatrixA_100  0endbmatrixf_1(Œª)+cdots+\nbeginbmatrixA_m00  0endbmatrixf_m(Œª)+","category":"page"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"beginbmatrix0A_1x0  0endbmatrixfracf_1(Œª)s-Œª+cdots+\nbeginbmatrix0A_mx0  0endbmatrixfracf_m(Œª)s-Œª+\nbeginbmatrix00x^T  0endbmatrix","category":"page"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"Clearly, the deflated NEP has more SPMF-terms than the original NEP. When the parameter mode=:SPMF is set, the deflation method will explicitly construct an SPMF_NEP.  This is not recommended if you have many SPMF-terms in the original problem, but can be efficient when you only have a few terms. (Some additional exploitation is however implemented, since we can use the fact that the introduced terms are of low rank, and therefore naturally represented as a LowRankFactorizedNEP.)","category":"page"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"If you select mode=:Generic, the compute functions are implemented without the use of SPMF, and can be more efficient if the NEP has many SPMF-terms. When mode=:MM the compute-functions are all implemented by calls to compute_MM. This will not be efficient if compute_Mder(nep,Œª,der) where  der>0 is needed.","category":"page"},{"location":"deflation/#Functions-1","page":"Deflation","title":"Functions","text":"","category":"section"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"deflate_eigpair","category":"page"},{"location":"deflation/#NonlinearEigenproblems.NEPTypes.deflate_eigpair","page":"Deflation","title":"NonlinearEigenproblems.NEPTypes.deflate_eigpair","text":"dnep=deflate_eigpair(orgnep::NEP,Œª,v,[mode=:Auto])\n\nThis function creates a deflated NEP based on (Œªv), which are assumed to an eigenpair of nep. Effectively, the function will return dnep::NEP which has the same solutions as orgnep, except those corresponding to (Œªv). Deflation is typically used to avoid reconvergence.\n\nIf orgnep is a DeflatedNEP, the orgnep the deflation in orgnep will be updated.\n\nThe mode kwarg can be :Auto, :Generic, :SPMF, :MM. This specifies how the deflated NEP should be represented. Which mode is the most efficient depends on many problem properties. If the original NEP is an AbstractSPMF with only a few terms, mode=:SPMF may be efficient. The SPMF-mode is based on a diagonalization of the deflated invariant pair and is not necessarily robust when you deflate eigenvalues near to each other. When mode=:MM is used, all compute functions are implemented via calls to the compute_MM. This can work well for small dense problems. The :Generic is based on an explicit derivation of the problem (via binomial expansion) which can be efficient if low order derivates are needed. If :Auto is selected, NEP-PACK tries to determine which one is the most efficient based on the orgnep.\n\nExample:\n\njulia> nep=nep_gallery(\"dep0\");\njulia> (Œª,v)=newton(nep);\njulia> n=size(nep,1);\njulia> dnep=deflate_eigpair(nep,Œª,v)\njulia> (Œª2,v2)=augnewton(dnep);  # this converges to different eigval\njulia> using LinearAlgebra;\njulia> minimum(svdvals(compute_Mder(nep,Œª2)))\n9.323003321058995e-17\n\nThe function get_deflated_eigpairs() extracts the eigenpairs that have been deflated. The returned pairs are eigenpairs of the original NEP:\n\njulia> dnep=deflate_eigpair(dnep,Œª2,v2)\njulia> (D,V)=get_deflated_eigpairs(dnep)\njulia> norm(compute_Mlincomb(nep,D[1],V[:,1]))\n6.164690797405912e-16\njulia> norm(compute_Mlincomb(nep,D[2],V[:,2]))\n5.20740757162067e-16\n\nReferences\n\nC. Effenberger, Robust solution methods for nonlinear eigenvalue problems, PhD thesis, 2013, EPF Lausanne\n\n\n\n\n\n","category":"function"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"get_deflated_eigpairs","category":"page"},{"location":"deflation/#NonlinearEigenproblems.NEPTypes.get_deflated_eigpairs","page":"Deflation","title":"NonlinearEigenproblems.NEPTypes.get_deflated_eigpairs","text":"(D,V)=get_deflated_eigpairs(dnep::DeflatedNEP [Œª,v])\n\nReturns a vector of eigenvalues D and a matrix with corresponding eigenvectors V. The eigenpairs correspond to the original problem, underlying the DeflatedNEP. The optional parameters Œª,v allows the inclusion of an additional eigpair. Essentially, the optional parameters are the expanding the deflation and the running get_deflated_eigpairs  with kwarg, i.e.,\n\n(D,V)=get_deflated_eigpairs(deflate_eigpair(dnep,Œª,v))`\n\nSee example in deflate_eigpair.\n\n\n\n\n\n","category":"function"},{"location":"deflation/#","page":"Deflation","title":"Deflation","text":"(Image: To the top)","category":"page"},{"location":"innersolvers/#Projection-1","page":"Projection","title":"Projection","text":"","category":"section"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"Many NEP-solvers are based on a computation of a solution to a projected problem, i.e., if VWinmathbbR^ntimes p we need to solve the (smaller) NEP","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"W^HM(Œª)Vz=0","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"This is sometimes called a nonlinear Rayleigh-Ritz procedure, or a direct projection. These are inner solvers for many NEP-solvers.","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"NEP-PACK provides a framework to handle projected problems and inner solves. This is implemented into two separate components:","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"Projection: As a user (or NEP-solver developer) you can create a new object corresponding to the projection. In NEP-PACK, the projection is again an object of with type inheriting from NEP. More precisely, it is a Proj_NEP which you normally create with the function create_proj_NEP.\nInner solvers: Since the projected problem is again a NEP, in principle any of the NEP-solvers of this package can be used. This is handled by the InnerSolver objects which are wrappers for corresponding NEP-solvers such that we can pass appropriate parameters to the inner soler. The inner solver is controlled by the inner_solver_method keyword in many NEP-solvers. By default DefaultInnerSolver is used.","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"As a NEP-user, you often do not need to care about how the projection is handled, e.g., if you use the type SPMF_NEP with only a few terms. For instance, if you wish to use the infinite Arnoldi method (iar) to handle the project solves in the nonlinear Arnoldi method (nlar), you can do the following:","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"julia> nep=nep_gallery(\"dep0_tridiag\");\njulia> Œª,v=nlar(nep,neigs=1,inner_solver_method=IARInnerSolver(),logger=1);\nUsing inner solver IARInnerSolver(1.0e-13, 80, :ones, false, NonlinearEigenproblems.NEPSolver.iar)\niter 1 err:0.05095382004494062 Œª=0.7579134426195271 - 0.03707164055891316im\niter 2 err:0.00031997693290503965 Œª=-0.00010049358638757657 + 0.0001763732030940319im\niter 3 err:6.563177508431498e-6 Œª=-0.0005335154073888051 - 4.498082881742902e-6im\niter 4 err:8.037612383023366e-9 Œª=-0.0005259618179586685 + 2.806438064753968e-9im\niter 5 err:3.386041718599221e-11 Œª=-0.0005259683064505526 + 1.3119844096548209e-11im\niter 6 err:3.4499779767886924e-13 Œª=-0.0005259682927702825 - 1.0404412824030558e-13im\niter 7 err:5.365662696809372e-15 Œª=-0.0005259682929434785 - 2.0247938561528697e-17im\n****** 1 converged to eigenvalue: -0.0005259682929434785 - 2.0247938561528697e-17im errmeasure:5.365662696809372e-15","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"The logging of the inner solver is controlled by the kwarg inner_logger, which follows the same framework as the standard NEP-PACK Logger. This produces very verbose output illustrating also the convergence of the inner solve:","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"julia> Œª,v=nlar(nep,neigs=1,inner_solver_method=IARInnerSolver(),logger=1,inner_logger=1);\nUsing inner solver IARInnerSolver(1.0e-13, 80, :ones, false, NonlinearEigenproblems.NEPSolver.iar)\n-\n--\n---\n----\n-----\n------\n-------\n--------\n---------\n----------\n-----------\n------------\n=------------\n+-------------\niter 1 err:0.04860520921206162 Œª=0.8437634284420165 + 0.005742468974957178im\n-\n--\n---\n+---\niter 2 err:0.0008771218464072076 Œª=-0.00065275394814732 - 0.0008601482370586537im\n-\n--\n---\n...","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"Rayleigh functional computation, which corresponds to projection with p=1, is also handled with this framework.","category":"page"},{"location":"innersolvers/#Inner-solvers-1","page":"Projection","title":"Inner solvers","text":"","category":"section"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"The inner solvers inherit from InnerSolver. The following inner solvers are available by default.","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"NewtonInnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.NewtonInnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.NewtonInnerSolver","text":"struct NewtonInnerSolver\nfunction NewtonInnerSolver(;tol=1e-13,maxit=80,starting_vector=:Vk,\n                           newton_function=augnewton)\n\nUses a Newton-like method to solve the inner problem, with tolerance, and maximum number of iterations given by tol and maxit. The starting vector can be :ones, :randn, or :Vk. The value :Vk specifies the use of the outer NEP-solver keyword argument (Vk). This is typically the previous iterate in the outer method.\n\nThe kwarg newton_function, specifies a Function which is called. The type supports augnewton, newton, resinv quasinewton, newtonqr. In principle it can be any method which takes the same keyword arguments as these methods.\n\nSee also: InnerSolver, inner_solve\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"IARInnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.IARInnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.IARInnerSolver","text":"struct IARInnerSolver\nfunction IARInnerSolver(;tol=1e-13,maxit=80,\n           starting_vector=:ones,normalize_DEPs=:auto,\n           iar_function=iar)\n\nUses iar, tiar or iar_chebyshev to solve the inner problem, with tolerance, and maximum number of iterations given by tol and maxit. The starting vector can be :ones or :randn. The iar_function can be iar, tiar or iar_chebyshev (or any function taking the same parameters as input). normalize_DEPs determines if the we should carry out precomputation and make sure the projection of a DEP  is again a DEP (which can speed up performance). It can take the value true, false or :auto. :auto sets it to true if we use the iar_chebyshev solver.\n\nThe kwarg iar_function, specifies a Function which is called. Examples of functions are iar and iar_chebyshev. It can be any NEP-solver which takes the same keyword arguments as these methods.\n\nSee also: InnerSolver, inner_solve\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"IARChebInnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.IARChebInnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.IARChebInnerSolver","text":"function IARChebInnerSolver(;tol=1e-13,maxit=80,starting_vector=:ones,\n                            normalize_DEPs=true)\n\nUses iar_chebyshev to solve the inner problem. See IARInnerSolver for keyword argument documentation.\n\nSee also: IARInnerSolver, InnerSolver, inner_solve\n\n\n\n\n\n","category":"function"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"ContourBeynInnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.ContourBeynInnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.ContourBeynInnerSolver","text":"struct ContourBeynInnerSolver <: InnerSolver\nfunction ContourBeynInnerSolver(;tol=sqrt(eps(real(Float64))),\n                                radius=:auto,N=1000)\n\nUses contour_beyn to solve the inner problem, with radius and number of quadrature nodes, given by radius and n. If the variable radius is set to :auto, the integration radius will be automatically selected by using the eigenvalue approximations specified by the outer solver.\n\nSee also: InnerSolver, inner_solve\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"PolyeigInnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.PolyeigInnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.PolyeigInnerSolver","text":"struct PolyeigInnerSolver <: InnerSolver\nfunction PolyeigInnerSolver()\n\nSpecifies the use of polyeig to solve the inner problem. This is intended for NEPs of the type PEP.\n\nSee also: InnerSolver, inner_solve\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"SGIterInnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.SGIterInnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.SGIterInnerSolver","text":"struct SGIterInnerSolver <: InnerSolver\n\nUses sgiter to solve the inner problem.\n\nSee also: InnerSolver, inner_solve\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"NleigsInnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.NleigsInnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.NleigsInnerSolver","text":"struct NleigsInnerSolver <: InnerSolver\nfunction NleigsInnerSolver(;Œ£= :auto,nodes =:auto, tol=1e-6 )\n\nUses nleigs to solve the inner problem, in the region Œ£ with shifts nodes and with tolerance tol. If the variable Œ£ is set to :auto, the region Œ£ will be set by using the eigenvalues approximations. See nleigs for description of parameters.\n\nSee also: InnerSolver, inner_solve\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"DefaultInnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.DefaultInnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.DefaultInnerSolver","text":"struct DefaultInnerSolver <: InnerSolver\n\nDispatches a version of inner_solve based on the type of the NEP provided. This function tries to automatically detect which solver is recommended.\n\nSee also: InnerSolver, inner_solve\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/#Inner-solvers:-Advanced-usage-1","page":"Projection","title":"Inner solvers: Advanced usage","text":"","category":"section"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"You can define your own inner solver by inheriting from InnerSolver and implementing the function inner_solve. Since the inner_solve obtains information from the solver via keyword arguments, you need to end your method signature with kwargs...).","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"InnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.InnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.InnerSolver","text":"abstract type InnerSolver\n\nStructs inheriting from this type are used to solve inner problems in an inner-outer iteration.\n\nThe InnerSolver objects are passed to the NEP-algorithms, which uses it to dispatch the correct version of the function inner_solve. Utilizes existing implementations of NEP-solvers and inner_solve acts as a wrapper to these.\n\nExample\n\nThere is a DefaultInnerSolver that dispatches an inner solver based on the provided NEP. However, this example shows how you can force nlar to use the IARInnerSolver for a PEP.\n\njulia> nep=nep_gallery(\"pep0\", 100);\njulia> Œª,v = nlar(nep, inner_solver_method=NEPSolver.IARInnerSolver(), neigs=1, num_restart_ritz_vecs=1, maxit=70, tol=1e-8);\njulia> norm(compute_Mlincomb(nep,Œª[1],vec(v)))\n8.68118417430353e-9\n\nSee also: inner_solve, DefaultInnerSolver, NewtonInnerSolver, PolyeigInnerSolver, IARInnerSolver, IARChebInnerSolver, SGIterInnerSolver, ContourBeynInnerSolver\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"inner_solve","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.inner_solve","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.inner_solve","text":"inner_solve(is::InnerSolver,T_arit,nep;kwargs...)\n\nSolves the projected linear problem with solver specied with is. This is to be used as an inner solver in an inner-outer iteration. T specifies which method to use. The most common choice is DefaultInnerSolver. The function returns (Œªv,V) where Œªv is an array of eigenvalues and V a matrix with corresponding vectors. The struct T_arit defines the arithmetics used in the outer iteration and should prefereably also be used in the inner iteration.\n\nDifferent inner_solve methods take different kwargs. These are standardized kwargs:\n\nneigs: Number of wanted eigenvalues (but less or more may be returned)\nœÉ: target specifying where eigenvalues\nŒªv, V: Vector/matrix of guesses to be used as starting values\nj: the jth eigenvalue in a min-max characterization\ntol: Termination tolarance for inner solver\ninner_logger: Determines how the inner solves are logged. See Logger for further references\n\n\n\n\n\n","category":"function"},{"location":"innersolvers/#Projection-2","page":"Projection","title":"Projection","text":"","category":"section"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"The NEP-PACK functionality for projected problems are represented by projection types. Normally, the projection is created by create_proj_NEP from a standard NEP. After creating a projected NEP, you can set the projection subspace (represented by the matrices V and W) using set_projectmatrices! or expand_projectmatrices!.","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"julia> A=[1 0 0; 0 1.0 0; 0 0 1]; B=[1 2 3; 3 3 3 ; 4 -1 -1.0];\njulia> nep=SPMF_NEP([A, B], [s->s, s->s^5]);\njulia> pnep=create_proj_NEP(nep);\njulia> W=[4 1 ; 6 1  ; 6.0 2]; V=[3 3;3 4.0;4.0 -1];\njulia> set_projectmatrices!(pnep,W,V); # modifies pnep\njulia> Œª=3.0+1im;\njulia> W'*compute_Mder(nep,Œª)*V\n2√ó2 Array{Complex{Float64},2}:\n -3366.0+92958.0im  -2238.0+61334.0im\n  -690.0+19290.0im   -513.0+13909.0im\njulia> compute_Mder(pnep,Œª)\n2√ó2 Array{Complex{Float64},2}:\n -3366.0+92958.0im  -2238.0+61334.0im\n  -690.0+19290.0im   -513.0+13909.0im","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"Effectively, the Proj_NEP creates compute functions, which are designed to be as efficient as possible.","category":"page"},{"location":"innersolvers/#Projection-functions-1","page":"Projection","title":"Projection functions","text":"","category":"section"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"You can create a projected NEP with create_proj_NEP:","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"create_proj_NEP","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPTypes.create_proj_NEP","page":"Projection","title":"NonlinearEigenproblems.NEPTypes.create_proj_NEP","text":"pnep=create_proj_NEP(orgnep::ProjectableNEP[,maxsize [,T]])\n\nCreate a NEP representing a projected problem N(Œª)=W^HM(Œª)V,  where the  base NEP is represented by orgnep. The optional parameter maxsize::Int determines how large the projected problem can be and T is the Number type used for the projection matrices (default ComplexF64). These are needed for memory preallocation reasons. Use set_projectmatrices! and expand_projectmatrices!  to specify projection matrices V and W.\n\nExample:\n\nThe following example illustrates that a projection of a NEP is also a NEP and we can for instance call compute_Mder on it:\n\njulia> nep=nep_gallery(\"pep0\")\njulia> V=Matrix(1.0*I,size(nep,1),2);\njulia> W=Matrix(1.0*I,size(nep,1),2);\njulia> pnep=create_proj_NEP(nep);\njulia> set_projectmatrices!(pnep,W,V);\njulia> compute_Mder(pnep,3.0)\n2√ó2 Array{Complex{Float64},2}:\n -2.03662+0.0im   13.9777+0.0im\n -1.35069+0.0im  -13.0975+0.0im\njulia> W'*compute_Mder(nep,3.0)*V  # Gives the same result\n2√ó2 Array{Float64,2}:\n -2.03662   13.9777\n -1.35069  -13.0975\n\nIf you know that you will only use real projection matrices, you can specify this in at the creation:\n\njulia> pnep=create_proj_NEP(nep,2,Float64);\njulia> set_projectmatrices!(pnep,W,V);\njulia> compute_Mder(pnep,3.0)\n2√ó2 Array{Float64,2}:\n -2.03662   13.9777\n -1.35069  -13.0975\n\n\n\n\n\n","category":"function"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"set_projectmatrices!","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPTypes.set_projectmatrices!","page":"Projection","title":"NonlinearEigenproblems.NEPTypes.set_projectmatrices!","text":"set_projectmatrices!(pnep::Proj_NEP,W,V)\n\nSet the projection matrices for the NEP to W and V, i.e., corresponding the NEP: N(Œª)=W^HM(Œª)V. See also create_proj_NEP.\n\nExample\n\nThis illustrates if W and V are vectors of ones, the projected problem becomes the sum of the rows and columns of the original NEP.\n\njulia> nep=nep_gallery(\"pep0\")\njulia> pnep=create_proj_NEP(nep);\njulia> V=ones(200,1);  W=ones(200,1);\njulia> set_projectmatrices!(pnep,W,V);\njulia> compute_Mder(pnep,0)\n1√ó1 Array{Complex{Float64},2}:\n 48.948104019482756 + 0.0im\njulia> sum(compute_Mder(nep,0),dims=[1,2])\n1√ó1 Array{Float64,2}:\n 48.948104019482955\n\n\n\n\n\n","category":"function"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"expand_projectmatrices!","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPTypes.expand_projectmatrices!","page":"Projection","title":"NonlinearEigenproblems.NEPTypes.expand_projectmatrices!","text":"expand_projectmatrices!(nep::Proj_SPMF_NEP, Wnew, Vnew)\n\nThe projected NEP is updated by adding the last column of Wnew and Vnew to the basis. Note that Wnew and Vnew contain also the \"old\" basis vectors. See also create_proj_NEP\n\nExample:\n\nIn the following example you see that the expanded projected problem has one row and column more, and the leading subblock is the same as the smaller projected NEP.\n\njulia> nep=nep_gallery(\"pep0\"); n=size(nep,1);\njulia> V=Matrix(1.0*I,n,2); W=Matrix(1.0*I,n,2);\njulia> pnep=create_proj_NEP(nep);\njulia> set_projectmatrices!(pnep,W,V);\njulia> compute_Mder(pnep,0)\n2√ó2 Array{Complex{Float64},2}:\n 0.679107+0.0im   -0.50376+0.0im\n 0.828413+0.0im  0.0646768+0.0im\njulia> Vnew=[V ones(n)]\njulia> Wnew=[W ones(n)]\njulia> expand_projectmatrices!(pnep,Wnew,Vnew);\njulia> compute_Mder(pnep,0)\n3√ó3 Array{Complex{Float64},2}:\n 0.679107+0.0im   -0.50376+0.0im  -12.1418+0.0im\n 0.828413+0.0im  0.0646768+0.0im   16.3126+0.0im\n -17.1619+0.0im   -10.1628+0.0im   48.9481+0.0im\n\n\n\n\n\n","category":"function"},{"location":"innersolvers/#Projection-types-1","page":"Projection","title":"Projection types","text":"","category":"section"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"NEPs for which this projection can be computed inherit from ProjectableNEP.","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"ProjectableNEP","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPTypes.ProjectableNEP","page":"Projection","title":"NonlinearEigenproblems.NEPTypes.ProjectableNEP","text":"abstract ProjectableNEP <: NEP\n\nA ProjectableNEP is a NEP which can be projected, i.e., one can construct the problem W*M(Œª)Vw=0 with the Proj_NEP. A NEP which is of this must have the function create_proj_NEP(orgnep::ProjectableNEP) implemented. This function must return a Proj_NEP.\n\nSee also: set_projectmatrices!.\n\nExample:\n\njulia> nep=nep_gallery(\"dep0\");\njulia> typeof(nep)\nDEP{Float64,Array{Float64,2}}\njulia> isa(nep,ProjectableNEP)\ntrue\njulia> projnep=create_proj_NEP(nep);\njulia> e1 = Matrix(1.0*I,size(nep,1),1);\njulia> set_projectmatrices!(projnep,e1,e1);\njulia> compute_Mder(nep,3.0)[1,1]\n-2.315345215259418\njulia> compute_Mder(projnep,3.0)\n1√ó1 Array{Float64,2}:\n -2.315345215259418\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"The result of the projection is represented in a Proj_NEP.","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"Proj_NEP","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPTypes.Proj_NEP","page":"Projection","title":"NonlinearEigenproblems.NEPTypes.Proj_NEP","text":"abstract type Proj_NEP <: NEP\n\nProj_NEP represents a projected NEP. The projection is defined as the NEP\n\nN(Œª)=W^HM(Œª)V\n\nwhere M(Œª) is a base NEP and W and V rectangular matrices representing a basis of the projection spaces. Instances are created with create_proj_NEP. See create_proj_NEP for examples.\n\nAny Proj_NEP needs to implement two functions to manipulate the projection:\n\nset_projectmatrices!: Set matrices W and V\nexpand_projectmatrices!: Effectively expand the matrices W and V with one column.\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"One explicit instance is the Proj_SPMF_NEP.","category":"page"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"Proj_SPMF_NEP","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPTypes.Proj_SPMF_NEP","page":"Projection","title":"NonlinearEigenproblems.NEPTypes.Proj_SPMF_NEP","text":"struct Proj_SPMF_NEP <: Proj_NEP\n\nThis type represents the (generic) way to project NEPs which are AbstractSPMF. See examples in create_proj_NEP.\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/#Rayleigh-functional-computation-1","page":"Projection","title":"Rayleigh functional computation","text":"","category":"section"},{"location":"innersolvers/#","page":"Projection","title":"Projection","text":"compute_rf","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.compute_rf","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.compute_rf","text":"compute_rf(eltype::Type,nep::NEP,x,inner_solver::InnerSolver;\n           y=x, target=zero(T), Œª0=target,TOL=eps(real(T))*1e3,max_iter=10)\n\nComputes the Rayleigh functional of the nep, i.e., computes a vector Œõ of values Œª such that y^TM(Œª)x=0, using the procedure specified in inner_solver. The default behaviour consists of a scalar valued Newton-iteration, and the returned vector has only one element.\n\nThe given eltype<:Number is the type of the returned vector.\n\nExample\n\nThis uses iar to solve the (scalar) nonlinear problem.\n\njulia> nep=nep_gallery(\"dep0\");\njulia> x=ones(size(nep,1));\njulia> s=compute_rf(ComplexF64,nep,x,IARInnerSolver())[1]; # Take just first element\n0.6812131933795565 + 0.0im\njulia> x'*compute_Mlincomb(nep,s,x)\n1.7763568394002505e-15 + 0.0im\n\n\n\n\n\n","category":"function"},{"location":"tutorial_newmethod/#Tutorial:-Implementing-your-own-method-1","page":"Tutorial 9 (New solver)","title":"Tutorial: Implementing your own method","text":"","category":"section"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"Although we try to provide state-of-the-art algorithms in NEP-PACK, you may want to implement a solver which is not available in NEP-PACK. By using the NEP-PACK data types and structures you can make your life easier in several ways. You do not need to know the internals of NEP-PACK. Correct usage, will give you access to many applications, helper functionality to combine with, and you will have to possibility to compare your method with other solvers. We now illustrate how to implement your own solver.","category":"page"},{"location":"tutorial_newmethod/#Halley's-method-1","page":"Tutorial 9 (New solver)","title":"Halley's method","text":"","category":"section"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"Halley's method for root-finding of nonlinear scalar equations has fast local convergence - even faster than Newton's method in terms of iterations. A NEP can be formulated as a root-finding problem since a solution will always satisfy","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"f(Œª)=det(M(Œª))=0","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"The application of Halley's method to this nonlinear scalar equation will serve as an example solver, although it does, to our knowledge, not lead to a competitive algorithm. Halley's method for the root-finding problem is defined as the","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"Œª_k+1=Œª_k-frac2f(Œª_k)f(Œª_k)2(f(Œª_k))^2-f(Œª_k)f(Œª_k)","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"Although there are formulas for the derivatives of the determinant, we will here for simplicity just use finite difference to estimate the derivatives, i.e.,","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":" f(Œª)approx fracf(Œª+Œ¥)-f(Œª-Œ¥)2Œ¥","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":" f(Œª)approx fracf(Œª+Œ¥)-2f(Œª)+f(Œª-Œ¥)Œ¥^2","category":"page"},{"location":"tutorial_newmethod/#Implementation-in-NEP-PACK-(preliminary-version)-1","page":"Tutorial 9 (New solver)","title":"Implementation in NEP-PACK (preliminary version)","text":"","category":"section"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"Let us first define our solver function and introduce the function of which we wish to find the roots. The matrix M(Œª) is obtained from the compute_Mder-function.","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"using NonlinearEigenproblems\nfunction halley(nep::NEP;Œª=0.0,Œ¥=sqrt(eps()),maxit=100,tol=eps()*100)\n   f=s-> det(compute_Mder(nep,s)); # The objective function\n   # More code here\nend","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"The main loop (which should go in # More code here) can be implemented, in a way that does not involve many function evaluations, as follows:","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"   for i=1:maxit\n       fŒª=f(Œª)\n       fŒªp=f(Œª+Œ¥)\n       fŒªm=f(Œª-Œ¥)\n       fp=(fŒªp-fŒªm)/(2Œ¥)\n       fpp=(fŒªp-2*fŒª+fŒªm)/(Œ¥^2)\n       ŒîŒª=2*fŒª*fp/(2*fp^2-fŒª*fpp);\n       Œª=Œª-ŒîŒª;\n       @show (i,Œª)\n       if (abs(ŒîŒª)<tol)\n          return Œª\n       end\n   end","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"Let's test our code on a benchmark problem:","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"julia> nep=nep_gallery(\"dep0\");\njulia> Œª=halley(nep)\n(i, Œª) = (1, -0.08425238005323712)\n(i, Œª) = (2, -0.14769529096609657)\n(i, Œª) = (3, -0.443164132772242)\n(i, Œª) = (4, -0.3653012970379835)\n(i, Œª) = (5, -0.35874460050208345)\n(i, Œª) = (6, -0.3587189462161427)\n(i, Œª) = (7, -0.35871894596862675)\n(i, Œª) = (8, -0.3587189459686267)","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"Clearly, the algorithm terminates after 8 iterations. We can verify that this is actually a solution easily if we also have an approximate eigenvector. An eigenvector can be computed by essentially one step of inverse iteration, on the matrix M(Œª):","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"julia> x=normalize(compute_Mder(nep,Œª)\\ones(size(nep,1)))\n5-element Array{Float64,1}:\n -0.3170546135678643\n  0.15957983055370098\n -0.30996780934165974\n  0.5577415634513512\n  0.6832678503094953","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"The residual norm  M(Œª)x does indeed become almost zero so it seems we have a solution:","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"julia> norm(compute_Mlincomb(nep,Œª,x))\n6.735017818475343e-16","category":"page"},{"location":"tutorial_newmethod/#Implementation-in-NEP-PACK-(full-version)-1","page":"Tutorial 9 (New solver)","title":"Implementation in NEP-PACK (full version)","text":"","category":"section"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"In the following we illustrate a more advanced usage of the NEP-PACK method development: NEP-PACKs logging facility  and error estimation. See Logger and Errmeasure. This gives access to other ways to measure error as well as a logging which is the same for all solvers and simplifies comparisons.","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"using NonlinearEigenproblems, LinearAlgebra, Plots\nfunction halley(nep::NEP;Œª=0.0,Œ¥=sqrt(eps()),maxit=100,\n                tol=eps()*100,logger=0,\n                errmeasure = DefaultErrmeasure(nep))\n    # Setup the logger.\n    @parse_logger_param!(logger);\n\n    n=size(nep,1);\n    f=s-> det(compute_Mder(nep,s)); # The objective function\n\n\n    for i=1:maxit\n        fŒª=f(Œª)\n        fŒªp=f(Œª+Œ¥)\n        fŒªm=f(Œª-Œ¥)\n        fp=(fŒªp-fŒªm)/(2Œ¥)\n        fpp=(fŒªp-2*fŒª+fŒªm)/(Œ¥^2)\n        ŒîŒª=2*fŒª*fp/(2*fp^2-fŒª*fpp);\n        Œª=Œª-ŒîŒª;\n        # Compute an eigenvector. This will not work if the\n        # eigenvector is orthogonal to ones(n)\n        x=normalize(compute_Mder(nep,Œª)\\ones(n));\n        err=estimate_error(ermdata,Œª,x)  # Estimate the error\n        push_iteration_info!(logger,i; Œª=Œª,err=err) # Put it into the log\n        if (err<tol)\n            return (Œª,x)\n        end\n    end\nend","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"We can now run our new method using with a logger=1 keyword argument so we get the standardized output of iteration info:","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"julia> (Œª,x)=halley(nep,logger=1);\niter 1 err:0.08492602120772309 Œª=-0.08425238005323712\niter 2 err:0.07450867012944977 Œª=-0.14769529096609657\niter 3 err:0.032639292900081246 Œª=-0.443164132772242\niter 4 err:0.00281602165251169 Œª=-0.3653012970379835\niter 5 err:1.1025990567599428e-5 Œª=-0.35874460050208345\niter 6 err:1.0638098128402615e-10 Œª=-0.3587189462161427\niter 7 err:4.942402279980973e-17 Œª=-0.35871894596862675\njulia> norm(compute_Mlincomb(nep,Œª,x))\n5.613646650354486e-16","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"If you now want to plot the error history, you can use the ErrorLogger:","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"julia> mylogger=ErrorLogger()\njulia> (Œª,x)=halley(nep,logger=mylogger);\njulia> plot(mylogger.errs[1:10,1],yaxis=:log)","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"We clearly observe the superlinear convergence:","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"using PyPlot # hide\nclf(); # hide\nz=[ 0.08492602120772309   # hide\n        0.07450867012944977 # hide\n        0.032639292900081246 # hide\n        0.00281602165251169 # hide\n        1.1025990567599428e-5 # hide\n        1.0638098128402615e-10 # hide\n        4.942402279980973e-17 # hide\n       ]; # hide\nsemilogy(z) # hide\ngrid() # hide\nsavefig(\"newmethod_convergence.svg\"); nothing # hide","category":"page"},{"location":"tutorial_newmethod/#","page":"Tutorial 9 (New solver)","title":"Tutorial 9 (New solver)","text":"(Image: )","category":"page"},{"location":"hydrotutorial/#Tutorial:-Stability-of-parallel-shear-flows-1","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial: Stability of parallel shear flows","text":"","category":"section"},{"location":"hydrotutorial/#Background-1","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Background","text":"","category":"section"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"Stability analysis of flows is a very important problem in fluid mechanics.  Linearizing the Navier‚ÄìStokes equations around the mean flow and then eliminating pressure gives us the Orr‚ÄìSommerfeld and Squire equations, which are a system of fourth order PDEs describing the dynamics:","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"left(Big(dfracpartial partial t+Udfracpartial partial xBig)nabla^2-Udfracpartial partial x-frac1Renabla^4right)v = 0\nleft(dfracpartial partial t+Udfracpartial partial x-frac1Renabla^2right)eta = -Udfracpartial vpartial z","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"More precisely, these equations stem from modeling using a mean base laminar flow overlineU = beginpmatrixU(y) 0 0endpmatrix and the perturbation u = beginpmatrixu v wendpmatrix. The normal vorticity is denoted eta.","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"This is a text-book model for fluid flows. The model is often used to study stability by making a plane wave ansatz and a transformation, and subsequently rewriting the discretized problem as a large standard eigenvalue problem, see Chapter 7, Stability and Transition in Shear Flows, Schmid, Peter J., Henningson, Dan S. We will here show that the plane wave ansatz directly leads to a NEP, which can be solved with methods in NEP-PACK without any additional transformations. We reproduce computational results in the above reference.","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"We thank Miguel Beneitez and Prabal Negi, Department of Mechanics, KTH for the valuable discussions and the discretization code.","category":"page"},{"location":"hydrotutorial/#Formulation-as-a-nonlinear-eigenvalue-problem-1","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Formulation as a nonlinear eigenvalue problem","text":"","category":"section"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"To study stability we use the plane wave perturbations ansatz","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"v(xyzt) = tildev(y)exp(i(alpha x+beta z-omega t))\neta(xyzt) = tildeeta(y)exp(i(alpha x+beta z-omega t))","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"which transforms the system to","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"left((-iomega+ialpha U)(mathcalD^2-alpha^2-beta^2)-ialpha U-frac1Re(mathcalD^2-alpha^2-beta^2)^2right)tildev = 0\nleft((-iomega+ialpha U)-frac1Re(mathcalD^2-alpha^2-beta^2)right)eta = -ibeta Utildev","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"where mathcalD denotes the 1-D differential operator fracpartial partial y. In this example, we consider the boundary conditions tildev = mathcalDtildev = tildeeta = 0. We assume that beta and omega are given and we wish to solve for the eigenvalue alphainmathbbC.","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"This is usually done by using a transformation of the form","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"beginpmatrixtildev tildeetaendpmatrix = beginpmatrixtildeV tildeEendpmatrixexp(-alpha y)","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"which reduces the power of alpha from four to two. The problem is then discretized and solved as a quadratic eigenvalue problem. See Chapter 7 in Schmid‚ÄìHenningson for details.  ","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"Rather than using the transformation approach described in the book of Schmid‚ÄìHenningson, we simply discretize mathcalD to D (using a suitable numerical discretization) which leads to a polynomial eigenvalue problem of fourth order.","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"We define diagonal matrices U_0, U_1 and U_2  as follows","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"U_0 = diag(U(y_0)U(y_1)ldotsU(y_n))\nU_1 = diag(U(y_0)U(y_1)ldotsU(y_n))\nU_2 = diag(U(y_0)U(y_1)ldotsU(y_n))","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"where y_i_i=1ldotsn denotes the y-coordinates of the n grid points used for discretization. The discretized problem, after expanding the powers, gives","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"left-fracIRealpha^4-iU_0alpha^3+left(frac2D^2Re+left(iomega-\nfrac2beta^2Reright)Iright)alpha^2right+\nleftleft(iU_0(D^2-beta^2I)-U_2right)alpha +Big(frac2beta^2D^2Re-fracD^4Re-fracbeta^4IRe+iomega(beta^2I-D^2)Big)righttildev = 0\nibeta U_1tildev+leftfracIRealpha^2 + iU_0 alpha +left(left(fracbeta^2Re-iomegaright)I-fracD^2Reright)righttildeeta = 0","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"This can be be formulated as a polynomial eigenvalue problem","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"M(lambda) = A_0+A_1lambda+A_2lambda^2+A_3lambda^3+A_4lambda^4","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"and the matrices A_0ldotsA_4 are given by","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"A_0 = beginpmatrixfrac2beta^2D^2Re-fracD^4Re-fracbeta^4IRe+iomega(beta^2I-D^2) 0 ibeta U_1left(fracbeta^2Re-iomegaright)I-fracD^2Reendpmatrix\nA_1 = beginpmatrixiU_0(D^2-beta^2I)-U_2 00 iU_0endpmatrix\nA_2 = beginpmatrixfrac2D^2Re+left(iomega-\nfrac2beta^2Reright)I 00 fracIReendpmatrix\nA_3 = beginpmatrix-iU_0 00 0endpmatrix\nA_4 = beginpmatrix-fracIRe 00 0endpmatrix","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"The eigenvector is given by beginpmatrixtildev^T  tildeetaendpmatrix^T","category":"page"},{"location":"hydrotutorial/#Problem-setup-in-NEP-PACK-1","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Problem setup in NEP-PACK","text":"","category":"section"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"The tutorial uses the helper-functions chebdif and cheb4c, which are provided in cheb4c.jl and chebdif.jl.","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"using NonlinearEigenproblems, Plots, ToeplitzMatrices;\ninclude(\"cheb4c.jl\");\ninclude(\"chebdif.jl\");","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"We begin by initializing the parameters to the values used to generate the data in Table 7.1 in Schmid‚ÄìHenningson.","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"N = 256;      # Number of interior points\nRe = 2000;    # Reynolds number\nœâ  = 0.3;     # Input frequency\nŒ≤  = 0.0;     # Spanwise wavenumber","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"To set up the matrices A_i, we need the discretized matrices corresponding to the operators mathcalD^2 and mathcalD^4. Here, we do this using Chebyshev nodes.","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"# √áhebyshev discretization of differential operators\nyF,DM = chebdif(N+2, 4);    \nD2 = DM[2:N+1,2:N+1,2];              #D^2\nyF,D4 = cheb4c(N+2);                 #D^4\n\n# The base flow for Poiseuille plane flow\nU   = 1 .-yF.^2;\nUp  = -2*yF;\nUpp = -2;\n\neye = Matrix{Float64}(I, N, N);  ","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"We can now set up the coefficient matrices and create a corresponding PEP object.","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"A4 = [-eye/Re zeros(N,N);zeros(N,N) zeros(N,N)];\nA3 = [-1im*diagm(0 => U) zeros(N,N);zeros(N,N) zeros(N,N)];\nA2 = [(1im*œâ-2Œ≤^2/Re)*eye+2D2/Re zeros(N,N);zeros(N,N) eye/Re];\nA1 = [1im*(diagm(0 => U)*(D2-eye*Œ≤^2)-Upp*eye) zeros(N,N);zeros(N,N) 1im*diagm(0=>U)];\nA0 = [2Œ≤^2*D2/Re-D4/Re-Œ≤^4*eye/Re+1im*œâ*(Œ≤^2*eye-D2) zeros(N,N);1im*Œ≤*diagm(0 => Up) (-1im*œâ+Œ≤^2/Re)*eye-D2/Re];\nnep = PEP([A0,A1,A2,A3,A4]); #Create a PEP object","category":"page"},{"location":"hydrotutorial/#Solving-with-NEP-PACK-1","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Solving with NEP-PACK","text":"","category":"section"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"Because of poorly scaled coefficient matrices, direct application of NEP-PACK's solvers on this problem is inadequate. We note that the norm of the coefficient matrices are:","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"julia> norm.(get_Av(nep))\n5-element Array{Float64,1}:\n      8.37194982854379e13\n 473949.06740743306      \n 303285.4108872535       \n      9.817076958035932  \n      0.008","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"Fortunally we can get around this issue by scaling the PEP with NEP-PACK's shift_and_scale , and solving the scaled problem T(lambda) = M(100lambda) instead.","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"sc=100;\nnep1 = shift_and_scale(nep,scale=sc);\nmult_scale = norm(nep1.A[end]);\nnep2 = PEP(nep1.A ./ mult_scale);","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"The scaled PEP has much better scaled coefficient matrices.","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"julia> norm.(get_Av(nep2))\n5-element Array{Float64,1}:\n    1.0464937285679738e8\n   59.24363342592913    \n 3791.0676360906696     \n   12.271346197544913   \n    1.0","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"In this example, we are interested in computing several eigenvalues and our region of interest for the spectrum is in the first quadrant. We use the Tensor Infinite Arnoldi (TIAR) method implemented in tiar. The method is called twice with different shifts œÉ.","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"Œª1,v1 = tiar(nep2,œÉ=0.006,v=ones(size(nep,1)),neigs=10,maxit=200,tol=1e-14);\nŒª2,v2 = tiar(nep2,œÉ=0.005+0.005im,v=ones(size(nep,1)),neigs=10,maxit=200,tol=1e-14);\nŒªtotal = [Œª1;Œª2];","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"The computed eigenvalues are scaled back to get the eigenvalues of the original problem.","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":" julia> Œª_orig = sc*Œªtotal\n20-element Array{Complex{Float64},1}:\n  0.3765784040323032 + 0.09959915134763689im\n 0.30865495875240445 + 0.008960297181538185im\n  0.4087137042139992 + 0.15906877547743775im\n  0.9787481874161135 + 0.0443939782417711im  \n  0.3430534698620533 + 0.049837687199345705im\n -0.2863097014631293 - 0.9011417554715162im  \n  0.6116671743160434 + 0.14049254864376023im\n 0.40933722321954447 + 0.15820580776369225im\n 0.43950860634751715 + 0.22808195062035772im\n 0.37687009160849716 + 0.09924325053688597im\n 0.47944942696208637 + 0.40059913080096726im\n  0.4934801111510124 + 0.520295324777746im   \n   0.496596553706975 + 0.480303769976205im   \n 0.49307795048742775 + 0.6085434637464817im  \n  0.5095613980300516 + 0.6639488620533516im  \n  0.4998069928360967 + 0.3870365082453997im  \n  0.4861657916302239 + 0.45751028495939855im\n  0.4766598864386299 + 0.5557787925858408im  \n  0.4684227095574837 + 0.4353215518427161im  \n  0.5014319544500476 + 0.5889845608687214im  ","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"The computed eigenvalues in the first quadrant can be plotted by:","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"julia> plot(real.(Œª_orig),imag.(Œª_orig),seriestype=:scatter,xaxis=[0.2,1.05],yaxis=[0,0.8])","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"The resulting plot is:","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"<br>\n<img src=\"https://nep-pack.github.io/NonlinearEigenproblems.jl/eigvals.png\" height=450>","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"This is in agreement with Figure 7.2 from Schmid‚ÄìHenningson for the eigenvalues in the first quadrant.","category":"page"},{"location":"hydrotutorial/#","page":"Tutorial 11 (Orr‚ÄìSomerfeld)","title":"Tutorial 11 (Orr‚ÄìSomerfeld)","text":"<br>\n<img src=\"https://nep-pack.github.io/NonlinearEigenproblems.jl/henningson.png\" height=450>","category":"page"},{"location":"compute_functions/#Compute-functions-1","page":"Compute functions","title":"Compute functions","text":"","category":"section"},{"location":"compute_functions/#","page":"Compute functions","title":"Compute functions","text":"The nonlinear eigenvalue problems in NEP-PACK are defined by the data stored in the corresponding NEP-class. The advised way NEP-solvers access the data is to do it through three main functions, which take the NEP-object as input.","category":"page"},{"location":"compute_functions/#","page":"Compute functions","title":"Compute functions","text":"compute_Mder: Computes a given derivative of the matrix function M(Œª).\ncompute_Mlincomb (or compute_Mlincomb!, with same documentation): Computes a linear combination of derivatives M(Œª)\ncompute_MM: Computes the block residual.","category":"page"},{"location":"compute_functions/#","page":"Compute functions","title":"Compute functions","text":"The choice of these functions as the fundamental way to access a NEP is a balancing between what applications can provide and NEP-solvers need.","category":"page"},{"location":"compute_functions/#","page":"Compute functions","title":"Compute functions","text":"A user who needs a new class of NEPs (which is not available in among the standard types) is advised to use the helper functions Mder_NEP and/or Mder_Mlincomb_NEP rather than reimplementing the compute-functions, since the helper types are more user friendly. Implementation of your own NEP-type is only advised if needed for efficiency reasons.","category":"page"},{"location":"compute_functions/#","page":"Compute functions","title":"Compute functions","text":"tip: Tip\nExamples of usage of Mder_NEP and/or Mder_Mlincomb_NEP are available in tutorials 3, 5, 6, and 7.","category":"page"},{"location":"compute_functions/#","page":"Compute functions","title":"Compute functions","text":"As a NEP-solver developer, compute_Mlincomb-calls are preferred over compute_Mder-calls, for the same reasons that algorithms that only require matrix vector products can be easier to use in a given application than an iterative algorithm using only matrix vector products. It is in general also more efficient although they produce the same result up to round-off errors:","category":"page"},{"location":"compute_functions/#","page":"Compute functions","title":"Compute functions","text":"julia> using BenchmarkTools;\njulia> n=1000; p=10;\njulia> nep=DEP([randn(n,n), randn(n,n)];\njulia> V=randn(n,p);\njulia> @btime compute_Mlincomb(nep,1.0,V);\n  478.316 Œºs (19 allocations: 80.78 KiB)\njulia> @btime for k=1:p; z[:]+=compute_Mder(nep,1.0,k)*V[:,k]; end\n  78.510 ms (183 allocations: 465.71 MiB)","category":"page"},{"location":"compute_functions/#","page":"Compute functions","title":"Compute functions","text":"The compute_Mlincomb-function exist in two variants, where compute_Mlincomb! may modify the V-matrix, but in general require less memory allocations.","category":"page"},{"location":"compute_functions/#","page":"Compute functions","title":"Compute functions","text":"For a type where only compute_Mder is implemented, the compute_Mlincomb-functionality can be provided by delegating using the function compute_Mlincomb_from_Mder, such that methods which require compute_Mlincomb can be used.","category":"page"},{"location":"compute_functions/#Compute-functions-documentation-1","page":"Compute functions","title":"Compute-functions documentation","text":"","category":"section"},{"location":"compute_functions/#","page":"Compute functions","title":"Compute functions","text":"compute_Mder","category":"page"},{"location":"compute_functions/#NonlinearEigenproblems.NEPCore.compute_Mder","page":"Compute functions","title":"NonlinearEigenproblems.NEPCore.compute_Mder","text":"compute_Mder(nep::NEP,Œª::Number [,i::Integer=0])\n\nComputes the ith derivative of nep evaluated in Œª.\n\nExample\n\nThis example shows that compute_Mder(nep,Œª,1) gives the first derivative.\n\njulia> nep=nep_gallery(\"dep0\");\njulia> œµ=1e-5;\njulia> Aminus=compute_Mder(nep,Œª-œµ);\njulia> Aminus=compute_Mder(nep,Œª-œµ);\njulia> Aplus=compute_Mder(nep,Œª+œµ);\njulia> opnorm((Aplus-Aminus)/(2œµ)-compute_Mder(nep,Œª,1))\n1.990970375089371e-11\n\n\n\n\n\n","category":"function"},{"location":"compute_functions/#","page":"Compute functions","title":"Compute functions","text":"compute_Mlincomb","category":"page"},{"location":"compute_functions/#NonlinearEigenproblems.NEPCore.compute_Mlincomb","page":"Compute functions","title":"NonlinearEigenproblems.NEPCore.compute_Mlincomb","text":"compute_Mlincomb(nep::NEP,Œª::Number,V, a::Vector=ones(size(V,2)), startder=0)\ncompute_Mlincomb!(nep::NEP,Œª::Number,V, a::Vector=ones(size(V,2)), startder=0)\n\nComputes the linear combination of derivatives\nŒ£_i a_i M^(i)(Œª) v_i starting from derivative startder. The function compute_Mlincomb! does the same but may modify the V matrix/array.\n\nExample\n\nThis example shows that compute_Mder gives a result consistent with compute_Mlincomb. Note that compute_Mlincomb is in general faster since no matrix needs to be constructed.\n\njulia> nep=nep_gallery(\"dep0\");\njulia> v=ones(size(nep,1)); Œª=-1+1im;\njulia> norm(compute_Mder(nep,Œª,1)*v-compute_Mlincomb(nep,Œª,hcat(v,v),[0,1]))\n1.0778315928076987e-15\n\n\n\n\n\n\ncompute_Mlincomb(nep::NEP,Œª::Number,V,a::Array,startder::Integer)\n\nComputes linear combination starting with derivative startder, i.e., Œ£_i a_i M^(i+startder)(Œª) v_i\n\nThe default implementation of this can be slow. Overload for specific NEP if you want efficiency, e.g., in  augnewton, iar, and others.\n\n\n\n\n\n","category":"function"},{"location":"compute_functions/#","page":"Compute functions","title":"Compute functions","text":"compute_MM","category":"page"},{"location":"compute_functions/#NonlinearEigenproblems.NEPCore.compute_MM","page":"Compute functions","title":"NonlinearEigenproblems.NEPCore.compute_MM","text":"compute_MM(nep::NEP,S,V)\n\nComputes the sum Œ£_i M_i V f_i(S) for a NEP, where S and V are matrices, and the NEP satisfies M(Œª)=Œ£_i M_i f_i(Œª).\n\nExample\n\nThis example shows that for diagonal S, the result of compute_MM can also be computed with compute_Mlincomb\n\njulia> nep=nep_gallery(\"dep0\");\njulia> D=diagm(0 => [1,2])\n2√ó2 Array{Int64,2}:\n 1  0\n 0  2\njulia> V=ones(size(n,1),2);\njulia> W=compute_MM(nep,D,V);\njulia> norm(W[:,1]-compute_Mlincomb(nep,D[1,1],V[:,1]))\n1.1102230246251565e-16\njulia> norm(W[:,2]-compute_Mlincomb(nep,D[2,2],V[:,2]))\n0.0\n\nReference\n\nProperties of the quantity Œ£_i M_i V f_i(S) for non-polynomial nonlinear eigenvalue problems were extensively used in:\n\nD. Kressner A block Newton method for nonlinear eigenvalue problems, Numer. Math., 114 (2) (2009), pp. 355-372\nC. Effenberger, Robust solution methods for nonlinear eigenvalue problems, PhD thesis, 2013, EPF Lausanne\n\n\n\n\n\n","category":"function"},{"location":"compute_functions/#Type-helpers-1","page":"Compute functions","title":"Type helpers","text":"","category":"section"},{"location":"compute_functions/#","page":"Compute functions","title":"Compute functions","text":"Mder_NEP\nMder_Mlincomb_NEP","category":"page"},{"location":"compute_functions/#NonlinearEigenproblems.NEPTypes.Mder_NEP","page":"Compute functions","title":"NonlinearEigenproblems.NEPTypes.Mder_NEP","text":"Mder_NEP(n,Mder_fun; maxder=max)\n\nCreates a NEP from its compute_Mder function defined by the function handle Mder_fun. The Mder_fun(Œª,der) takes two parameters a scalar Œª::Number, derivative number  der. The size n::Int must also be specified. The function Mder_fun(Œª,der) should return the n x n matrix corresponding to the  derth derivatve. If only a limited number of derivatives are available, maxder should be set, e.g., if not derivatives are implemented, set maxder=0. The function compute_Mlicomb is automatically available by (delegation) to compute_Mlincomb_from_Mder.\n\nNote: This is a convenience function it is not recommended for high performance computations, since, e.g., it will not maintain type stability.\n\nExample\n\nThe following example defines a linear eigenvalue problem A0+ŒªA1 defined in an external function.\n\njulia> using LinearAlgebra; # For the I function\njulia> function my_Mder(s,der)\n    A0=ones(Float64,3,3)-I; A0[1,1]=-1;\n    A1=ones(Float64,3,3)*3; A1[2,3]=0;\n    if (der==0)\n       return A0+A1*s;\n    elseif (der==1)\n       return A1;\n    else\n       return zero(A0);\n    end\nend\njulia> nep=Mder_NEP(3,my_Mder);\njulia> (Œª,v)=augnewton(nep,v=ones(3));\njulia> norm(compute_Mder(nep,Œª)*v)\n5.551115123125783e-17\n\n\n\n\n\n","category":"function"},{"location":"compute_functions/#NonlinearEigenproblems.NEPTypes.Mder_Mlincomb_NEP","page":"Compute functions","title":"NonlinearEigenproblems.NEPTypes.Mder_Mlincomb_NEP","text":"Mder_Mlincomb_NEP(n,Mder_fun, [maxder_Mder,] Mlincomb_fun, [maxder_Mlincomb])\n\nCreates a NEP from its compute_Mder and compute_Mlincombfunctions  defined by the function handles Mder_fun and Mlincomb_fun. The Mlincomb_fun(Œª,X) takes two parameters a scalar Œª::Number and a matrix X.  The size n::Int must also be specified. The function Mlincomb_fun(Œª,X) should return a vector corresponding of the linear combination of derivatives multiplied with the vectors in X. If only a limited number of derivatives are implemented, maxder_Mder or maxder_Mlincomb should be set, e.g., if not derivatives are implemented, set maxder=0.\n\nSee also Mder_NEP.\n\nNote: This is a convenience function it is not recommended for high performance computations, since, e.g., it will not maintain type stability.\n\nExample\n\nThe following example defines a linear eigenvalue problem A0+ŒªA1 defined in an external function.\n\njulia> using LinearAlgebra; # For the I function\njulia> function my_Mder(s,der)\n    A0=ones(Float64,3,3)-I; A0[1,1]=-1;\n    A1=ones(Float64,3,3)*3; A1[2,3]=0;\n    if (der==0)\n       return A0+A1*s;\n    elseif (der==1)\n       return A1;\n    else\n       return zero(A0);\n    end\nend\njulia> function my_Mlincomb(s,X) # Compute linear comb of derivatives\n    A0=ones(Float64,3,3)-I; A0[1,1]=-1;\n    A1=ones(Float64,3,3)*3; A1[2,3]=0;\n    if (size(X,2) <= 1)\n       return A0*X[:,1]+s*A1*X[:,1]\n    else # This means: size(X,2) => 2\n       return A0*X[:,1]+A1*(s*X[:,1]+X[:,2]);\n    end\nend\njulia> nep=Mder_Mlincomb_NEP(3,my_Mder,my_Mlincomb);\njulia> (Œª,v)=augnewton(nep,v=[1.0; 2.3; 0.0])\njulia> norm(compute_Mder(nep,Œª)*v)\n6.798699777552591e-17\n\n\n\n\n\n","category":"type"},{"location":"compute_functions/#","page":"Compute functions","title":"Compute functions","text":"compute_Mlincomb_from_Mder","category":"page"},{"location":"compute_functions/#NonlinearEigenproblems.NEPCore.compute_Mlincomb_from_Mder","page":"Compute functions","title":"NonlinearEigenproblems.NEPCore.compute_Mlincomb_from_Mder","text":"compute_Mlincomb_from_Mder(nep::NEP,Œª::Number,V,a)\n\nThe function computes Mlincomb by a call to compute_Mder. This function is slow since it requires the construction of the matrices. Usage normally by overloading in this way\n\n    compute_Mlincomb(nep::MyNEP,Œª::Number,V,a)=compute_Mlincomb_from_Mder(nep,Œª,V,a)\n\n\n\n\n\n","category":"function"},{"location":"compute_functions/#","page":"Compute functions","title":"Compute functions","text":"compute_Mlincomb_from_MM","category":"page"},{"location":"compute_functions/#NonlinearEigenproblems.NEPCore.compute_Mlincomb_from_MM","page":"Compute functions","title":"NonlinearEigenproblems.NEPCore.compute_Mlincomb_from_MM","text":"compute_Mlincomb_from_MM(nep::NEP,Œª::Number,V,a)\n\nThis function provides a compute_Mlincomb-function call  by invoking a call to compute_MM. The underlying mathematical relationship  is described in github issue #2 and #3.\n\nThe standard usage is by the following command:\n\ncompute_Mlincomb(nep::MyNEP,Œª::Number,V,a)=compute_Mlincomb_from_MM(nep,Œª,V,a)\n\n\n\n\n\n","category":"function"},{"location":"#NEP-PACK-1","page":"Introduction","title":"NEP-PACK","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"NEP-PACK is a package with implementations of methods to solve nonlinear eigenvalue problems of the type: Find (Œªv)inmathbbCtimesmathbbC^n such that","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"M(Œª)v=0","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"and vneq 0.","category":"page"},{"location":"#Getting-started-1","page":"Introduction","title":"Getting started","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"Install it as a registered  package in Julia's REPL package mode by typing ] add Nonline...:","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"julia> ]\n(v1.0) pkg> add NonlinearEigenproblems","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"Then we can start to load the NEP-PACK package","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"julia> using NonlinearEigenproblems","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"As a first example we will solve the NEP associated with the matrix polynomial","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"M(Œª)=beginbmatrix13newline56endbmatrix+\nŒªbeginbmatrix34newline66endbmatrix+\nŒª^2beginbmatrix10newline01endbmatrix","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"The following code creates this NEP, by constructing an object called PEP, an abbreviation for polynomial eigenvalue problem. It subsequencly solves it using the NEP solution method implemented in polyeig:","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"julia> A0=[1.0 3; 5 6]; A1=[3.0 4; 6 6]; A2=[1.0 0; 0 1.0];\njulia> nep=PEP([A0,A1,A2])\nPEP(2, Array{Float64,2}[[1.0 3.0; 5.0 6.0], [3.0 4.0; 6.0 6.0], [1.0 0.0; 0.0 1.0]])\njulia> Œª,v=polyeig(nep)\n(Complex{Float64}[1.36267+0.0im, -0.824084+0.280682im, -0.824084-0.280682im, -8.7145+0.0im], Complex{Float64}[-1.0+0.0im 0.739183-0.196401im 0.739183+0.196401im 0.627138+0.0im; 0.821812+0.0im -0.501408-0.375337im -0.501408+0.375337im 1.0+0.0im])","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"You have now solved your first nonlinear eigenvalue problem with NEP-PACK.","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"In order to verify that we have a solution, we can check that  M(Œª) is singular, with a singular vector v such that M(Œª)v=0:","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"julia> Œª1=Œª[1]; v1=v[:,1];\njulia> using LinearAlgebra # the norm-function is in this Julia package\njulia> norm(A0*v1+Œª1*A1*v1+Œª1^2*v1)/norm(v1)\n1.1502634749464687e-14","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"tip: Tip\nMATLAB users: Do you have a NEP defined in MATLAB? You can solve MATLAB-defined NEPs with this package.  See the MATLAB tutorial. We also have some MATLAB implementations of the solvers in NEP-PACK in a separate repository.","category":"page"},{"location":"#Accessing-more-complicated-applications-1","page":"Introduction","title":"Accessing more complicated applications","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"We have made benchmark examples available through the function nep_gallery:","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"julia> nep=nep_gallery(\"dep0\",100);\njulia> size(nep)\n(100, 100)\njulia> Œª,v=mslp(nep,tol=1e-10);\njulia> Œª\n0.23169217667341738 - 2.1866254654451488e-16im\njulia> size(v)\n(100,)\njulia> resnorm=norm(compute_Mlincomb(nep,Œª,v))\n3.124042808475689e-14","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"Information about the gallery can be found by typing ?nep_gallery. The second arument in the call to nep_gallery is a problem parameter, in this case specifying that the  size of the problem should be 100. The example solves the problem with the NEP-algorithm MSLP. The parameter tol specifies the tolerance for iteration termination.","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"note: Note\nAll the NEP-solvers have considerble documentation easily available. Every NEP-solver has documentation accompanied with at least one example, and references to corresponding research papers, which we strongly recommend you to cite if you use the method. This is available to you in Julia's repl-prompt. Type ?mslp and you will see an example how to use mslp and that citation credit should go to A. Ruhe, Algorithms for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 10 (1973) 674-689. This documentation is the same as the online documentation under the tab NEP-solvers.","category":"page"},{"location":"#A-model-of-a-neuron-1","page":"Introduction","title":"A model of a neuron","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"The following (delay) differential equation models the interaction of two neurons","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"dotx_1(t)=-kappa x_1(t)+betatanh(x_1(t-tau_3))+a_1tanh(x_2(t-tau_2))","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"dotx_2(t)=-kappa x_2(t)+betatanh(x_2(t-tau_3))+a_2tanh(x_1(t-tau_1))","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"See L. P. Shayer and S. A. Campbell.  Stability, bifurcation and multistability in a system of two coupled neurons with multiple time delays. SIAM J. Applied Mathematics , 61(2):673‚Äì700, 2000. It is also available as a first demo in DDE-BIFTOOL. The linear stability analysis of this problem requires the solution of a nonlinear eigenvalue problem","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"M(Œª)=-ŒªI+A_0+A_1e^-tau_1Œª+A_2e^-tau_2Œª+A_3e^-tau_3Œª","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"where the matrices are the Jacobian at the stationary solution. For the zero stationary solution, the matrices are","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"kappa=0.5; a2=2.34; a1=1; beta=-1;\nA0=-kappa*[1 0; 0 1];\nA1=a2*[0 0; 1 0];\nA2=a1*[0 1; 0 0];\nA3=beta*[1 0; 0 1];","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"We can now create the nonlinear eigenvalue problem and determine the stability by first creating the problem","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"julia> tauv=[0;0.2;0.2;1.5];\njulia> dep=DEP([A0, A1,   A2, A3],tauv);","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"The constructor  DEP is an abbreviation for a delay eigenvalue problem, which is a NEP with exponential terms stemming from the stability analysis of a delay-differential equation. See Types and data-structures for other NEP-types. You can now solve this NEP, for instance, with the infinite Arnoldi method:","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"julia> Œª,V=iar_chebyshev(dep,maxit=100); # This takes some time the first time is run due to JIT-compiler","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"The figure in a demo of DDE-BIFTOOL http://ddebiftool.sourceforge.net/demos/neuron/html/demo1_stst.html#3 can be directly generated by","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"using PyPlot\n# Hardcoded/cached values in the documentation compilation  # hide\nŒª=[ -0.09712795241565722 + 2.612885243197631e-19im # hide\n         0.30886599775839135 + 4.146563548756125e-18im # hide\n        -0.45584765486526174 + 1.6884551234089458im # hide\n         -0.4558476548652613 - 1.6884551234089418im # hide\n         -0.8832708076887316 + 5.325050575287575im # hide\n         -0.8832708076887288 - 5.3250505752875625im] # hide\nplot(real(Œª),imag(Œª),\"*\");\nxlabel(\"real(Œª)\"); ylabel(\"imag(Œª)\");\nsavefig(\"neuron_eigvals.svg\"); nothing # hide","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"(Image: )","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"tip: Tip\nThis problem is also available in the Gallery by calling dep=nep_gallery(\"neuron0\"). Most of the NEPs constructed in the tutorials are also available in corresponding gallery problems. See all gallery problems under NEP Gallery. In particular, note that the problems in the Berlin-Manchester collection of problems NLEVP are also directly available.","category":"page"},{"location":"#The-\"gun\"-benchmark-problem-1","page":"Introduction","title":"The \"gun\" benchmark problem","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"One of the most common benchmark problems for NEPs is the so-called \"gun\"-problem. It models an electromagnetic cavity, and it is directly available in the NEP-PACK gallery. (See gallery references or type ?nep_gallery at the repl-prompt.) This is how you can set it up and solve it with the block Newton method:","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"julia> nep=nep_gallery(\"nlevp_native_gun\");\njulia> n=size(nep,1)\njulia> S=150^2*[1.0 0; 0 1]; V=[[1 0; 0 1]; zeros(n-2,2)];\njulia> (Z,X)=blocknewton(nep,S=S,X=V,logger=1,armijo_factor=0.5,maxit=20)\nIteration 1: Error: 6.081316e+03\nIteration 2: Error: 1.701970e-02 Armijo scaling=0.031250\nIteration 3: Error: 1.814887e-02 Armijo scaling=0.250000\n...\nIteration 13: Error: 6.257442e-09\nIteration 14: Error: 2.525942e-15","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"This algorithm returns a partial Schur factorization of the NEP, and therefore the eigenvalues of the small matrix Z are eigenvalues of the problem. An eigenpair of the NEP can be extracted by diagonalizing:","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"julia> using LinearAlgebra\njulia> (Œõ,P)=eigen(Z);\njulia> VV=X*P;  # Construct the eigenvector matrix\njulia> v=VV[:,1]; Œª=Œõ[1]\n61330.208714730004 + 63185.15983933589im\njulia> norm(compute_Mlincomb(nep,Œª,v)) # Very small residual\n1.8270553408452648e-16","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"If you use the NEP-algorithms for research, please give the author of the algorithm credit by citiation. The recommended citation can be found in the function documentation, e.g., ?blocknewton.","category":"page"},{"location":"#Your-own-NEP-nonlinearity-1","page":"Introduction","title":"Your own NEP nonlinearity","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"As an application researcher, we recommend that you first try to express your problem in the following form since it gives access to several efficient routines associated with the NEP, in turn making it possible to use many NEP-solvers. A problem that can be expressed as a (short) Sum of Products of Matrices and Functions can be represented with the objects of type SPMF in NEP-PACK. For instance, a problem with three terms","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"M(Œª) = A+ŒªB+e^sin(Œª2)C","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"can be created by","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"julia> A=(1:4)*(1:4)'+I; B=diagm(1 => [1,2,3]); C=ones(4,4);\njulia> f1= Œª-> one(Œª);\njulia> f2= Œª-> Œª;\njulia> f3= Œª-> exp(sin(Œª/2))\njulia> nep=SPMF_NEP([A,B,C],[f1,f2,f3]);","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"The NEP can now be solved with many algorithms, e.g.,","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"julia> Œª,v=quasinewton(nep,Œª=3)\n(3.176099007141426 + 0.0im, Complex{Float64}[37.1759+0.0im, -21.3016+0.0im, 0.0937992+0.0im, -1.15711+0.0im])","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"Note that the functions f1,f2 and f3 have to be defined for scalar values and for matrices (in the matrix function sense, not elementwise sense). This is the reason f1 needs to be defined as one(Œª), instead of just 1.","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"As usual, you can check that we computed a sensible solution:","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"julia> (A+B*Œª+C*exp(sin(Œª/2)))*v\n4-element Array{Complex{Float64},1}:\n  -6.586145128765412e-14 + 0.0im\n  2.8285461200559146e-14 + 0.0im\n -4.1550357082583515e-14 + 0.0im\n  -8.815768150428286e-15 + 0.0im","category":"page"},{"location":"#What-now?-1","page":"Introduction","title":"What now?","text":"","category":"section"},{"location":"#","page":"Introduction","title":"Introduction","text":"Now you are ready to try out one of our tutorials on artificial boundary conditions, boundary element method, contour integration, or deflation. See also the other tutorials (in the side-bar), or have a look at the examples in NEP-solvers and  NEP Gallery.","category":"page"},{"location":"#","page":"Introduction","title":"Introduction","text":"(Image: To the top)","category":"page"},{"location":"types/#Types-and-Data-structures-1","page":"Types & Data structures","title":"Types & Data structures","text":"","category":"section"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"Nonlinear eigenvalue problems in NEP-PACK are represented by objects of the type NEP. Each NEP-object needs to provide compute functions as we describe in the manual page on compute functions. Efficient compute functions are already implemented for many common and several general types.","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"In the section specific types below, we list a number of common classes. As a user, first see if your problem fits to one of those classes, as NEP-PACK has very efficient compute functions for these classes. If your NEP does not fit into any of the specific types, we recommend that a user tries to specify the problem as an SPMF_NEP, which is described in the section general types. If your problem can be phrased as a sum of two specific or general types, it is recommended that you use the SumNEP-type. NEP-PACK also supports efficient computation with low-rank NEPs via the LowRankFactorizedNEP.","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"If your NEP is not easily expressed as an SPMF_NEP, you may want to use the helper types.","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"The types also have a number of associated operations and transformation functions. The following example illustrates how you can resample a NEP (by interpolation with a Chebyshev polynomial basis in Chebyshev points provided by the ChebPEP constructor) and apply a NEP-solver which requires many function evaluations, in this case contour_beyn. The two-stage solution approach is much more efficient.","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"julia> nep_bem=nep_gallery(\"bem_fichera\");\njulia> cheb_nep=ChebPEP(nep_bem,20,0,10); # resample the NEP with 20 cheb points\n 32.651313 seconds (263.16 M allocations: 36.279 GiB, 17.19% gc time)\njulia> @time (Œª1,v1)=contour_beyn(nep_bem,radius=[5 0.2],œÉ=5.0, N=100,k=10,);\n180.329069 seconds (1.39 G allocations: 183.462 GiB, 13.01% gc time)\njulia> @time (Œª2,v2)=contour_beyn(cheb_nep,radius=[5 0.2],œÉ=5.0, N=100,k=10,);\n  4.319376 seconds (362.34 k allocations: 8.856 GiB, 12.42% gc time)","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"Note that running the contour integral method on the cheb_nep is much faster, even if we take into account that the resampling takes some computational effort. The computed solutions are very similar","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"julia> Œª1\n2-element Array{Complex{Float64},1}:\n 6.450968052414575 - 4.819767260258272e-5im\n 8.105873440358572 - 0.00012794471501522612im\njulia> Œª2\n2-element Array{Complex{Float64},1}:\n 6.450968052984224 - 4.819762104884087e-5im\n 8.105873439472735 - 0.0001279450670266529im","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"Moreover, if we want a very accurate solution, we can run a locally convergence iterative method on the original problem. It converges in very few iterations:","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"julia> (Œª2_1,v1_1)=quasinewton(nep_bem,Œª=Œª2[1], v=v2[:,1],logger=1);\nPrecomputing linsolver\niter 1 err:3.638530108313503e-12 Œª=6.450968052984224 - 4.819762104884087e-5im\niter 2 err:1.2789912958165988e-14 Œª=6.450968052419756 - 4.819768321350077e-5im\njulia> (Œª2_2,v1_2)=quasinewton(nep_bem,Œª=Œª2[2], v=v2[:,2],logger=1)\nPrecomputing linsolver\niter 1 err:3.4824421200567996e-12 Œª=8.105873439472735 - 0.0001279450670266529im\niter 2 err:2.05407750614131e-14 Œª=8.105873440343123 - 0.00012794469925178411im","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"tip: Tip\nThe use of of Chebyshev interpolation in combination with the boundary element method (but with a companion linearization approach) was presented in  Effenberger and Kressner. \"Chebyshev interpolation for nonlinear eigenvalue problems.\" BIT Numerical Mathematics 52.4 (2012): 933-951. See also the tutorial on boundary element method.","category":"page"},{"location":"types/#Specific-types-1","page":"Types & Data structures","title":"Specific types","text":"","category":"section"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"DEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.DEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.DEP","text":"type DEP <: AbstractSPMF\nfunction DEP(AA::Vector{AbstractMatrix} [,tauv::Vector=[0,1.0]])\n\nA DEP (Delay Eigenvalue problem) is a problem defined by the sum\n\nM(Œª)=-ŒªI + Œ£_i A_i exp(-œÑ_i Œª)\n\nwhere all of the matrices are of size nn. This type of NEP describes the stability of time-delay systems.\n\nThe construction takes the system matrices A_i, and tauv is a vector of the values  œÑ_i.\n\nExample:\n\njulia> A0=randn(3,3); A1=randn(3,3);\njulia> tauv=[0,0.2] # Vector with delays\njulia> dep=DEP([A0,A1],tauv)\njulia> Œª=3.0;\njulia> M1=compute_Mder(dep,Œª)\njulia> M2=-Œª*I+A0+A1*exp(-tauv[2]*Œª)\njulia> norm(M1-M2)\n0.0\n\n\n\n\n\n","category":"type"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"There are two types to represent PEPs natively in NEP-PACK. You can use a monomial basis with PEP or a Chebyshev basis with ChebPEP.","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"PEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.PEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.PEP","text":"struct PEP <: AbstractSPMF\nfunction PEP(AA::Vector{AbstractMatrix})\n\nThe type PEP defines a polynomial eigenvalue  problem via its monomial coefficients. A polynomial eigenvalue problem (PEP) is defined by the sum the\n\nŒ£_i A_i Œª^i\n\nwhere i = 012, and  all of the matrices are of size nn. The vector AA contains A_1.\n\nExample\n\njulia> A0=[1.0 3; 4 5]; A1=A0.+one(2); A2=ones(2,2);\njulia> pep=PEP([A0,A1,A2])\njulia> compute_Mder(pep,3)-(A0+A1*3+A2*9)\n2√ó2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0\n\nSee also polyeig, companion, ChebPEP, interpolate.\n\n\n\n\n\n","category":"type"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"ChebPEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.ChebPEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.ChebPEP","text":"ChebPEP(orgnep::NEP,k,[a=-1,[b=1]] [,cosine_formula_cutoff=5])\n\nThe type ChebPEP<:AbstractSPMF represents a polynomial function where the function is stored using a Chebyshev basis scaled to the interval [a,b], i.e.,\n\nM(Œª)= B_0T_0(Œª)++B_k-1T_k-1(Œª)\n\nwhere T_i are the scaled and shifted Chebyshev polynomials.\n\nThe creator ChebPEP takes nep::NEP as an input and interpolates this NEP in k Chebyshev nodes, resulting in a polynomial of degree k-1, represented by its coefficients in the Chebyshev basis. Interpolation in Chebyshev nodes is known to have attractive approximation properties, as well as robustness with respect to round-off errors.\n\nThe kwarg cosine_formula_cutoff decides how the Chebyshev polynomials should be computed. For larger degrees, one wants to use the cosine formula, whereas for low degrees the explicit monomial expression is more efficient. The explicit monomial expression will be used for degrees lower than cosine_formula_cutoff.\n\nExample:\n\njulia> nep=nep_gallery(\"dep0\");\njulia> chebpep=ChebPEP(nep,9);\njulia> using LinearAlgebra;\njulia> norm(compute_Mder(nep,0.3)-compute_Mder(chebpep,0.3))\n1.6920305863798614e-8\njulia> chebpep=ChebPEP(nep,19); # Better interpolation\njulia> norm(compute_Mder(nep,0.3)-compute_Mder(chebpep,0.3))\n2.2782119183158333e-15\n\nSee also: polyeig, PEP\n\n\n\n\n\n","category":"type"},{"location":"types/#REP-1","page":"Types & Data structures","title":"REP","text":"","category":"section"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"The Rational Eigenvalue Problem is described by:","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"REP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.REP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.REP","text":"struct REP <: AbstractSPMF\nfunction REP(A,poles)\n\nA REP represents a rational eigenvalue problem. The REP is defined by the sum Œ£_i A_i s_i(Œª)q_i(Œª), where i = 0,1,2,..., all of the matrices are of size n times n and si and qi are polynomials.\n\nThe constructor takes the matrices A_i and a sequence of poles as input (not complete).\n\nExample\n\njulia> A0=[1 2; 3 4]; A1=[3 4; 5 6];\njulia> nep=REP([A0,A1],[1,3]);\njulia> compute_Mder(nep,3)\n2√ó2 Array{Float64,2}:\n NaN  NaN\n NaN  NaN\n\n\n\n\n\n","category":"type"},{"location":"types/#General-types-1","page":"Types & Data structures","title":"General types","text":"","category":"section"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"The basic class is the abstract class NEP which represents a NEP. All other defined NEPs should inherit from NEP, or from a more specialized version; see, e.g., ProjectableNEP or AbstractSPMF.","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"NEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPCore.NEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPCore.NEP","text":"abstract NEP\n\nA NEP object represents a nonlinear eigenvalue problem. All NEPs should implement\n\nsize(nep::NEP,d)\n\nand at least one of the following\n\nM = compute_Mder(nep::NEP,Œª::Number,i::Integer=0)\nV = compute_Mlincomb(nep::NEP,Œª::Number,V::AbstractVecOrMat,a::Vector) (or compute_Mlincomb!)\nMM = compute_MM(nep::NEP,S,V)\n\n\n\n\n\n","category":"type"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"Below we list the most common types built-in to NEP-PACK, and further down how you can access the NEP. However, the structure is made for extendability, and hence it is possible for you to extend with your own class of NEPs.","category":"page"},{"location":"types/#SPMF-1","page":"Types & Data structures","title":"SPMF","text":"","category":"section"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"One of the most common problem types is the SPMF_NEP. SPMF is short for Sum of Products of Matrices and Functions and the NEP is described by","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"M(Œª) = sum_i A_i f_i(Œª)","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"The constructor of the SPMF_NEP, takes the the matrices and the functions, but also a number of other (optional) parameters which may increase performance or preserve underlying types.","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"SPMF_NEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.SPMF_NEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.SPMF_NEP","text":"struct SPMF_NEP{T<:AbstractMatrix,Ftype}  <: AbstractSPMF{T}\nfunction SPMF_NEP(AA, fii [,check_consistency=true] [,Schur_fact = false]\n                  [,align_sparsity_patterns = false] [,Ftype=ComplexF64])\n\nAn SPMF_NEP is a NEP defined by a Sum of Products of Matrices and Functions, i.e.,\n\nM(Œª)=_i A_i f_i(Œª)\n\nAll of the matrices A_0 are of size nn and f_i are a functions. The  functions f_i must be defined for matrices in the standard matrix function sense. The constructor creates a SPMF_NEP consisting of matrices AA and functions fii.\n\nParameters\n\nAA is a Vector of matrices. The matrices have to be of the same type. If you need a NEP with different types you can use SumNEP to construct a sum of two SPMF_NEP.\nfii is a Vector of functions. Each function takes one parameter S. The functions must be available both as a scalar valid function and a matrix function. If S is a square matrix, fii[k](S) musst also be a square matrix. If S is a scalar fii[k](S) is a scalar.\ncheck_consistency (default true) determines if we should initiate by running tests to verify that the fii satisfies the conditions that every function is valid both for matrices and scalars. This is done by using @code_typed and the functions need to be type-stable in that sense.\nalign_sparsity_patterns (default false) has effect only for sparse matrices (SparseMatrixCSC). If align_sparsity_patterns=true the SparseMatrixCSC matrices will be replaced by equivalent SparseMatrixCSC matrices where the colptr and rowval are identical. This increases the speed of some functions, e.g., compute_Mder. If align_sparsity_patterns=true the matrices in the NEP should be considered read only. If the sparsity patterns are completely or mostly distinct, it may be more efficient to set this flag to false.\nFtype (default ComplexF64) determines an underlying type of the functions. The output of any function should be \"smaller\" than the promoted type of the input and Ftype. More precisely, if F=fii[k], then the type logic is as follows eltype(F(Œª))=promote_type(eltype(Œª),Ftype).\nSchur_fact (default false) determines if the compute_MM function should triangularize the matrix before carrying out the computation. This can be faster for large matrices.\n\nExample\n\njulia> A0=[1 3; 4 5]; A1=[3 4; 5 6];\njulia> id_op=S -> one(S) # Note: We use one(S) to be valid both for matrices and scalars\njulia> exp_op=S -> exp(S)\njulia> nep=SPMF_NEP([A0,A1],[id_op,exp_op]);\njulia> compute_Mder(nep,1)-(A0+A1*exp(1))\n2√ó2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0\n\n\n\n\n\n","category":"type"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"AbstractSPMF\nget_Av\nget_fv","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.AbstractSPMF","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.AbstractSPMF","text":"abstract  AbstractSPMF <: ProjectableNEP\n\nAn AbstractSPMF is an abstract class representing NEPs which can be represented as a Sum of products of matrices and functions M(Œª)=Œ£_i A_i f_i(Œª), where i = 0,1,2,..., all of the matrices are of size n times n and f_i are functions.\n\nAny AbstractSPMF has to have implementations of get_Av() and get_fv() which return the functions and matrices.\n\n\n\n\n\n","category":"type"},{"location":"types/#NonlinearEigenproblems.NEPTypes.get_Av","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.get_Av","text":"get_Av(nep::AbstractSPMF)\n\nReturns an array of matrices A_i in the AbstractSPMF: M(Œª)=Œ£_i A_i f_i(Œª)\n\n\n\n\n\n","category":"function"},{"location":"types/#NonlinearEigenproblems.NEPTypes.get_fv","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.get_fv","text":"get_Av(nep::AbstractSPMF)\n\nReturns an Array of functions (that can be evaluated both as scalar and matrix functions) f_i in the AbstractSPMF: M(Œª)=Œ£_i A_i f_i(Œª)\n\n\n\n\n\n","category":"function"},{"location":"types/#Projectable-NEP-types-1","page":"Types & Data structures","title":"Projectable NEP types","text":"","category":"section"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"There are also types associated with projection described on  the projection manual page:","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"ProjectableNEP\nProj_NEP","category":"page"},{"location":"types/#SumNEP-1","page":"Types & Data structures","title":"SumNEP","text":"","category":"section"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"It is also possible to consider NEPs that are sums of other NEPs. For such situations there are SumNEPs. Specifically GenericSumNEP and SPMFSumNEP. Both are constructed using the function SumNEP.","category":"page"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"SumNEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.SumNEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.SumNEP","text":"SumNEP{nep1::NEP,nep2::NEP}\nSumNEP{nep1::AbstractSPMF,nep2::AbstractSPMF}\n\nSumNEP is a function creating an object that corresponds to a sum of two NEPs, i.e., if nep is created by SumNEP it is defined by\n\nM(Œª)=M_1(Œª)+M_2(Œª)\n\nwhere M_1 and M_2 are defined by nep1 and nep2.\n\nExample:\n\njulia> nep1=DEP([ones(3,3),randn(3,3)])\njulia> nep2=PEP([ones(3,3),randn(3,3),randn(3,3)])\njulia> sumnep=SumNEP(nep1,nep2);\njulia> s=3.0;\njulia> M=compute_Mder(sumnep,s);\n3√ó3 Array{Float64,2}:\n  8.54014     6.71897   7.12007\n -0.943908  -13.0795   -0.621659\n  6.03155    -7.26726  -6.42828\njulia> M1=compute_Mder(nep1,s);\njulia> M2=compute_Mder(nep2,s);\njulia> M1+M2  # Same as M\n3√ó3 Array{Float64,2}:\n  8.54014     6.71897   7.12007\n -0.943908  -13.0795   -0.621659\n  6.03155    -7.26726  -6.42828\n\nSee also: SPMFSumNEP, GenericSumNEP\n\n\n\n\n\n","category":"function"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"GenericSumNEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.GenericSumNEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.GenericSumNEP","text":"struct GenericSumNEP{NEP1<:NEP,NEP2<:NEP}  <: NEP\n\nSee also: SumNEP, SPMFSumNEP\n\n\n\n\n\n","category":"type"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"SPMFSumNEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.SPMFSumNEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.SPMFSumNEP","text":"struct SPMFSumNEP{NEP1<:AbstractSPMF,NEP2<:AbstractSPMF}  <: AbstractSPMF{AbstractMatrix}\n\nSee also: SumNEP, GenericSumNEP\n\n\n\n\n\n","category":"type"},{"location":"types/#Low-rank-NEPs-1","page":"Types & Data structures","title":"Low-rank NEPs","text":"","category":"section"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"LowRankFactorizedNEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.LowRankFactorizedNEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.LowRankFactorizedNEP","text":"struct LowRankFactorizedNEP <: AbstractSPMF\nfunction LowRankFactorizedNEP(L::Vector,U::Vector,f::Vector)\nfunction LowRankFactorizedNEP(L::Vector,U::Vector,A::Vector, f::Vector)\n\nRepresentation of a NEP which has low rank in the sense that it is an SPMF where each of the terms are factorized: A[i]=L[i]*U[i]'. The factorization is provided in the L and U vectors and the full matrix A[i] can be either provided (or is otherwise implicitly computed).\n\nExample:\n\njulia> L=randn(5,1); U=randn(5,1);\njulia> f=S->exp(S)\njulia> nep=LowRankFactorizedNEP([L],[U],[f]);\njulia> X=randn(5,2);\njulia> norm(compute_Mlincomb(nep,0.0,X)-L*U'*X*ones(2),1)\n6.661338147750939e-16\n\n\n\n\n\n","category":"type"},{"location":"types/#Helper-types-1","page":"Types & Data structures","title":"Helper types","text":"","category":"section"},{"location":"types/#","page":"Types & Data structures","title":"Types & Data structures","text":"There are also the helper types Mder_NEP and Mder_Mlincomb_NEP. These are further described in the section about Compute functions","category":"page"}]
}
