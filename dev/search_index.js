var documenterSearchIndex = {"docs":
[{"location":"tutorial_linsolve/#Tutorial:-Specifying-linear-solvers","page":"Tutorial 11 (Linear solvers)","title":"Tutorial: Specifying linear solvers","text":"","category":"section"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"Many of the NEP-solvers are based on solving linear systems of the type","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"M(λ)x=b","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"In some methods the linear system matrices are the same, i.e., λ does not change. You can specify which numerical methods should be used to solve the linear system when you call a NEP-solver. This tutorial illustrates this functionality, and finally shows how you can specify your own method for linear systems.","category":"page"},{"location":"tutorial_linsolve/#Built-in-linear-solvers","page":"Tutorial 11 (Linear solvers)","title":"Built-in linear solvers","text":"","category":"section"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"The linear solver is specified with the linsolvercreator keyword argument in most NEP-solvers. Let us contruct an example which we will solve with several methods. The matrix M(λ) is sparse, and the nonlinearity is an exponential term:","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"using NonlinearEigenproblems, SparseArrays, LinearAlgebra;\nn=100;\nα=0.01;\nA=spdiagm(0=>ones(n),1=>α*ones(n-1),-3=>α*ones(n-3));\nB=spdiagm(0=>ones(n));\nC=spdiagm(0=>(1:n)/n);\nnep= SPMF_NEP([A,B,C],[s->one(s),s->s,s->exp(s)],align_sparsity_patterns=true);\nλ0=-1.3; # Starting guess","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"Let us first solve it with the  resinv method, using the default solver for the linear system:","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"julia> (λ,x)=resinv(nep,λ=λ0,v=ones(n),logger=1,tol=1e-16);\nPrecomputing linsolver\niter 1 err:0.0066371687626530325 λ=-1.3 + 0.0im\niter 2 err:0.005517924619612248 λ=-1.175478914232863 + 0.0im\niter 3 err:0.002478390282482615 λ=-1.237914206446667 + 0.0im\niter 4 err:0.0007175125397164684 λ=-1.2715354474842264 + 0.0im\n...\niter 68 err:1.9815836266850424e-16 λ=-1.2845622481786096 + 0.0im\niter 69 err:1.2398848173585647e-16 λ=-1.28456224817861 + 0.0im\niter 70 err:8.341032972349128e-17 λ=-1.2845622481786103 + 0.0im\n","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"We will carry out some timing experiments, so let's use the BenchmarkTools-package and switch off printouts in the NEP-solver:","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"julia> using BenchmarkTools\njulia> @btime (λ,x)=resinv(nep,λ=λ0,v=ones(n),tol=1e-16);\n  8.170 ms (32457 allocations: 10.99 MiB)","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"The linear system that has to be solved in every iteration in resinv has a constant system matrix, and therefore a prefactorization (typically an LU-factorization) is useful. This is done with the FactorizeLinSolverCreator, which is actually the default behaviour, so we get no substantial difference when we specify a creator if the type FactorizeLinSolverCreator.","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"julia> creator=FactorizeLinSolverCreator();\njulia> @btime (λ,x)=resinv(nep,λ=λ0,v=ones(n),maxit=100,linsolvercreator=creator,tol=1e-16);\n  8.104 ms (32447 allocations: 10.98 MiB)","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"If we do not want to use a prefactorization, you can specify BackslashLinSolverCreator as your creator object.","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"julia> creator=BackslashLinSolverCreator();\njulia> @btime (λ,x)=resinv(nep,λ=λ0,v=ones(n),maxit=100,linsolvercreator=creator,tol=1e-16);\n  19.985 ms (36932 allocations: 22.31 MiB)","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"This does not use a prefactorization and is therefore slower.","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"The above approach corresponded to direct methods for linear systems. You can also use iterative methods, e.g., the GMRES-method. The GMRES-method is available in the GMRESLinSolverCreator function. Iterative methods in general need preconditioners. We continue the example and use a diagonal preconditioner:","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"julia> D0=(Diagonal(compute_Mder(nep,λ0))); # Preconditioner\njulia> creator=GMRESLinSolverCreator(Pl=D0, tol=1e-2);","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"All the keyword arguments in the call GMRESLinSolverCreator are passed to gmres!. Hence, the tol here  specifies a termination criteria for the GMRES-method, and Pl specifies the left preconditioner, in this case just a diagonal matrix.","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"julia> (λ,x)=resinv(nep,λ=λ0,v=ones(n),maxit=100,linsolvercreator=creator,logger=1,tol=1e-16);\nPrecomputing linsolver\niter 1 err:0.0066371687626530325 λ=-1.3 + 0.0im\niter 2 err:0.005516840431746622 λ=-1.175478914232863 + 0.0im\niter 3 err:0.002478456565315529 λ=-1.2379013065364441 + 0.0im\niter 4 err:0.0007137260829914206 λ=-1.271604846382212 + 0.0im\n...\niter 69 err:1.4948517196633335e-16 λ=-1.2845622481786099 + 0.0im\niter 70 err:1.0136830543996086e-16 λ=-1.28456224817861 + 0.0im\niter 71 err:6.468407765141646e-17 λ=-1.2845622481786103 + 0.0im\n","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"The printout reveals that we need one more more iteration, than with a direct method. In terms of computation time, this approach can however still be competitive:","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"julia> @btime (λ,x)=resinv(nep,λ=λ0,v=ones(n),maxit=100,linsolvercreator=creator,tol=1e-16);\n  10.912 ms (49183 allocations: 18.95 MiB)","category":"page"},{"location":"tutorial_linsolve/#Your-own-linear-solver","page":"Tutorial 11 (Linear solvers)","title":"Your own linear solver","text":"","category":"section"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"There are many ways to solve linear systems in Julia, e.g., by using package such as KrylovKit.jl, Pardiso.jl or KrylovMethods.jl. These are not natively supported by NEP-PACK, but due to the extendability of the LinSolverCreator-objects specified above, you can still use them. We illustrate the extendability by creating a linear solver based on solving a Schur complement. The following helper-function for the Schur complement solve will be used later.","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"function schur_complement_lin_solve(AA,b,n0)\n  A=AA[1:n0,1:n0];\n  B=AA[1:n0,(n0+1):end];\n  C=AA[(n0+1):end,1:n0];\n  D=AA[(n0+1):end,(n0+1):end];\n  S=D-C*(A\\B); # Schur complement\n  b1=b[1:n0]; b2=b[(n0+1):end];\n  Ainvb1=A\\b1; Sinvb2=S\\b2;\n  # Formula for the linear solve:\n  x1=A\\(b1+(B*(S\\(C*(Ainvb1)))))-A\\(B*(Sinvb2))\n  x2=-S\\(C*(Ainvb1))+Sinvb2;\n  return [x1;x2];\nend","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"Julia's efficiency stems partially from the extensive use of types. We need to define new types to specify our own linear solver and integrate it with NEP-PACK.","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"struct MyLinSolverCreator <: LinSolverCreator; end\nstruct MyLinSolver <: LinSolver;\n  mynep\n  myλ\nend","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"NEP-solvers call the function create_linsolver(creator,nep,λ), which should return a linear solver. We need to overload this function for our own creator-type. In general, this is to allow precomputation. However, in this example we do not have any precomputations and thus just return an instance of MyLinSolver.","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"import NonlinearEigenproblems.create_linsolver # Needed since we want overload it\nfunction create_linsolver(::MyLinSolverCreator,nep,λ)\n   return MyLinSolver(nep,λ);\nend","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"The rest of the implementation of the solver goes into the function lin_solve, where we utilize our function schur_complement_lin_solve from above.","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"import NonlinearEigenproblems.LinSolvers.lin_solve # Needed since we want overload it\nfunction lin_solve(solver::MyLinSolver,b::Vector;tol=eps())\n   n0=10;\n   return schur_complement_lin_solve(compute_Mder(solver.mynep,solver.myλ),b,n0)\nend","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"You can now solve the problem by passing a creator object MyLinSolverCreator() to a NEP-solver, e.g., augnewton:","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"julia> dep=nep_gallery(\"dep0\",50);\njulia> creator=MyLinSolverCreator();\njulia> augnewton(dep,λ=1,v=ones(size(dep,1)),logger=1,linsolvercreator=creator);\niter 1 err:0.10615052208736536 λ=1.0 + 0.0im\niter 2 err:0.04682362994161844 λ=3.004830719411172 + 0.0im\niter 3 err:0.08148964717804698 λ=0.213140384062811 + 0.0im\niter 4 err:0.03955381142282053 λ=0.47667949368248896 + 0.0im\niter 5 err:0.06584371583464586 λ=2.985447356041631 + 0.0im\niter 6 err:0.02262384918568079 λ=3.722422057973499 + 0.0im\niter 7 err:0.0036373167693678717 λ=3.389502913018821 + 0.0im\niter 8 err:0.00704620404184537 λ=3.2745554693864496 + 0.0im\niter 9 err:0.0009450496517445758 λ=3.1652287152386758 + 0.0im\niter 10 err:2.138372017573122e-5 λ=3.187725547526568 + 0.0im\niter 11 err:1.0100960591678548e-8 λ=3.188230946035159 + 0.0im\niter 12 err:2.801564990446382e-15 λ=3.1882313460682705 + 0.0im","category":"page"},{"location":"tutorial_linsolve/","page":"Tutorial 11 (Linear solvers)","title":"Tutorial 11 (Linear solvers)","text":"(Image: To the top)","category":"page"},{"location":"movebc_tutorial/#Tutorial:-Application-to-absorbing-boundary-conditions","page":"Tutorial 1 (ABC)","title":"Tutorial: Application to absorbing boundary conditions","text":"","category":"section"},{"location":"movebc_tutorial/#A-Schrödinger-equation","page":"Tutorial 1 (ABC)","title":"A Schrödinger equation","text":"","category":"section"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"We consider the  Schrödinger type eigenvalue problem on the interval 0L_1,","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"begineqnarray*\n left(\n fracpartial^2partial x^2\n-V(x)-lambda\nright)psi(x)=0 xin0L_1\n   psi(0)=0\n   psi(L_1)=0\nendeqnarray*","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"We wish to compute eigenvalue λ and eigenfunction psi. Moreover, we assume that the potential function V(x) is benign in the domain L_0L_1, in our case for simplicity it is constant, such that we can later solve the problem in that domain analytically. In the simulations we will consider this function","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"  V(x)=\nbegincases\n1+sin(alpha x)   xin0L_0=01\nV_0  xin(L_0L_1)=(18)\nendcases","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"where α is large, i.e., the potential has high frequency oscillations in one part of the domain.","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"<br>\n<img src=\"https://user-images.githubusercontent.com/11163595/49676288-62c71080-fa79-11e8-8542-3b7857720473.png\" height=300>","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"This tutorial illustrates how we can avoid a discretization of the domain L_0L_1 and only discretize 0L_0, by solving a NEP. The implementation described below is also directly available in the gallery: nep_gallery(\"schrodinger_movebc\").","category":"page"},{"location":"movebc_tutorial/#Derivation-of-reduced-domain-differential-equation","page":"Tutorial 1 (ABC)","title":"Derivation of reduced domain differential equation","text":"","category":"section"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"The technique is based on moving the boundary condition at L_1 to L_0. This can be done without doing any approximation, if we allow the new artificial boundary condition at L_0 to depend on λ. We introduce what is called an absorbing boundary condition, also known as an artificial boundary condition.","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"We first note that we can transform the problem to first order form","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"  fracddx\nbeginbmatrixpsi(x)psi(x)endbmatrix\n=\nbeginbmatrix\n0  1\nlambda+V(x)  0\nendbmatrix\nbeginbmatrixpsi(x)psi(x)endbmatrix","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"The potential V(x) is constant in the domain L_0L_1. This  allows us to directly express the solution using the matrix exponential","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"beginbmatrixpsi(x)psi(x)endbmatrix\n=expleft((x-L_0)\nbeginbmatrix\n0  1\nlambda+V_0  0\nendbmatrix\nright)\nbeginbmatrixpsi(L_0)psi(L_0)endbmatrix","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"when xinL_0L_1. The boundary condition psi(L_1)=0 can be imposed as","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"0=psi(L_1)=beginbmatrix1  0endbmatrix\nbeginbmatrixpsi(L_1)psi(L_1)endbmatrix\n=beginbmatrix1  0endbmatrixexpleft((L_1-L_0)\nbeginbmatrix\n0  1\nlambda+V_0  0\nendbmatrix\nright)\nbeginbmatrixpsi(L_0)psi(L_0)endbmatrix","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"By explicitly using the hyperbolic functions formula for the matrix exponential of an antidiagonal two-by-two matrix we obtain the relation","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"0=\ng(λ)psi(L_0)+\nf(λ)psi(L_0)","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"where","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"g(λ)=coshleft((L_1-L_0)sqrtλ+V_0right)","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"f(λ)=fracsinhleft((L_1-L_0)sqrtλ+V_0right)sqrtλ+V_0","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"Note that a solution to the original boundary value problem will satisfy the condition 0=g(λ)psi(L_0)+f(λ)psi(L_0), which involves only the point x=L_0, i.e., the middle of the domain. We can now disconnect the problem and only consider only the domain 0L_0 by using this condition instead, since a solution to the original boundary value problem satisfies","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"begineqnarray*\n left(\n fracpartial^2partial x^2\n-V(x)-lambda\nright)psi(x)=0 xin0L_0\n   psi(0)=0\n   g(λ)psi(L_0)+f(λ)psi(L_0)=0\nendeqnarray*","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"which is a boundary value problem on the reduced domain 0L_0. The boundary condition is a Robin boundary condition (also called mixed boundary condition) at x=L_0, since it contains both psi(L_0) and psi(L_0). It can be shown that the solutions to the original problem are the same as the solutions on the reduced domain, except for some unintresting special cases.","category":"page"},{"location":"movebc_tutorial/#Discretization-of-the-λ-dependent-boundary-value-problem","page":"Tutorial 1 (ABC)","title":"Discretization of the λ-dependent boundary value problem","text":"","category":"section"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"The boundary condition in the reduced domain boundary value problem is λ-dependent. Therefore a standard discretization the domain 0L_0, e.g., finite difference, will lead to a nonlinear eigenvalue problem. More precisely, we discretize the problem as follows.","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"Let x_k=hk, k=1ldots n and h=1n such that x_1=h and x_n=1=L_0. An approximation of the lambda-dependent boundary condition can be found with the one-sided second order difference scheme","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"   0=g(λ)psi(L_0)+f(λ)frac1hleft(frac32 psi(L_0)\n-2psi(x_n-1)\n+frac12psi(x_n-2)right)+O(h^2)","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"Let","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"  D_n=\nfrac1h^2\nbeginbmatrix\n-2   1  0 \n1  ddots 1 \n0  1 -2  1\n0  cdots  0  0\nendbmatrixtextrm and \nunderlineI_n=beginbmatrix1  ddots 1    0endbmatrix","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"Then the boundary value problem can expressed as","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"M(λ)v=0","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"where","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"M(λ)=A-λunderlineI_n\n+g(λ)e_ne_n^T+f(λ)F","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"and","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"A=D_n-operatornamediag(V(x_1)ldotsV(x_n-1)0)F=frac12he_ne_n-2^T-frac2he_ne_n-1^T+frac32he_ne_n^T","category":"page"},{"location":"movebc_tutorial/#Implementation-in-NEP-PACK","page":"Tutorial 1 (ABC)","title":"Implementation in NEP-PACK","text":"","category":"section"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"The above discretization can be expressed as a SPMF_NEP with four terms. Let us set up the matrices first","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"using LinearAlgebra,SparseArrays;\nL0=1; L1=8; V0=10.0;\nxv=Vector(range(0,stop=L0,length=1000))\nh=xv[2]-xv[1];\nn=size(xv,1);\nα=25*pi/2;\nV=x->1+sin(α*x);\nDn=spdiagm(-1 => [ones(n-2);0]/h^2, 0 => -2*ones(n-1)/h^2, 1 => ones(n-1)/h^2)\nVn=spdiagm(0 => [V.(xv[1:end-1]);0]);\nA=Dn-Vn;\nIn=spdiagm(0 => [ones(n-1);0])\nF=sparse([n, n, n],[n-2, n-1, n],[1/(2*h), -2/h, 3/(2*h)])\nG=sparse([n],[n],[1]);","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"The corresponding functions in the SPMF are defined as follows","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"f1=S->one(S);\nf2=S->-S;\nhh=S-> sqrt(S+V0*one(S))\ng=S-> cosh((L1-L0)*hh(S))\nf=S-> inv(hh(S))*sinh((L1-L0)*hh(S))","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"Note that when defining an SPMF, all functions should be defined in a matrix function sense (not element-wise sence). Fortunately, in Julia, sinh(A) and cosh(A) for matrix A are interpreted as matrix functions. The NEP can now be created and solved by directly invoking the SPMF-creator and applying a NEP-solver:","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"using NonlinearEigenproblems\nnep=SPMF_NEP([Dn-Vn,In,G,F],[f1,f2,g,f]);\n(λ1,v1)=quasinewton(Float64,nep,logger=1,λ=-5,v=ones(n),tol=1e-9);\n(λ2,v2)=quasinewton(nep,logger=1,λ=-11,v=ones(n),tol=1e-9)\n(λ3,v3)=quasinewton(nep,logger=1,λ=-20,v=ones(n),tol=1e-9)\n(λ4,v4)=quasinewton(nep,logger=1,λ=-35,v=ones(n),tol=1e-9)","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"We can easily do a sanity check of the solution by visualizing it in this way","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"using Plots\nplot(xv,v1/norm(v1))\nplot!(xv,real(v2)/norm(v2))\nplot!(xv,real(v3)/norm(v3))\nplot!(xv,real(v4)/norm(v4))","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"resulting in","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"<br>\n<img src=\"https://user-images.githubusercontent.com/11163595/49675575-96ed0200-fa76-11e8-8341-b3faef1e800b.png\" height=450>","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"Rather than making several calls to a specific method, some NEP-solvers directly compute several solutions. The NEP-solver iar works quite well for this problem (see also the deflation approach to compute several solutions):","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"julia> (λ,v)=iar(nep,logger=1,σ=-36,v=ones(n),tol=1e-9,neigs=5,maxit=100);\n-\n--\n---\n----\n-----\n------\n=------\n+-------\n+--------\n+---------\n+----------\n+-----------\n+=-----------\n++------------\n++-------------\n++--------------\n++---------------\n++----------------\n+++----------------\n++=-----------------\n++=------------------\n+++-------------------\n+++--------------------\n+++---------------------\n+++----------------------\n+++-----------------------\n+++------------------------\n+++-------------------------\n+++=-------------------------\n+++=--------------------------\n++++---------------------------\n++++----------------------------\n++++-----------------------------\n++++------------------------------\n++++-------------------------------\n++++--------------------------------\n++++=--------------------------------\n+++++---------------------------------\njulia> λ\n5-element Array{Complex{Float64},1}:\n  -34.93072323018405 + 4.272712516424266e-18im\n  -39.14039540604307 + 2.054980381709175e-16im\n -31.057106551809486 - 3.2616991503097867e-15im\n  -43.66198303378091 - 4.3753274496659e-15im\n -27.537645678335437 + 4.8158177866759774e-15im","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"The output of the logging of iar is a compact notation for how many eigenvalues have converged at a specific iteration. Every line corresponds to one iteration step. The signs correspond to: +=a converged eigenvalue, -=not converged eigenvalue, ==almost converged eigenvalue in the sense that it almost (up to a factor 10) satisfies the convergence criteria.","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"tip: Tip\nThe performance of many NEP-algorithms for this problem can be improved. One improvement is achieved with a simple variable transformation. If we let mu=sqrtlambda+V_0 we have lambda=mu^2-V_0. Therefore the NEP can be transformed in a way that it does not contain square roots. Square roots are undesirable, since they can limit convergence in many methods due to the fact that they are not entire functions. The sinh and cosh can be merged to a tanh-expression, leading to less nonlinear terms (but possibly more difficult singularities).","category":"page"},{"location":"movebc_tutorial/#Verifying-the-solution","page":"Tutorial 1 (ABC)","title":"Verifying the solution","text":"","category":"section"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"Let us verify the solution with a direct discretization of the domain. The ApproxFun.jl package provides tools to solve differential equations in one dimension. We use this package to discretize the entire domain 0L_1, whereas only a discretization of 0L_0 is necessary in the NEP-approach.","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"The eigenvalues of the operator can be computed as follows (where we approximate the singular point of the potential with a regularized heaviside function).","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"julia> using LinearAlgebra, ApproxFun;\njulia> x = Fun(0 .. 8)\njulia> V0 = 10;\njulia> α = 25*pi/2;\njulia> # Let Ha be an approximation of H(x-1) where H is a Heaviside function\njulia> kk=10; Ha = 1 ./(1+exp(-2*kk*(x .- 1.0)));\njulia> VV=V0*Ha + (1-Ha) * sin(α*x)\njulia> L = 𝒟^2-VV\njulia> S = space(x)\njulia> B = Dirichlet(S)\njulia> ee= eigvals(B, L, 500,tolerance=1E-10);","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"We obtain approximations of the same eigenvalues as with the NEP-approach","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"julia> ee[sortperm(abs.(ee.+36))[1:5]]\n -34.85722089717211\n -39.051578662445074\n -30.984470654329677\n -43.54933251507695\n -27.450712883781343","category":"page"},{"location":"movebc_tutorial/","page":"Tutorial 1 (ABC)","title":"Tutorial 1 (ABC)","text":"(Image: To the top)","category":"page"},{"location":"deflate_tutorial/#Tutorial:-Computing-several-solutions-with-deflation","page":"Tutorial 4 (Deflation)","title":"Tutorial: Computing several solutions with deflation","text":"","category":"section"},{"location":"deflate_tutorial/#Background","page":"Tutorial 4 (Deflation)","title":"Background","text":"","category":"section"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"Several algorithms for NEPs compute one solution to the NEP given a starting value. In many applications several solutions are of interest. Let us first consider the trivial partial \"work-around\": You can try to run an algorithm which computes one eigenvalue twice with different starting values, e.g., quasinewton as in this example:","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"julia> using NonlinearEigenproblems\njulia> nep=nep_gallery(\"dep0\",4);\njulia> (λ1,v1)=quasinewton(nep,λ=0,v=ones(size(nep,1)),maxit=500)\n(-0.2094378352960786 + 0.0im, Complex{Float64}[2.2479093650910866 + 0.0im, 3.208352895087154 + 0.0im, 0.6628450056308428 + 0.0im, 17.946407917249605 + 0.0im])\njulia> (λ2,v2)=quasinewton(nep,λ=1,v=ones(size(nep,1)),maxit=500)\n(0.2966714721676867 + 0.0im, Complex{Float64}[-0.8369951877176647 + 0.0im, -5.749143077718012 + 0.0im, 5.720770822961643 + 0.0im, 10.495353352793199 + 0.0im])","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"This simple approach often suffers from the problem called reconvergence (we obtain the same solution again) or solutions of interest may be missed. In this case we get reconvergence when we use starting value -1:","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"julia> (λ3,v3)=quasinewton(nep,λ=-1,v=ones(size(nep,1)),maxit=500)\n(-0.20943783529618362 + 0.0im, Complex{Float64}[-0.6110572600894503 + 0.0im, -0.8721380674494782 + 0.0im, -0.18018353377334895 + 0.0im, -4.878436391013284 + 0.0im])","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"Note that applying the algorithm with starting values λ=0 and λ=-1 lead to the same solution. Other solution methods do not suffer from this, e.g., block Newton method, the infinite Arnoldi method and nleigs since they compute several solutions at once. Another attempt to remedy reconvergence is to use the technique called deflation. See also the manual page on deflation.","category":"page"},{"location":"deflate_tutorial/#Deflation-in-NEP-PACK","page":"Tutorial 4 (Deflation)","title":"Deflation in NEP-PACK","text":"","category":"section"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"The term deflation is referring to making something smaller (in the sense of opposite of inflating a balloon). In this case we can make the solution set smaller. We compute a solution and subsequently construct a deflated problem, which has the same solutions as the original problem except of the solution we have already computed.","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"A general solver independent deflation technique is available in NEP-PACK based on increasing the problem size. (There are also NEP-solver deflation techniques incoprorated in, e.g., in the nonlinear Arnoldi method and the Jacobi-Davidson method.) The solver independent technique is inspired by what is described in the PhD thesis of Cedric Effenberger.","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"In NEP-PACK, this type of deflation is implemented in the function deflate_eigpair, which takes a NEP and an eigenpair as input and returns a new NEP.","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"julia> # Construct a deflated NEP where we remove (λ1,v1)\njulia> dnep=deflate_eigpair(nep,λ1,v1);\njulia> # The dnep is a new NEP but with dimension increased by one\njulia> size(nep)\n(4, 4)\njulia> size(dnep)\n(5, 5)","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"We now illustrate that we can avoid reconvergence:","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"julia> (λ4,v4)=quasinewton(dnep,λ=-1,v=ones(size(dnep,1)),maxit=500)\n(0.29667147216767376 + 0.0im, Complex{Float64}[-11.767671406737819 + 0.0im, -43.86197116968253 + 0.0im, 31.9938464980679 + 0.0im, 8.133682253178579 + 0.0im, -28.114795306465478 + 0.0im])","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"Note: In contrast to the initial example, starting value λ=-1 does not lead to converge to the eigenvalue we obtained from starting value λ=0.","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"The computed solution is indeed a solution to the original NEP since M(λ4) is singular:","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"julia> minimum(svdvals(compute_Mder(nep,λ4)))\n4.166120681513672e-14","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"In fact, you can even start with the first starting value λ=0, and get a new solution","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"julia> quasinewton(dnep,λ=0,v=ones(size(dnep,1)),maxit=500)\n(-1.3640414062700734 + 0.0im, Complex{Float64}[-1.0976664883572566e307 + 0.0im, -2.8870394809137054e307 + 0.0im, 2.1189933442957902e307 + 0.0im, 5.753536946292879e306 + 0.0im, -1.9207807191677339e307 + 0.0im])","category":"page"},{"location":"deflate_tutorial/#Repeated-deflation","page":"Tutorial 4 (Deflation)","title":"Repeated deflation","text":"","category":"section"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"The above procedure can be repeated by calling deflate_eigpair on the deflated NEP. This effectively deflates another eigenpair (but without creating a recursive deflated nep structure).","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"function multiple_deflation(nep,λ0,p)\n   n=size(nep,1);\n   dnep=nep;\n   for k=1:p\n      # Compute one solution of the deflated problem\n      (λ2,v2)=quasinewton(dnep,λ=λ0,v=ones(size(dnep,1)),maxit=1000);\n      # expand the invariant pair\n      dnep=deflate_eigpair(dnep,λ2,v2)\n   end\n   return get_deflated_eigpairs(dnep);\nend","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"We can now compute several solutions by calling multiple_deflation. Note that we use the same starting guess, 1im, for all eigenvalues.","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"julia> (Λ,VV)=multiple_deflation(nep,1im,3)\n(Complex{Float64}[-0.20943783529608836 - 1.1876898672667347e-13im, 0.09916136114196937 + 1.5040449444406283im, 0.2966714721675515 - 1.1055942412512364e-13im], Complex{Float64}[0.08606692232135099 - 0.0868831949158175im -0.33250443251734496 + 0.6897411986346054im -0.04563655283979674 + 0.04339934493508566im; 0.12283994350000517 - 0.12400497736757769im 0.2101087999777705 - 0.18967830722177997im -0.31346783792781846 + 0.29810092957798906im; 0.025378705430330793 - 0.02561940117237799im 0.41435154273390934 + 0.36869913908327107im 0.31192086140711456 - 0.2966297893745159im; 0.6871238316577664 - 0.6936406250750684im -0.15130500943732544 - 0.05527070830243071im 0.5722514954516473 - 0.5441984219948924im])","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"The values in Λ and VV are eigenpairs:","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"julia> norm(compute_Mlincomb(nep,Λ[1],VV[:,1]))\n1.7819713566771836e-13\njulia> norm(compute_Mlincomb(nep,Λ[2],VV[:,2]))\n1.2888961114892419e-13\njulia> norm(compute_Mlincomb(nep,Λ[3],VV[:,3]))\n1.5058274131661697e-13","category":"page"},{"location":"deflate_tutorial/","page":"Tutorial 4 (Deflation)","title":"Tutorial 4 (Deflation)","text":"(Image: To the top)","category":"page"},{"location":"tutorial_call_python/#Tutorial:-Solving-NEP-defined-in-Python","page":"Tutorial 5 (Python 1)","title":"Tutorial: Solving NEP defined in Python","text":"","category":"section"},{"location":"tutorial_call_python/#A-problem-defined-in-Python","page":"Tutorial 5 (Python 1)","title":"A problem defined in Python","text":"","category":"section"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"Julia is a great programming language, but your problem may not be easy to define in Julia code, e.g., for legacy reasons. Don't let that prevent you from using the package. We now show how a problem defined in Python can be solved with NEP-PACK.","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"One of the advantages of the Julia language is that it is reasonably easy to interface with code written in other languages. In this tutorial we work with Python, and the two following tutorials we interface MATLAB and fortran.","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"note: Note\nTo work with NEPs defined in Python you need to have Python installed on your computer. With the package PyCall it is possible to let Julia control execution of Python code.","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"The following python code correspond to the NEP","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"M(λ)=beginbmatrix12newline34endbmatrix+\nλbeginbmatrix00newline01endbmatrix+\ne^λbeginbmatrix11newline11endbmatrix","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"The code has two functions: one that can compute an evaluation of M(λ) and one that can form a linear combination of derivatives","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"  sum_i=1^kM^(k)(λ)x_i","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"Put a file  mynep.py  in your current directory with the following contents:","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"import numpy as np;\nimport cmath as m;\ndef compute_M(s):\n    \"\"\"Compute the matrix M(s) for a given eigenvalue approximation\"\"\"\n    A=np.matrix('1 2; 3 4');  B=np.matrix('0 0; 0 1');   C=np.matrix('1 1; 1 1');\n    M=A+s*B+m.exp(s)*C\n    return M\n\ndef compute_Mlincomb(s,X):\n    \"\"\"Compute the linear combination of derivatives for value s\"\"\"\n    A=np.matrix('1 2; 3 4');  B=np.matrix('0 0; 0 1');   C=np.matrix('1 1; 1 1');\n\n    X=np.matrix(X) # Explicitly convert to matrix\n    z=np.zeros((2,1));\n    # Zeroth derivative\n    z=z+A*X[:,0]\n    z=z+B*(s*X[:,0])\n    z=z+C*(m.exp(s)*X[:,0])\n\n    # First derivative\n    if (np.size(X,1)>1):\n        z=z+B*(X[:,1])+C*(m.exp(s)*X[:,1])\n    # Higher derivatives\n    if (np.size(X,1)>1):\n        for k in range(2,np.size(X,1)):\n            z=z+C*(m.exp(s)*X[:,k])\n    return z","category":"page"},{"location":"tutorial_call_python/#Interfacing-Python-code","page":"Tutorial 5 (Python 1)","title":"Interfacing Python code","text":"","category":"section"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"We first initiate PyCall as follows. Note that the pushfirst! command is needed, otherwise the module defined in the file mynep.py we gave above will not be found. (PyCall does not include the current directory in the module search path by default.)","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"using PyCall;\npushfirst!(PyVector(pyimport(\"sys\").\"path\"), \"\");\nmynep = pyimport(\"mynep\")","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"This gives us direct access to the compute_M and compute_Mlincomb functions from python, e.g., if we want to evaluate M(3+3i) we run this code","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"julia> mynep.compute_M(3+3im)\n2×2 Array{Complex{Float64},2}:\n -18.8845+2.83447im  -17.8845+2.83447im\n -16.8845+2.83447im  -12.8845+5.83447im","category":"page"},{"location":"tutorial_call_python/#Implementation-in-NEP-PACK-(using-Mder_Mlincomb_NEP)","page":"Tutorial 5 (Python 1)","title":"Implementation in NEP-PACK (using Mder_Mlincomb_NEP)","text":"","category":"section"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"We can now use the Python interface to define a NEP in Julia. The type Mder_Mlincomb_NEP is a special type made for this situation. The required inputs are the size, called n; a function to compute M(λ), called fder; and a function to compute sum_i=1^kM^(k)(λ)x_i, called flincomb. The extra 0 passed in the definition defines that M(λ) is available, but no higher derivatives.","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"using NonlinearEigenproblems\nn=2;\nfder = (λ,der) -> mynep.compute_M(complex(λ));\nflincomb =  (λ,X) -> mynep.compute_Mlincomb(complex(λ),complex(reshape(X,size(X,1),size(X,2))));\nnep=Mder_Mlincomb_NEP(n,fder,0,flincomb);","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"We can compare the Python call with the NEP-PACK call","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"julia> compute_Mder(nep,3+3im)\n2×2 Array{Complex{Float64},2}:\n -18.8845+2.83447im  -17.8845+2.83447im\n -16.8845+2.83447im  -12.8845+5.83447im","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"We continue by computing some eigenvalues of the the NEP using the Infinite Arnoldi method (iar).","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"julia> (λ,v)=iar(nep,v=[1;1],σ=1,logger=0,neigs=3);\njulia> λ\n3-element Array{Complex{Float64},1}:\n  0.6748316143423988 + 7.336803319821954e-19im\n 0.11742590291190791 - 3.649946317867008im    \n 0.11742590291191168 + 3.6499463178670144im  ","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"We can verify that we actually computed solutions as follows:","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"julia> norm(compute_Mlincomb(nep,λ[1],v[:,1]))\n1.106424240899132e-15","category":"page"},{"location":"tutorial_call_python/#Implementation-in-NEP-PACK-(using-new-type)","page":"Tutorial 5 (Python 1)","title":"Implementation in NEP-PACK  (using new type)","text":"","category":"section"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"The previous implementation utilizes the convenience type Mder_Mlincomb_NEP, and solves the problem in a satisfactory way. Nevertheless, to illustrate more of the inner workings of NEP-PACK we solve the problem in a second way, by defining our own type. The first thing we need to do is to define the size-function, which is hard-coded in this example.","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"import NonlinearEigenproblems.size # We will overload these functions\nimport NonlinearEigenproblems.compute_Mlincomb;\nimport NonlinearEigenproblems.compute_Mder;\nstruct PyNEP <: NEP # Set up a dummy type for our specific NEP\nend\nsize(::PyNEP) = (2,2) # Trivial function definitions\nsize(::PyNEP,::Int) = 2","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"As explained in NEPTypes, a NEP is defined by its compute functions. Here is how you define two compute functions that call our python-defined NEP:","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"function compute_Mder(::PyNEP,s::Number,der::Integer=0)\n    if (der>0)\n        error(\"Higher derivatives not implemented\");\n    end\n    return mynep.compute_M(complex(s)); # Call python\nend\nfunction compute_Mlincomb(::PyNEP,s::Number,X::AbstractVecOrMat)\n    XX=complex(reshape(X,size(X,1),size(X,2))) # Turn into a matrix\n    return mynep.compute_Mlincomb(complex(s),XX); # Call python\nend","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"We now create an object of our newly created type and we can access the NEP with the NEP-PACK specific compute functions:","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"julia> pynep=PyNEP();\njulia> compute_Mder(pynep,3+3im)\n2×2 Array{Complex{Float64},2}:\n -18.8845+2.83447im  -17.8845+2.83447im\n -16.8845+2.83447im  -12.8845+5.83447im","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"The behavior is the same as above. Since a NEP-object is defined by its compute functions, we can now use many NEP-solvers to solve this problem. We again use iar:","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"julia> (λ2,v2)=iar(pynep,v=[1;1],σ=1,logger=0,neigs=3);\njulia> λ2\n3-element Array{Complex{Float64},1}:\n  0.6748316143423988 + 7.336803319821954e-19im\n 0.11742590291190791 - 3.649946317867008im    \n 0.11742590291191168 + 3.6499463178670144im   ","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"We can compare with the eigenvalues computed above and, again, verify that we actually computed solutions as follows:","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"julia> norm(compute_Mlincomb(pynep,λ2[1],v2[:,1]))\n1.106424240899132e-15","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"Residual is almost zero, so we have a solution.","category":"page"},{"location":"tutorial_call_python/","page":"Tutorial 5 (Python 1)","title":"Tutorial 5 (Python 1)","text":"(Image: To the top)","category":"page"},{"location":"development/#Developer-info","page":"Developer info","title":"Developer info","text":"","category":"section"},{"location":"development/#Compiling-the-documentation","page":"Developer info","title":"Compiling the documentation","text":"","category":"section"},{"location":"development/","page":"Developer info","title":"Developer info","text":"Compile this documentation page by running:","category":"page"},{"location":"development/","page":"Developer info","title":"Developer info","text":"jarl@bjork:~/src/NonlinearEigenproblems.jl/docs$ julia --color=yes make.jl &&  mkdocs build --clean\njarl@bjork:~/src/NonlinearEigenproblems.jl/docs$ firefox site/index.html","category":"page"},{"location":"development/","page":"Developer info","title":"Developer info","text":"If you want this to appear on our documentation page https://nep-pack.github.io/NonlinearEigenproblems.jl/ you need to push it to the gh-branch, e.g.,  by running","category":"page"},{"location":"development/","page":"Developer info","title":"Developer info","text":"jarl@bjork:~/src/NonlinearEigenproblems.jl/docs$ export DOCSDIR=`pwd`\njarl@bjork:~/src/NonlinearEigenproblems.jl/docs$ cd /tmp\njarl@bjork:/tmp$ git clone -b \"gh-pages\" git@github.com:nep-pack/NonlinearEigenproblems.jl.git\njarl@bjork:/tmp$ cd NonlinearEigenproblems.jl\njarl@bjork:/tmp/NonlinearEigenproblems.jl$ cp -r $DOCSDIR/site/* .\njarl@bjork:/tmp/NonlinearEigenproblems.jl$ git add *;  git commit . -m \"refresh docs\"; git push","category":"page"},{"location":"development/","page":"Developer info","title":"Developer info","text":"More information about Documenter.jl: here","category":"page"},{"location":"tutorial_contour/#Contour-integral-tutorial","page":"Tutorial 2 (Contour)","title":"Contour integral tutorial","text":"","category":"section"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"NEP-PACK contains several implementations of methods in the family of approaches based on contour integration. Although they have been worked out and presented independently (in different research articles by different research groups), we have implemented them in a unified and extendible way.","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"Contour integral methods have one property which makes them attractive from the perspective of parallelization, which we will illustrate in the final example below.","category":"page"},{"location":"tutorial_contour/#Basic-usage","page":"Tutorial 2 (Contour)","title":"Basic usage","text":"","category":"section"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"The most popular methods contour integral methods are Beyn's contour integral method (implemented in contour_beyn) and the block SS method of Asakura and Sakurai (implemented in contour_block_SS). We illustrate both of them. First set up a large and sparse problem:","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> using SparseArrays, LinearAlgebra;\njulia> n=1000;\njulia> A0=spdiagm(0 => ones(n))\njulia> A1=spdiagm(-2 => ones(n-2), 0 => 30*(n:-1:1)/n,  1 => 3*ones(n-1))/3\njulia> A2=spdiagm(-1 => ones(n-1), 0 => (1:n)/n, 1 => sin.(range(0,5,length=n-1)))/10\njulia> nep=SPMF_NEP([A0,A1,A2],[s->one(s), s->s, s->exp(-s)])","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"and call the two integral solution methods:","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> (λ,v)= contour_beyn(nep,radius=0.5,k=10);","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"We can verify that we found some good solutions","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> λ\n2-element Array{Complex{Float64},1}:\n -0.4938003805961036 + 0.03369433628038132im\n -0.4984653501095431 - 0.013414744968396205im\njulia> norm(compute_Mlincomb(nep,λ[1],normalize(v[:,1])))\n2.8693125572899838e-6\njulia> norm(compute_Mlincomb(nep,λ[2],normalize(v[:,2])))\n3.0028543096707394e-6","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"For comparison we also use contour_block_SS","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> (λ,v)= contour_block_SS(nep,radius=0.5,k=10);\njulia> julia> λ\n7-element Array{Complex{Float64},1}:\n -0.49789562317811836 + 0.029382625854591973im\n  -0.5020899933123398 - 0.027308288264250524im\n  -0.5006296180796399 + 0.011976675667372098im\n  -0.5000287784310599 - 0.010301420892154335im\n  -0.5044451294089868 - 0.0074606034247795975im\n  -0.5001550771105308 - 0.00026147429323077303im\n -0.49957316937095864 + 0.003511006328045692im","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"and the corresponding residual norms","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> for j=1:7; @show norm(compute_Mlincomb(nep,λ[j],normalize(v[:,j]))); end\nnorm(compute_Mlincomb(nep, λ[j], normalize(v[:, j]))) = 2.8693125572899838e-6\nnorm(compute_Mlincomb(nep, λ[j], normalize(v[:, j]))) = 3.0028543096707394e-6\nnorm(compute_Mlincomb(nep, λ[j], normalize(v[:, j]))) = 1.1514402700870265e-7\nnorm(compute_Mlincomb(nep, λ[j], normalize(v[:, j]))) = 4.123810796391466e-8\nnorm(compute_Mlincomb(nep, λ[j], normalize(v[:, j]))) = 6.261761794674978e-8\nnorm(compute_Mlincomb(nep, λ[j], normalize(v[:, j]))) = 1.7269388863226059e-9\nnorm(compute_Mlincomb(nep, λ[j], normalize(v[:, j]))) = 2.994085882385125e-9","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"The functions contour_beyn and contour_block_SS have compatible keyword argumengs. The kwarg radius=0.5, means that we numerically integrate  a circle of radius 0.5. The center of the circle is given by the σ, argument and by default σ=0. We should expect the method to find eigenvalues (hopefully all eigenvalues) within that disk. Our implementation also supports ellipses, by specifying radius as a length two vector with the two radii of the ellipse. The value k=10 specifies how many columns the rectangular probe matrix has. In general, we do not obtain more k eigenvalues.","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"It seems that in this case contour_block_SS is better since it finds eigenvalues  which contour_beyn misses. However, a closer look reveals that the additional eigenvalues are outside the requested disc, and the call to  contour_block_SS also requires more computation time, making the comparison unfair.","category":"page"},{"location":"tutorial_contour/#Your-own-quadrature-method","page":"Tutorial 2 (Contour)","title":"Your own quadrature method","text":"","category":"section"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"The contour integral methods are based on numerical quadrature. There are many different ways to carry out quadrature, and NEP-PACK provides a way to use user-defined quadrature methods. The default behaviour is to use the trapezoidal rule. When we parameterize a circle (or ellipse) with a phase, the integrand is periodic and the trapezoidal rule works particularly well. It is however not the only option for quadrature and we can for instance implement a gauss quadrature, in this case by using the functionality in the package QuadGK:","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> using Pkg\njulia> Pkg.add(\"QuadGK\");\njulia> using QuadGK","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"The function (x,w)=gauss(N) provides weights and quadrature points for a function to be integrated over the interval [-1,1] with N quadrature points.","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"Before implementing the method, let us first have a look at the documtation of MatrixIntegrator:","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"MatrixIntegrator","category":"page"},{"location":"tutorial_contour/#NonlinearEigenproblems.NEPSolver.MatrixIntegrator","page":"Tutorial 2 (Contour)","title":"NonlinearEigenproblems.NEPSolver.MatrixIntegrator","text":"abstract type MatrixIntegrator\n\nThis type is used for integration of (matrix valued) functions with a particular structure. It is used in contour_beyn and contour_block_SS.\n\nIn order to specify your own way to do numerical quadrature you should inherit from this type\n\njulia> abstract type MyIntegrator <: MatrixIntegrator; end\n\nand implement the method integrate_interval:\n\njulia> import NonlinearEigenproblems.NEPSolver.integrate_interval\njulia> function integrate_interval(ST::Type{MyType},::Type{T},f,gv,a,b,N,logger) where {T<:Number}\n\nThe function integrate_interval should integrate functions on the interval [a,b] with N quadrature points. Further parameters:\n\nThe type T (typically ComplexF64) specifies what the target number type is.\nThe logger::Logger specifies if / how things should written to the log.\nf::Function, takes a scalar input (in the interval [a,b]) and returns a matrix or a vector.\ngv::Vector{Function} which takes scalar input (in the interval [a,b])  and returns scalars.\n\nThe function integrate_interval should return a tensor I where the last dimension is m=length(gv) and should contain the integrals. More precisely,  I[:,:,1], ... I[:,:,m] should contain approximations of the product of f(x)gv[1](x),...f(x)gv[m](x) over [a,b], e.g., I[:,:,j] should contain an approximation of\n\nint_a^b f(x)g_j(x)dx\n\nUsually, f(x) is considerably more expensive to evaluate than g_1(x),..,g_m(x).\n\nSee also: contour_beyn, contour_block_SS, MatrixTrapezoidal\n\n\n\n\n\n","category":"type"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"Let us now combine the Gauss method in an implementation of a numerical quadrature to be used in the quadrature methods.","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> abstract type GaussIntegrator <: MatrixIntegrator; end\njulia> import  NonlinearEigenproblems.NEPSolver.integrate_interval\njulia> function integrate_interval(ST::Type{GaussIntegrator},::Type{T},f,gv,a,b,N,logger) where {T<:Number}\n    x,w=gauss(N);        # Compute the Gauss weights\n    w=w*(b-a)/2;         # Rescale w to interval [a,b]\n    t=a .+ ((x .+ 1)/2)*(b-a); # Rescale t\n    m=size(gv,1);\n    # create the tensor and compute all quadratures\n    S = zeros(T,size(f(t[1]))...,m)\n    for i = 1:N\n        ## Extra code goes here\n        temp = f(t[i]) # Only computed once for all g-functions\n        for j=1:m\n            S[:,:,j] += temp*(gv[j](t[i])*w[i]);\n        end\n    end\n    return S\nend","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"To specify this solver, you need to add the type you just created as a parameter in the call. This is an argument (not a keyword argument) after the argument nep:","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> (λ,v)= contour_block_SS(nep,GaussIntegrator,radius=0.5, k=10);\njulia> λ\n6-element Array{Complex{Float64},1}:\n  -0.5030050924478993 + 0.025867789190345332im\n  -0.4998917126923037 - 0.014647029189145597im\n -0.49991828738335686 - 0.007092586236661307im\n  -0.5000067107140442 - 0.0026614262456865663im\n -0.49903549969757116 + 0.0075397370638041255im\n   -0.501620024772268 + 0.00393810326235837im","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"Let's make it print some pretty decoration during the progress of the method. In the code where it currently says ## Extra code goes here we will now insert","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"if (mod(i,round(N/50))==1)\n   print(\".\")\nend","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"and println() in the second code insertion. In this way, we will print a progress bar, which prints in total (approximately) 50 dots. You will see dots gradually appearing as a progress bar:","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> (λ,v)= contour_beyn(nep,GaussIntegrator,radius=0.5,k=10);\n..................................................","category":"page"},{"location":"tutorial_contour/#Parallellized-quadrature-method","page":"Tutorial 2 (Contour)","title":"Parallellized quadrature method","text":"","category":"section"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"The main computational effort of the contour integral methods lies in solving many linear systems. This is done in the call to f in the integrate_interval-function. Since they are completely independent operations in the for-loop, they can be easily parallelized.","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"Install the package Distributed and BenchmarkTools and include with","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> using Distributed,BenchmarkTools","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"Similar to the previous example we make a new type corresponding to our integrator and explicitly import that","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> abstract type ParallelIntegrator <: MatrixIntegrator; end\njulia> import  NonlinearEigenproblems.NEPSolver.integrate_interval","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"and define a function which computes the main for-loop in parallel using the @distributed macro:","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> function integrate_interval(ST::Type{ParallelIntegrator},::Type{T},f,gv,a,b,N,logger) where {T<:Number}\n    h = (b-a)/N\n    t = range(a, stop = b-h, length = N)\n    m = size(gv,1);\n    S = @distributed (+) for i = 1:N\n        temp = f(t[i])\n        Z=zeros(T,size(temp,1),size(temp,2),m);\n        for j=1:m\n            Z[:,:,j]=temp*gv[j](t[i]);\n        end\n        Z\n    end\n    return S\nend","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"To use the parallelization you may need to start julia with command-line arguments to specify the number of parallel processes to be used, e.g., -p 4. The @btime macro provides a way to measure how much faster the parallel implementation is.","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"julia> @btime (λ,v)= contour_block_SS(nep,ParallelIntegrator,radius=0.5, k=10);\n  863.420 ms (1385 allocations: 10.46 MiB)\njulia> @btime (λ,v)= contour_block_SS(nep,radius=0.5, k=10);\n  2.990 s (321362 allocations: 5.84 GiB)","category":"page"},{"location":"tutorial_contour/","page":"Tutorial 2 (Contour)","title":"Tutorial 2 (Contour)","text":"This is a speed up of 3.4, with p=4 processes.","category":"page"},{"location":"bemtutorial/#Tutorial:-User-defined-matrices-boundary-element-method","page":"Tutorial 3 (BEM)","title":"Tutorial: User-defined matrices - boundary element method","text":"","category":"section"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"Suppose you have a new type of NEP, which does not naturally fit into the standard types in NEP-PACK. This tutorial shows how you can define a NEP where the only way to access the NEP is a function to compute M^(k)(λ). We first show the manual way to do it, as it illustrates some of the workings of NEP-PACK. However, the use case is common enough to have native support in NEP-PACK. Hence, we also show how to use a special NEP-type called Mder_NEP.","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"For this example we use a boundary element method approach for computation of resonances. The complete code is available in gallery_extra/bem_hardcoded. The example is also available as a gallery problem: nep=nep_gallery(\"bem_fichera\").","category":"page"},{"location":"bemtutorial/#Boundary-element-method","page":"Tutorial 3 (BEM)","title":"Boundary element method","text":"","category":"section"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"The boundary element method applied to Helmholtz eigenvalue problem can be described by the matrix consisting of elements","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"M(λ)_ij=frac14piint_Delta_iint_Delta_jfrace^iotalambdaxi-etaxi-etadS(eta)dS(xi)","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"where Delta_i, i=1ldotsn are boundary elements. The boundary element approach is available through three functions: gen_ficheramesh to compute the mesh, precompute_quad! to precompute the quadrature coeeficients, and assemble_BEM to compute the matrix consisting of all the integrals corresponding to λ. These functions are based on the model (and inspired by some of the code) in \"A boundary element method for solving PDE eigenvalue problems\", Steinlechner, bachelor thesis, ETH Zürich, 2010 and also used in the simulations in \"Chebyshev interpolation for nonlinear eigenvalue problems\", Effenberger, Kressner, BIT Numerical Mathematics, 2012, Volume 52, Issue 4, pp 933–951.","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"To get access to the helper functions you need either to work in the gallery_extra/bem_hardcoded-directory, or copy the files in there to your current working directory. The code can also be found directly on github. We start by loading the necessary code:","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> using NonlinearEigenproblems;\njulia> include(\"triangle.jl\");\njulia> include(\"genmesh.jl\");\njulia> include(\"assemble_BEM.jl\");","category":"page"},{"location":"bemtutorial/#Manual-implementation-in-NEP-PACK","page":"Tutorial 3 (BEM)","title":"Manual implementation in NEP-PACK","text":"","category":"section"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"In order to define your new NEP you need to define a new NEP-type","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> struct BEM_NEP <: NEP\n    mesh::Vector{Triangle}\n    n::Int\n    gauss_order::Int\n    function BEM_NEP(mesh,gauss_order)\n        return new(mesh,length(mesh),gauss_order)\n    end\nend","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"The mesh variable is a vector of triangle objects defining the domain, n is the size of the mesh and gauss_order the quadrature order. All NEPs have to define size() functions","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> import Base.size; # Import from Base explicitly since we overload\n\njulia> function size(nep::BEM_NEP)\n    return (nep.n,nep.n);\nend\nsize (generic function with 142 methods)\njulia> function size(nep::BEM_NEP,dim)\n    return nep.n;\nend\nsize (generic function with 143 methods)","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"The function assemble_BEM computes the matrix defined by the integrals. Hence, we need to call this function for every call to compute_Mder:","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> import NonlinearEigenproblems.NEPCore.compute_Mder # We overload the function\njulia> function compute_Mder(nep::BEM_NEP,λ::Number,der::Int=0)\n    return assemble_BEM(λ, nep.mesh, nep.gauss_order, der)[:,:,1];\nend\ncompute_Mder (generic function with 42 methods)","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"In order to make other compute functions available to the methods, we can use the conversion functions. In particular, the compute_Mlincomb function can be implemented by making several calls in compute_Mder. This is done in the NEP-PACK-provided helper function compute_Mlincomb_from_Mder. We make this the default behaviour for this NEP:","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> import NonlinearEigenproblems.NEPCore.compute_Mlincomb # Since we overload\n# Delegate the compute Mlincomb functions. This can be quite inefficient.\njulia> compute_Mlincomb(nep::BEM_NEP,λ::Number,V::AbstractVecOrMat, a::Vector) =\n      compute_Mlincomb_from_Mder(nep,λ,V,a)\ncompute_Mlincomb (generic function with 36 methods)\njulia> compute_Mlincomb(nep::BEM_NEP,λ::Number,V::AbstractVecOrMat) =\n      compute_Mlincomb(nep,λ,V, ones(eltype(V),size(V,2)))\ncompute_Mlincomb (generic function with 37 methods)","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"We can now create a BEM_NEP as follows:","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> gauss_order=3; N=5;\njulia> mymesh=gen_ficheramesh(N);\njulia> precompute_quad!(mymesh,gauss_order);\njulia> nep=BEM_NEP(mymesh,gauss_order);","category":"page"},{"location":"bemtutorial/#Solving-the-NEP","page":"Tutorial 3 (BEM)","title":"Solving the NEP","text":"","category":"section"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"After creating the NEP, you can try to solve the problem with methods in the package, e.g., mslp works quite well for this problem:","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> (λ,v)=mslp(nep,λ=8,logger=1);\niter 1 err:4.122635537095191e-6 λ=8.128272919317748 + 0.007584851218213724im\niter 2 err:1.787963303966838e-8 λ=8.132181234599429 - 1.952792817333862e-5im\niter 3 err:3.2884911876526185e-13 λ=8.132145310156645 - 1.2648247030082216e-5im\niter 4 err:4.417989064002117e-18 λ=8.132145310195458 - 1.264891803723658e-5im","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"This is the computed solution:","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"<br>\n<img src=\"https://user-images.githubusercontent.com/11163595/49595409-324b7d80-f978-11e8-818d-eeeaf9441505.png\" height=450>","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"The plotting was done with the following code (by using internals of the BEM-implementation):","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> using PyPlot\njulia> v=v./maximum(abs.(v));\njulia> for k=1:size(nep.mesh,1);\n    tri=nep.mesh[k];\n    col=[1-abs.(v)[k];0;0]; # plot abslolute value\n    X=[tri.P1[1] tri.P2[1]; tri.P3[1] tri.P3[1]];\n    Y=[tri.P1[2] tri.P2[2]; tri.P3[2] tri.P3[2]];\n    Z=[tri.P1[3] tri.P2[3]; tri.P3[3] tri.P3[3]];\n    plot_surface(X,Y,Z,color=col,alpha=0.8);\n    plot_wireframe(X,Y,Z,color=[0;0;0],linewidth=1,alpha=0.5,);\nend","category":"page"},{"location":"bemtutorial/#Implementation-in-NEP-PACK-using-the-Mder_NEP-type","page":"Tutorial 3 (BEM)","title":"Implementation in NEP-PACK using the Mder_NEP type","text":"","category":"section"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"Some of the manual implementation can be avoided by using the Mder_NEP type. We only need to pass the size of the NEP and a function to compute M^(k)(λ), i.e., (λf,derf) -> assemble_BEM(λf, mymesh, gauss_order, derf)[:,:,1], to the Mder_NEP.","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"julia> n = length(mymesh);\njulia> mdernep = Mder_NEP(n, (λf,derf) -> assemble_BEM(λf, mymesh, gauss_order, derf)[:,:,1]);\njulia> (mderλ,mderv)=mslp(mdernep,λ=8,logger=1);\niter 1 err:4.122635537095191e-6 λ=8.128272919317748 + 0.007584851218213724im\niter 2 err:1.787963303966838e-8 λ=8.132181234599429 - 1.952792817333862e-5im\niter 3 err:3.2884911876526185e-13 λ=8.132145310156645 - 1.2648247030082216e-5im\niter 4 err:4.417989064002117e-18 λ=8.132145310195458 - 1.264891803723658e-5im\njulia> λ-mderλ\n0.0 + 0.0im","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"note: Note\nThe above code executes under the assumption that the following code had been run:precompute_quad!(mymesh,gauss_order);","category":"page"},{"location":"bemtutorial/","page":"Tutorial 3 (BEM)","title":"Tutorial 3 (BEM)","text":"(Image: To the top)","category":"page"},{"location":"errmeasure/#Measuring-the-error","page":"Measuring the error","title":"Measuring the error","text":"","category":"section"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"All iterative algorithms need some form of termination criteria. In NEP-PACK, all NEP-solvers provide the possibility to specify the desired tolerance, as well as how the error is measured or estimated. The tolerance is specified in the kwarg  tol (which is a real number) and the way to measure the error is given in errmeasure.","category":"page"},{"location":"errmeasure/#Standard-usage","page":"Measuring the error","title":"Standard usage","text":"","category":"section"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"NEP-PACK comes with several ways to measure errors for many NEP-types.","category":"page"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"errmeasure=ResidualErrmeasure(nep): The error is estimated by the use of the residual norm:","category":"page"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"mathrmerr=fracM(λ)vv","category":"page"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"errmeasure=StandardSPMFErrmeasure(nep): The error is estimated by using backward error theory. This error measure will not work for all NEPs. An implementation is provided for any AbstractSPMF. If your NEP is an AbstractSPMF with terms:\nM(λ)=A_1f_1(λ)+cdots+A_mf_m(λ)\nthe error will be estimated by\nmathrmerr=fracM(λ)vvfrac1A_1_Ff_1(λ)+cdots+A_m_Ff_m(λ)\nIn other words, the StandardSPMFErrmeasure is a weighting of the ResidualErrmeasure.\nerrmeasure=DefaultErrmeasure(nep): When this errmeasure is specified, NEP-PACK tries to determine a error measure for you. In general, StandardSPMFErrmeasure will be preferred if possible. This behavior may change in future versions of NEP-PACK.\nerrmeasure=EigvalReferenceErrmeasure(nep,λref): This errmeasure is used when an exact (or very accurate) eigenvalue is already known. Typically, if you wish to visualize the eigenvalue error of a specific method, you run the method twice and use the result of the first run as to instantiate this error measure and get real eigenvalue errors as output.\nerrmeasure=(λ,v)-> compute_error(λ,v): A user defined error measure can be specified using a function. The function should be take an eigenpair as input, and return a real value. See ErrmeasureType for an example.","category":"page"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"Example: Most NEP-solvers take the errmeasure as an kwarg.","category":"page"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"julia> nep=nep_gallery(\"qdep0\");\njulia> # Solve the problem to residual norm 1e-8\njulia> (λ,v)=mslp(nep,errmeasure=ResidualErrmeasure(nep),tol=1e-8);\njulia> norm(compute_Mlincomb(nep,λ,v))/norm(v) # It's smaller than tol?\n3.503700738108789e-9\njulia> nep isa AbstractSPMF # Is it an AbstractSPMF so we can use StandardSPMFErrmeasure?\ntrue\njulia> (λ,v)=mslp(nep,errmeasure=StandardSPMFErrmeasure(nep),tol=1e-10);\njulia> fv = get_fv(nep); Av = get_Av(nep);\njulia> factor=abs(fv[1](λ))*norm(Av[1])+\n     abs(fv[2](λ))*norm(Av[2])+abs(fv[3](λ))*norm(Av[3]);\njulia> norm(compute_Mlincomb(nep,λ,v))/(norm(v)*factor)\n1.6591695084414612e-11","category":"page"},{"location":"errmeasure/#User-defined-error-measure","page":"Measuring the error","title":"User defined error measure","text":"","category":"section"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"A common situation is that you want to report the error (as a function of iteration) with a reference solution. We take this situation as an example and show how a relative error of the eigenvalue estimate, compared to a reference solution, can be computed. Compare with type EigvalReferenceErrmeasure which measures an absolute error relative a reference solution.","category":"page"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"There are two ways that a user can specify how to measure the error.","category":"page"},{"location":"errmeasure/#User-defined-error-1:-Function-handle","page":"Measuring the error","title":"User defined error 1: Function handle","text":"","category":"section"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"The user can provide a function handle which is called to obtain the error. The errmeasure can be a function, which takes two parameters as input (λ,v) and returns the error (or estimate thereof).","category":"page"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"If we want to get a very accurate approximation of the true error, we can run the algorithm twice, and the second time we run the algorithm we use the result of the first run as a reference.","category":"page"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"julia> nep=nep_gallery(\"qdep0\");\njulia> v0=ones(size(nep,1));\njulia> (λref,_)=resinv(nep,v=v0,λ=-0.1,logger=0);\njulia> myerrmeasure = (λ,v) -> abs(λ-λref)/abs(λ);\njulia> (λ,v)=resinv(nep,v=v0,λ=-0.1,logger=1,tol=1e-10,errmeasure=myerrmeasure);\nPrecomputing linsolver\niter 1 err:0.02854168838549373 λ=-0.1 + 0.0im\niter 2 err:0.8397508140476416 λ=-0.6418389474323298 + 0.0im\niter 3 err:0.17336372619725743 λ=-0.08765753239354723 + 0.0im\niter 4 err:0.0005771170619943501 λ=-0.1029135620110966 + 0.0im\niter 5 err:4.762006833879597e-7 λ=-0.10285411985934721 + 0.0im\niter 6 err:4.074039107701665e-7 λ=-0.10285421074175707 + 0.0im\niter 7 err:2.6448037288912206e-8 λ=-0.10285417155884034 + 0.0im\niter 8 err:1.3926542408883378e-9 λ=-0.10285416898178967 + 0.0im\niter 9 err:6.324560618281378e-11 λ=-0.10285416884505445 + 0.0im","category":"page"},{"location":"errmeasure/#User-defined-error-2:-A-user-defined-type","page":"Measuring the error","title":"User defined error 2: A user defined type","text":"","category":"section"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"Due to the multiple dispatch and handling of types in Julia, code may run faster if one uses types instead of function handles. It is possible to do the same simulation as above with a user defined type.","category":"page"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"You first need to define a new type","category":"page"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"julia> struct RefErrmeasure <: Errmeasure; end","category":"page"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"The error measure should then provided in the function estimate_error which we now define as the relative eigenvalue error:","category":"page"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"julia> function NonlinearEigenproblems.estimate_error(e::RefErrmeasure,λ,v)\n         return abs(λ-λref)/abs(λ);\n       end\njulia> (λ,v)=resinv(nep,v=v0,λ=0.1,logger=1,tol=1e-10,errmeasure=RefErrmeasure());\nPrecomputing linsolver\niter 1 err:0.02854168838549373 λ=-0.1 + 0.0im\niter 2 err:0.8397508140476416 λ=-0.6418389474323298 + 0.0im\niter 3 err:0.17336372619725743 λ=-0.08765753239354723 + 0.0im\niter 4 err:0.0005771170619943501 λ=-0.1029135620110966 + 0.0im\niter 5 err:4.762006833879597e-7 λ=-0.10285411985934721 + 0.0im\niter 6 err:4.074039107701665e-7 λ=-0.10285421074175707 + 0.0im\niter 7 err:2.6448037288912206e-8 λ=-0.10285417155884034 + 0.0im\niter 8 err:1.3926542408883378e-9 λ=-0.10285416898178967 + 0.0im\niter 9 err:6.324560618281378e-11 λ=-0.10285416884505445 + 0.0im","category":"page"},{"location":"errmeasure/#As-a-NEP-solver-developer","page":"Measuring the error","title":"As a NEP-solver developer","text":"","category":"section"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"NEP-solvers should use the Errmeasure as follows. The NEP-solver should take as input an object of the type Errmeasure  or function. The fact that it can be different types, is transparent and a NEP-solver developer does not have to do anything to take care of that if the following procedure is followed.","category":"page"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"Suppose your solver is defined in a function with this signature:","category":"page"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"function mysolver(nep::NEP; errmeasure::ErrmeasureType=DefaultErrmeasure(nep), tol::Real=eps()*100)","category":"page"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"In the main for loop you want to call the estimate_error function:","category":"page"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"for k=1:maxit\n    err=estimate_error(errmeasure,λ,v)\n    if (err < tol)\n       return (λ,v)\n    end\n    ....\n\nend","category":"page"},{"location":"errmeasure/#Methods-and-types","page":"Measuring the error","title":"Methods and types","text":"","category":"section"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"Errmeasure","category":"page"},{"location":"errmeasure/#NonlinearEigenproblems.NEPTypes.Errmeasure","page":"Measuring the error","title":"NonlinearEigenproblems.NEPTypes.Errmeasure","text":"abstract type Errmeasure; end\n\nConcrete subtypes of Errmeasure represent specific ways of measuring the error of an eigenpair. NEP-solvers take such an object as input. As a NEP-solver user, you use the type as follows\n\njulia> quasinewton(nep,errmeasure=ResidualErrmeasure(nep))\n\nUser-specified ways of measuring error can be given by creating a new subtype of Errmeasure and using it as a errmeasure keyword. You need to specify the way to measure the error in the method estimate_error.\n\nNote that in practice a Function can essentially be used instead of a Errmeasure-object, which is a simple way to have user-defined error measures. See ErrmeasureType.\n\nSee also: ErrmeasureType, DefaultErrmeasure, ResidualErrmeasure, StandardSPMFErrmeasure, estimate_error, EigvalReferenceErrmeasure.\n\n\n\n\n\n","category":"type"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"DefaultErrmeasure","category":"page"},{"location":"errmeasure/#NonlinearEigenproblems.NEPTypes.DefaultErrmeasure","page":"Measuring the error","title":"NonlinearEigenproblems.NEPTypes.DefaultErrmeasure","text":"struct DefaultErrmeasure <: Errmeasure\nfunction DefaultErrmeasure(nep::NEP)\n\nWhen you specify this Errmeasure, NEP-PACK tries to determine a suitable Errmeasure based on the type of the NEP. Note that this behavior may change in future versions.\n\nSee also: Errmeasure\n\n\n\n\n\n","category":"type"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"StandardSPMFErrmeasure","category":"page"},{"location":"errmeasure/#NonlinearEigenproblems.NEPTypes.StandardSPMFErrmeasure","page":"Measuring the error","title":"NonlinearEigenproblems.NEPTypes.StandardSPMFErrmeasure","text":"struct StandardSPMFErrmeasure <: Errmeasure\nfunction StandardSPMFErrmeasure(nep::AbstractSPMF)\n\nThis Errmeasure provides a way to compute the backward error. The backward error estimate are only given for NEPs which are subtypes of  AbstractSPMF. We use the Frobenius norm as the matrix norm, since it is much cheaper to compute than the spectral norm.\n\nExample\n\njulia> nep=nep_gallery(\"qdep0\");\njulia> (λ,v)=quasinewton(nep,λ=-1,v=ones(size(nep,1)),errmeasure=StandardSPMFErrmeasure(nep),tol=1e-10,logger=1);\nPrecomputing linsolver\niter 1 err:0.022010375110869937 λ=-1.0 + 0.0im\niter 2 err:0.002515422247048546 λ=-0.7063330111559607 + 0.0im\niter 3 err:0.000892354247568813 λ=-0.8919579082730457 + 0.0im\niter 4 err:5.445678793151584e-5 λ=-1.0097584042560848 + 0.0im\niter 5 err:6.649967517409105e-7 λ=-1.0023823873044 + 0.0im\niter 6 err:1.0557281809769784e-8 λ=-1.0024660870524031 + 0.0im\niter 7 err:6.420125566431444e-9 λ=-1.0024677891861997 + 0.0im\niter 8 err:3.181093707909799e-10 λ=-1.0024669496893164 + 0.0im\niter 9 err:2.6368050026394416e-11 λ=-1.0024669918249076 + 0.0im\n\n\nSee also: Errmeasure\n\n\n\n\n\n","category":"type"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"ResidualErrmeasure","category":"page"},{"location":"errmeasure/#NonlinearEigenproblems.NEPTypes.ResidualErrmeasure","page":"Measuring the error","title":"NonlinearEigenproblems.NEPTypes.ResidualErrmeasure","text":"struct ResidualErrmeasure <: Errmeasure\nfunction ResidualErrmeasure(nep::NEP)\n\nThis Errmeasure species that the residual norm should be used to measure the error.\n\nSee also: Errmeasure\n\n\n\n\n\n","category":"type"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"EigvalReferenceErrmeasure","category":"page"},{"location":"errmeasure/#NonlinearEigenproblems.NEPTypes.EigvalReferenceErrmeasure","page":"Measuring the error","title":"NonlinearEigenproblems.NEPTypes.EigvalReferenceErrmeasure","text":"struct EigvalReferenceErrmeasure{X<:Number} <: Errmeasure\nfunction EigvalReferenceErrmeasure(nep,λref)\n\nUse the difference between a precomputed λ-value (reference solution) and the eigenvalue estimate as the error measure.\n\nExample\n\njulia> using LinearAlgebra\njulia> nep=nep_gallery(\"qdep0\");\njulia> (λref,vref)=quasinewton(nep,λ=-1,v=ones(size(nep,1)));\njulia> (λ,v)=quasinewton(nep,errmeasure=EigvalReferenceErrmeasure(nep,λref),λ=-1.0 ,logger=1,tol=5e-13,v=ones(size(nep,1)));\nPrecomputing linsolver\niter 1 err:0.002466988585763996 λ=-1.0 + 0.0im\niter 2 err:0.2961339774298033 λ=-0.7063330111559607 + 0.0im\niter 3 err:0.11050908031271833 λ=-0.8919579082730457 + 0.0im\niter 4 err:0.007291415670320767 λ=-1.0097584042560848 + 0.0im\niter 5 err:8.460128136400513e-5 λ=-1.0023823873044 + 0.0im\niter 6 err:9.015333608530796e-7 λ=-1.0024660870524031 + 0.0im\niter 7 err:8.006004357241636e-7 λ=-1.0024677891861997 + 0.0im\niter 8 err:3.889644761834177e-8 λ=-1.0024669496893164 + 0.0im\niter 9 err:3.2391436199930013e-9 λ=-1.0024669918249076 + 0.0im\niter 10 err:2.418474309706653e-10 λ=-1.0024669883439166 + 0.0im\niter 11 err:2.0230705999324528e-11 λ=-1.0024669886059947 + 0.0im\niter 12 err:0.0 λ=-1.002466988585764 + 0.0im\n\nSee also: Errmeasure\n\n\n\n\n\n","category":"type"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"estimate_error","category":"page"},{"location":"errmeasure/#NonlinearEigenproblems.NEPTypes.estimate_error","page":"Measuring the error","title":"NonlinearEigenproblems.NEPTypes.estimate_error","text":"function estimate_error(E::ErrmeasureType,λ,v)\n\nReturns the error estimate for the eigenpair (λ,v). The way to measure the error is specified in E, which can be an Errmeasure or a Function.\n\nSee also: Errmeasure, ErrmeasureType\n\n\n\n\n\n","category":"function"},{"location":"errmeasure/","page":"Measuring the error","title":"Measuring the error","text":"ErrmeasureType","category":"page"},{"location":"errmeasure/#NonlinearEigenproblems.NEPTypes.ErrmeasureType","page":"Measuring the error","title":"NonlinearEigenproblems.NEPTypes.ErrmeasureType","text":"ErrmeasureType = Union{Type{<:Errmeasure}, Function}\n\nThe ErrmeasureType represents (essentially) what you can insert in the errmeasure keyword argument for most NEP-solvers. It can be a function or an  Errmeasure object. If it is a Function this function will be used to obtain error estimate.\n\nExample\n\nThis shows how to compute a reference solution and then use this as a reference solution. The error in the second run will be effectively the eigenvector error (appropriately normalized).\n\njulia> using LinearAlgebra\njulia> nep=nep_gallery(\"qdep0\");\njulia> (λref,vref)=quasinewton(nep,λ=-1,v=ones(size(nep,1)));\njulia> myerrmeasure=(λ,v) -> norm(vref/vref[1]-v/v[1]);\njulia> (λ,v)=quasinewton(nep,errmeasure=myerrmeasure,λ=-1.0 ,logger=1,tol=5e-13,v=ones(size(nep,1)));\nPrecomputing linsolver\niter 1 err:46.40296482739195 λ=-1.0 + 0.0im\niter 2 err:2.1592671533657883 λ=-0.7063330111559607 + 0.0im\niter 3 err:0.17079231439255405 λ=-0.8919579082730457 + 0.0im\niter 4 err:0.1633846991066227 λ=-1.0097584042560848 + 0.0im\niter 5 err:0.003434042059262583 λ=-1.0023823873044 + 0.0im\niter 6 err:0.0003182517281689052 λ=-1.0024660870524031 + 0.0im\niter 7 err:2.0105257231740345e-5 λ=-1.0024677891861997 + 0.0im\niter 8 err:1.618661190265619e-6 λ=-1.0024669496893164 + 0.0im\niter 9 err:1.233489068442819e-7 λ=-1.0024669918249076 + 0.0im\niter 10 err:9.44707811957546e-9 λ=-1.0024669883439166 + 0.0im\niter 11 err:7.867601351698812e-10 λ=-1.0024669886059947 + 0.0im\niter 12 err:0.0 λ=-1.002466988585764 + 0.0im\n\n\nThe eigenvalue error can be measured with the EigvalReferenceErrmeasure.\n\nSee also: Errmeasure\n\n\n\n\n\n","category":"type"},{"location":"tutorial_python_call/#Tutorial:-Using-NEP-PACK-from-python","page":"Tutorial 6 (Python 2)","title":"Tutorial: Using NEP-PACK from python","text":"","category":"section"},{"location":"tutorial_python_call/#PyJulia","page":"Tutorial 6 (Python 2)","title":"PyJulia","text":"","category":"section"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":"The previous tutorial illustrated how a NEP defined in python code can be solved with NEP-PACK. Python is currently a more mature language than Julia, and there are considerable packages and features in python not present in Julia. If you need these features, it may be more convenient to call NEP-PACK from  python, rather than calling python code from julia.","category":"page"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":"The python package PyJulia gives us that possibility. The installation of PyJulia on Ubuntu linux is simple:","category":"page"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":"$ python3 -m pip install julia # Only necessary first time you run it\n...\n$ python3\n>>> from julia.api import Julia\n>>> jl = Julia(compiled_modules=False) # compilation flag necessary on ubuntu\n>>> julia.install()               # Only necessary first time you run it\n>>> from julia import Base\n>>> Base.MathConstants.golden  # Julia's definition of golden ratio\n1.618033988749895","category":"page"},{"location":"tutorial_python_call/#Using-PyJulia-and-NEP-PACK","page":"Tutorial 6 (Python 2)","title":"Using PyJulia and NEP-PACK","text":"","category":"section"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":"The Mder_NEP-function provides a convenient way to define NEPs by only using a function that computes the matrix M(λ) and its derivatives. Let us first define a function which does that in python. We consider the problem","category":"page"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":"M(λ)=beginbmatrix32newline3-1endbmatrix+\nλbeginbmatrix02newline01endbmatrix+\ne^05 λbeginbmatrix11newline11endbmatrix","category":"page"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":"and implement it with this python code:","category":"page"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":"import numpy as np;\nimport cmath as m;\ndef my_compute_M(s,der):\n    \"\"\"Compute the matrix M^{(k)}(s) for a given eigenvalue approximation and derivative k\"\"\"\n    A=np.matrix('3 2; 3 -1');  B=np.matrix('0 2; 0 1');   C=np.matrix('1 1; 1 1');\n    tau=0.5;\n    M=pow(tau,der)*m.exp(tau*s)*C\n    if (der==0):\n        M=M+A+s*B;\n    elif (der==1):\n        M=M+B;\n    return M","category":"page"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":"An evaluation of the matrix function can be done by the call:","category":"page"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":">>> my_compute_M(0.3,0)\nmatrix([[4.16183424+0.j, 3.76183424+0.j],\n        [4.16183424+0.j, 0.46183424+0.j]])","category":"page"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":"We instantiate a new NEP based with Mder_NEP which first must be imported","category":"page"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":">>> from julia.NonlinearEigenproblems import Mder_NEP\n>>> n=2; # Size of the problem\n>>> nep=Mder_NEP(2,my_compute_M);","category":"page"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":"and we can apply most of our solvers to this problem by first importing the corresponding function, in this case we use contour_beyn.","category":"page"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":">>> from julia.NonlinearEigenproblems import contour_beyn;\n>>> sol=contour_beyn(nep,logger=1,neigs=1,radius=3)\nComputing integrals\nNonlinearEigenproblems.NEPSolver.MatrixTrapezoidal: computing G...\nNonlinearEigenproblems.NEPSolver.MatrixTrapezoidal: summing terms........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\nComputing SVD prepare for eigenvalue extraction  p=1\nComputing eigenvalues\nComputing eigenvectors\n>>>","category":"page"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":"We can verify that we computed a solution as follows","category":"page"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":">>> s=sol[0][0]; v=sol[1]\n>>> my_compute_M(s,0)*v\nmatrix([[1.71634841e-17-1.59872116e-14j],\n        [9.55210099e-17-3.99680289e-15j]])\n>>> from numpy.linalg import norm\n>>> norm(my_compute_M(s,0)*v)\n1.6479526251408437e-14","category":"page"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":"Note that in order to obtain better efficiency for large-scale problems, and reduce overhead, you may want to use Mder_Mlincomb_NEP, as described in the previous tutorial.","category":"page"},{"location":"tutorial_python_call/","page":"Tutorial 6 (Python 2)","title":"Tutorial 6 (Python 2)","text":"(Image: To the top)","category":"page"},{"location":"tutorial_fortran1/#Tutorial:-Solving-a-NEP-defined-in-fortran","page":"Tutorial 8 (FORTRAN)","title":"Tutorial: Solving a NEP defined in fortran","text":"","category":"section"},{"location":"tutorial_fortran1/#A-problem-defined-in-fortran","page":"Tutorial 8 (FORTRAN)","title":"A problem defined in fortran","text":"","category":"section"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"A situation may arise where you  have to (or have the opportunity to) work with fortran code. This is not as uncommon as many think, often due to the legacy software in many engineering disciplines. The Julia language is designed with interoperability in mind. Don't let some fortran code scare you. The following tutorial illustrates interoperability in Julia and how to use it in NEP-PACK.","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"note: Note\nTo work with NEPs defined in fortran you need to compile your fortran code. This tutorial is written for Ubuntu Linux and GNU fortran. However, the procedure is very similiar with other operating systems and compilers.","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"We assume our NEP is defined in fortran code and defines the problem","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"M(lambda)=A_0+lambda^3e_ne_1^T-exp(lambda)e_1e_n^T","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"where A_0 is a finite difference approximation of a scaled Laplacian matrix. The problem can be naturally represented in sparse format, which we will also take advantage of.","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"The fortran implementation of the problem is given in the following subroutine which computes three vectors I, J and F, where I and J correspond to row and column pointers and F the value of the sparse matrix. The variable s is λ, i.e., the evaluation point. The input der determines which derivative of M(λ) should be computed.","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"tip: Tip\nLater in this tutorial we look at what can be done if the derivatives are not easily available.","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"This is the implementation which we put in myproblem.f95:","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"subroutine mder(s,n,der,I,J,F)\n  real*8, intent(in) :: s\n  integer*8, intent(in) :: n\n  integer*8, intent(in) :: der\n  integer*8, intent(out), dimension(3*n):: I\n  integer*8, intent(out), dimension(3*n):: J\n  real*8, intent(out), dimension(3*n):: F\n  integer*8 :: p\n  real*8 :: factor\n  if (der==0) then\n     factor=1;\n  else\n     factor=0;\n  end if\n  do p = 1, n\n     I(p) = p\n     J(p) = p\n     F(p) = 2.0*factor;\n  end do\n  do p = 1, n-1\n     I(n+p) = p\n     J(n+p) = p+1\n     F(n+p) = -1.0*factor;\n     I(2*n+p) = p+1\n     J(2*n+p) = p\n     F(2*n+p) = -1.0*factor;\n  end do\n  I(2*n)=n;\n  J(2*n)=1;\n  if (der == 0) then\n     F(2*n)=s*s*s;\n  else if (der == 1) then\n     F(2*n)=3*s*s;\n  else if (der == 2) then\n     F(2*n)=3*2*s;\n  else if (der == 3) then\n     F(2*n)=3*2;\n  else\n     F(2*n)=0;\n  end if\n  I(3*n)=1;\n  J(3*n)=n;\n  F(3*n)=-exp(s);\nend subroutine mder","category":"page"},{"location":"tutorial_fortran1/#Compile-and-call-the-code","page":"Tutorial 8 (FORTRAN)","title":"Compile and call the code","text":"","category":"section"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"Compile the code to a shared object file with the command gfortran:","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"$ gfortran -shared -fPIC -o myproblem.so myproblem.f95","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"(Under the Windows OS, you would want to compile the code to a dll-file.) In Julia, you can now call this routine using the Libdl package:","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"using NonlinearEigenproblems, Libdl;\nmylib=Libdl.dlopen(\"./myproblem.so\");\nλ=0.3;\nder=0;\nn=3; # Problem size\nI=Vector{Int}(undef,3*n); # 3*n nnz elements in matrix\nJ=Vector{Int}(undef,3*n); # 3*n nnz elements in matrix\nF=Vector{Float64}(undef,3*n); # 3*n nnz elements in matrix\n# This is the call to the fortran code\n# Note that :mder_ is a reference to a fortran subroutine:\n# it must be lower-case and  a _ should be appended\nccall(Libdl.dlsym(mylib,:mder_), Nothing,\n   (Ref{Float64}, Ref{Int},Ref{Int},  Ptr{Int}, Ptr{Int}, Ptr{Float64}),\n   λ, n, der, I, J, F)","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"The above code sets vectors I, J and F such that they represent a sparse matrix. The sparse matrix can be constructed with the sparse command:","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"julia> using SparseArrays\njulia> A=sparse(I,J,F)\n3×3 SparseMatrixCSC{Float64,Int64} with 9 stored entries:\n  [1, 1]  =  2.0\n  [2, 1]  =  -1.0\n  [3, 1]  =  0.027\n  [1, 2]  =  -1.0\n  [2, 2]  =  2.0\n  [3, 2]  =  -1.0\n  [1, 3]  =  -1.34986\n  [2, 3]  =  -1.0\n  [3, 3]  =  2.0\njulia> Matrix(A)\n3×3 Array{Float64,2}:\n  2.0    -1.0  -1.34986\n -1.0     2.0  -1.0\n  0.027  -1.0   2.0","category":"page"},{"location":"tutorial_fortran1/#Implementation-in-NEP-PACK:-basic-usage","page":"Tutorial 8 (FORTRAN)","title":"Implementation in NEP-PACK: basic usage","text":"","category":"section"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"We saw above how to compute a derivative matrix with a fortran call. This is sufficient to define a NEP-object in NEP-PACK using the Mder_NEP type.","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"n=100;\n# A function which allocates vectors and calls fortran,\n# and returns a sparse matrix\nfunction my_Mder(λ::Float64,der::Int=0)\n  # Index vectors: Length 3*n since we have 3n nnz elements in matrix\n  I=Vector{Int}(undef,3*n);\n  J=Vector{Int}(undef,3*n);\n  F=Vector{Float64}(undef,3*n);\n  ccall(Libdl.dlsym(mylib,:mder_), Nothing,\n     (Ref{Float64}, Ref{Int},Ref{Int},  Ptr{Int}, Ptr{Int}, Ptr{Float64}),\n     λ, n, der, I, J, F)\n  return sparse(I,J,F);\nend\nnep=Mder_NEP(n,my_Mder);","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"With the NEP defined, we can use, e.g., quasinewton, to solve it:","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"julia> quasinewton(Float64,nep,λ=-1.8,v=ones(n), logger=1);\nPrecomputing linsolver\nIteration:  1 errmeasure:4.903565024143569095e-01, λ=-1.8\nIteration:  2 errmeasure:8.776860766232853772e-02, λ=-1.3816406142423465\nIteration:  3 errmeasure:6.109070850428219984e-02, λ=-2.0060080798679913\n...\nIteration: 11 errmeasure:5.305001776886219717e-12, λ=-1.7940561686588974\nIteration: 12 errmeasure:2.895637837297152945e-14, λ=-1.7940561686787597\nIteration: 13 errmeasure:3.874312247075750238e-16, λ=-1.7940561686786516","category":"page"},{"location":"tutorial_fortran1/#Implementation-in-NEP-PACK:-basic-usage,-no-derivatives","page":"Tutorial 8 (FORTRAN)","title":"Implementation in NEP-PACK: basic usage, no derivatives","text":"","category":"section"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"In the above example, all the derivatives of M(λ) were easy to compute by hand and made available in the fortran subroutine. In many applications, the nonlinearity is not so simple, and its derivatives may require man-hours to analyze and implement, or may be very computationally expensive.","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"Most NEP-algorithms in NEP-PACK do require the derivative (except for certain versions of nleigs, broyden, contour_beyn, contour_block_SS, and sgiter). However, many NEP-algorithms do not require a very accurate derivative. We now show how you can make a numerical approximation of the derivative available, if you do not want to compute the exact derivative. The example below uses finite differences, but any numerical differentiation procedure may be used. (The code does not use derivatives in mder, since all calls are done with der=0.)","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"n=100;\nfunction my_Mder_FD(λ::Float64,der::Int=0)\n  if (der>1)\n   error(\"Higher derivatives not supported\");\n  end\n  # 3*n nnz elements in matrix\n  I=Vector{Int}(undef,3*n);\n  J=Vector{Int}(undef,3*n);\n  F1=Vector{Float64}(undef,3*n);\n  ccall(Libdl.dlsym(mylib,:mder_), Nothing,\n     (Ref{Float64}, Ref{Int},Ref{Int},  Ptr{Int}, Ptr{Int}, Ptr{Float64}),\n     λ, n, 0, I, J, F1)\n  if (der==0)\n     return sparse(I,J,F1);\n  end\n\n  if (der==1)\n     # Make another fortran call to make a finite difference approximation\n     ee=sqrt(eps());\n     F2=Vector{Float64}(undef,3*n);\n     ccall(Libdl.dlsym(mylib,:mder_), Nothing,\n          (Ref{Float64}, Ref{Int},Ref{Int},  Ptr{Int}, Ptr{Int}, Ptr{Float64}),\n          λ-ee, n, 0, I, J, F2)\n     # We exploit the fact that the sparsity pattern is independent of λ\n     Fder=(F1-F2)/ee;\n     return sparse(I,J,Fder);\n  end\nend","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"Create the NEP and call a solver, in this case MSLP.","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"julia> nep=Mder_NEP(n,my_Mder_FD,maxder=1);\njulia> mslp(Float64,nep,λ=-1.8,logger=1);\niter 1 err:5.14547949525844e-6 λ=-1.7941228234498503\niter 2 err:6.60477516490422e-10 λ=-1.7940561772509709\niter 3 err:5.617933513637005e-16 λ=-1.794056168678654","category":"page"},{"location":"tutorial_fortran1/#Implementation-in-NEP-PACK:-advanced-usage","page":"Tutorial 8 (FORTRAN)","title":"Implementation in NEP-PACK: advanced usage","text":"","category":"section"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"The above procedure requires that sparse matrices are created every time the NEP is accessed. This may be computationally demanding. A common call in NEP-PACK, is to compute the matrix vector product M(λ)*v. If the creation of the matrix M(λ) requires considerable computation or storage, you may want to implement the function which directly computes the matrix vector product. This is made available to the NEP-PACK object as follows.","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"Add the following to your myproblem.f95:","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"subroutine matvec(s,n,v,x)\n  real*8, intent(in) :: s\n  integer*8, intent(in) :: n\n  real*8, intent(in), dimension(n):: v\n  real*8, intent(out), dimension(n):: x\n  integer*8 :: p\n  do p = 1, n\n      x(p)=2*v(p)\n  end do\n  do p = 1, n-1\n      x(p)= x(p) - v(p+1)\n      x(p+1)= x(p+1) - v(p)\n  end do\n  x(n)=x(n)+v(1)*s*s*s;\n  x(1)=x(1)-v(n)*exp(s);\nend subroutine matvec","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"After recompilation of the library file myproblem.so, restarting Julia, and loading again myproblem.so, we can make a matvec function available.","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"function my_matvec(λ,v)\n   v=vec(v);  # It has to be a vector\n   x=copy(v); # Allocate a vector for storage of result\n   ccall(Libdl.dlsym(mylib,:matvec_), Nothing,\n      (Ref{Float64}, Ref{Int}, Ptr{Float64},  Ptr{Float64}),\n      λ, n, v, x)\n   return x;\nend","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"We can now create a Mder_Mlincomb_NEP which is defined from both matrix derivative computations as well as matrix vector products (or a linear combinations of derivatives).","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"julia> nep2=Mder_Mlincomb_NEP(n,my_Mder,1,my_matvec,0);","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"The 1 and 0 specify the highest derivative available for the two functions. We can now solve the NEP with many methods, e.g. resinv.","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"julia> resinv(Float64,nep2,λ=-1.8,v=ones(n),logger=1);\nPrecomputing linsolver\niter 1 err:0.4903565024143571 λ=-1.8\niter 2 err:0.11453605256493624 λ=-1.1926857650225988\n...\niter 7 err:5.834331567428063e-13 λ=-1.7940561686808254\niter 8 err:2.989922602862964e-15 λ=-1.794056168678641","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"When using NEP-solvers requiring higher derivatives, the above procedure can also be used to compute linear combinations of higher derivatives by implementing a compute_Mlincomb which takes a matrix as input.","category":"page"},{"location":"tutorial_fortran1/","page":"Tutorial 8 (FORTRAN)","title":"Tutorial 8 (FORTRAN)","text":"(Image: To the top)","category":"page"},{"location":"methods/#NEP-Solvers","page":"NEP-Solvers","title":"NEP-Solvers","text":"","category":"section"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"The NEP solver methods implemented in NEP-PACK, are accessed by the functions below. The functions all return λv where λ is either a number (eigenvalue) a vector of eigenvalues v is either a vector containing an eigenvector or a matrix whose columns corresponding to the eigenvectors. Two-sided methods may return λvw where w are the left eigenvectors.","category":"page"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"The first optional parameter in all NEP solver methods is a type. This type specifies which arithmetic should be used for the algorithm.","category":"page"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"Example:","category":"page"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"julia> nep=nep_gallery(\"dep0\");\njulia> λ,v=augnewton(ComplexF64,nep,v=ones(5))\n(-0.15955391823299256 + 0.0im, Complex{Float64}[0.12505315954062152 + 0.0im, 0.8475907515488971 + 0.0im, -0.10910413290558324 + 0.0im, 0.027714719799174125 + 0.0im, 0.10874550201689052 + 0.0im])\njulia> typeof(λ)\nComplex{Float64}\njulia> λ,v=augnewton(Float16,nep,v=ones(5))\n(Float16(-0.718), Float16[0.435, 0.6606, -0.205, -0.1445, 0.254])\njulia> typeof(λ)\nFloat16","category":"page"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"The NEP-solvers can be separated into the following types (with some overlap):","category":"page"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"Newton type methods\nProjection methods\nContour integral methods\nArnoldi and Krylov based methods\nClass specific methods","category":"page"},{"location":"methods/#Newton-type-methods","page":"NEP-Solvers","title":"Newton type methods","text":"","category":"section"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"newton","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.newton","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.newton","text":"λ,v = newton([eltype],nep::NEP;[errmeasure,][tol,][maxit,][λ,][v,][c,][logger,][armijo_factor=1,][armijo_max])\n\nApplies Newton-Raphsons method on the system of nonlinear equations with n+1 unknowns:\n\nM(λ)v=0\n\nc^Hv-1=0\n\nThe vector c is the orthogonalization vector.  If c=0 the current approximation will be used for the orthogonalization. See augnewton for other parameters.\n\nExample\n\njulia> using LinearAlgebra\njulia> nep=nep_gallery(\"dep0\");\njulia> λ,v=newton(nep);\njulia> minimum(svdvals(compute_Mder(nep,λ)))\n1.9997125567227177e-16\n\nReferences\n\nNichtlineare Behandlung von Eigenwertaufgaben, Z. Angew. Math. Mech. 30 (1950) 281-282.\nA. Ruhe, Algorithms for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 10 (1973) 674-689\n\n\n\n\n\n","category":"function"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"augnewton","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.augnewton","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.augnewton","text":"augnewton([eltype], nep::NEP; [errmeasure,][tol,][maxit,][λ,][v,][c,][logger,][linsolvercreator,][armijo_factor,][armijo_max])\n\nRun the augmented Newton method. The method is equivalent to newton() in exact arithmetic,  but works only with operations on vectors of length n.\n\nThe following keyword arguments are in common for many NEP-solvers:\n\nlogger is either a Logger object or an Int. If it is an Int, a PrintLogger(logger) will be instantiated. logger=0 prints nothing, logger=1 prints more, etc.\nerrmeasure determines how error is measured. It is either a function handle or an object of the type Errmeasure.  If it is a function handle, it should take (λ,v) as input and return a real scalar (the error). See Errmeasure and ErrmeasureType for further description.\ntol is a scalar which determines termination. If errmeasure is less than tol the eigenpair is marked as converged.\nThe scalar λ and the vector v are starting approximations.\nmaxit determines the maximum number of iterations. The error NoConvergenceException is thrown if this is exceeded.\nThe linsolvecreator specifies how the linear system should be solved. See LinSolver for further information.\narmijo_factor specifies if an Armijo rule should be applied, and its value specifies the scaling factor of the step length (per reduction step). The variable armijo_max specifies the maximum number of step length reductions.\n\nExample\n\nThis illustrates the equivalence between newton and augnewton.\n\njulia> nep=nep_gallery(\"dep1\")\njulia> λ1,v1=newton(nep,maxit=20,v=ones(size(nep,1)),λ=0)\njulia> λ2,v2=augnewton(nep,maxit=20,v=ones(size(nep,1)),λ=0)\njulia> λ1-λ2\n0.0 + 0.0im\n\nReferences\n\nNichtlineare Behandlung von Eigenwertaufgaben, Z. Angew. Math. Mech. 30 (1950) 281-282.\nA. Ruhe, Algorithms for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 10 (1973) 674-689\n\n\n\n\n\n","category":"function"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"resinv","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.resinv","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.resinv","text":"λ,v = resinv([eltype],nep::NEP;[errmeasure,][tol,][maxit,][λ,][v,][c,][logger,][armijo_factor=1,][armijo_max,][linsolvecreator])\n\nApplies residual inverse iteration method for nonlinear eigenvalue problems. The kwarg linsolvecreator is a function which specifies how the linear system is created. The function calls compute_rf for the computation of the Rayleigh functional. See augnewton for other parameters.\n\nExample\n\nThe example shows how to specify if the method should run in real or complex mode (or any other Number type).\n\njulia> nep=nep_gallery(\"qdep0\");\njulia> λ,v=resinv(nep,λ=-2,v=ones(size(nep,1)))\njulia> typeof(λ)\nComplex{Float64}\njulia> norm(compute_Mlincomb(nep,λ,v))\n6.688224435370382e-12\njulia> λ,v=resinv(Float64,nep,λ=-2,v=ones(size(nep,1)))\njulia> typeof(λ)\nFloat64\njulia> norm(compute_Mlincomb(nep,λ,v))\n5.939894690000396e-12\n\nReferences\n\nA. Neumaier, Residual inverse iteration for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 22 (1985) 914-923\n\n\n\n\n\n","category":"function"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"quasinewton","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.quasinewton","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.quasinewton","text":"quasinewton([T=ComplexF64],nep,[errmeasure,][tol,][maxit,][λ,][v][ws][logger][linsolvercreator,][armijo_factor,][armijo_max])\n\nAn implementation of the quasi-Newton approach referred to as quasi-Newton 2 in the reference. The method involves one linear system solve per iteration corresponding with the matrix M(λ), where λ is constant. The vector ws is a representation of the normalization, in the sense that c^T=w_s^TM(λ), where all iterates satisfy c^Tx_i=1. See augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"pep0\")\njulia> λ,v=quasinewton(nep,λ=1.0,v=ones(size(nep,1)));\njulia> norm(compute_Mlincomb(nep,λ,v))/norm(v)\n5.448264607410413e-12\n\nReferences\n\nJarlebring, Koskela, Mele, Disguised and new Quasi-Newton methods for nonlinear eigenvalue problems, Numer. Algorithms, 79:311-335, 2018. preprint\n\n\n\n\n\n","category":"function"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"mslp","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.mslp","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.mslp","text":" mslp([eltype],nep::NEP;[errmeasure,][tol,][maxit,][λ,][logger,][eigsolvertype::Type])\n\nRuns the method of successive linear problems. The  method requires the solution of a generalized eigenvalue problem in every iteration. The method used for the eigenvalue computation is specified in eigsolvertype. See augnewton for other parameters.\n\nExample\n\nCreate a rational NEP using a SPMF_NEP.\n\njulia> eye=Matrix{Float64}(I,3,3);\njulia> Av=[ones(3,3),eye,triu(ones(3,3))];\njulia> fv=[S-> S, S -> S^2, S->inv(S-one(S)*10)];\njulia> nep=SPMF_NEP(Av,fv);\njulia> (λ,v)=mslp(nep);\njulia> compute_Mlincomb(nep,λ,v)\n3-element Array{Complex{Float64},1}:\n -1.38778e-17+1.65715e-18im\n -5.55112e-17+1.30633e-17im\n -4.16334e-17-1.54436e-17im\n\nReferences\n\nA. Ruhe, Algorithms for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 10 (1973) 674-689\n\n\n\n\n\n","category":"function"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"sgiter","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.sgiter","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.sgiter","text":"λ,v = sgiter([eltype],nep::NEP,j::Integer;[λ_min,][λ_max,][λ,][errmeasure,][tol,][maxit,][logger,][eigsolvertype::Type,])\n\nFinds the j-th eigenvalue of the NEP using safeguarded iteration, with eigenvalue numbering according to min-max theory. The method only works for Hermitian problems, and the eigenvalues are assumed to be real. If an interval [λ_min,λ_max] is given, then the Rayleigh functional is assumed to be unique on the interval. If no interval is given, then the minimum solution is always taken. The method requires the computation of (all) eigenvalues of a matrix. The eigsolvertype is a Type that specifies which eigevalue solver is used inside the algorithm.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> nep = nep_gallery(\"real_quadratic\");\njulia> λ,v = sgiter(nep, 1, λ_min = -10, λ_max = 0,  λ = -10, maxit = 100);\njulia> minimum(svdvals(compute_Mder(nep,λ)))\n0.0\njulia> norm(v)\n1.0\n\nReferences\n\nV. Mehrmann and H. Voss, Nonlinear eigenvalue problems: a challenge for modern eigenvalue methods, GAMM‐Mitteilungen 27.2 (2004): 121-152.\nH. Voss and B. Werner, Solving sparse nonlinear eigenvalue problems. Technical Report 82/4, Inst. f. Angew. Mathematik, Universität Hamburg, 1982.\nB. Werner. Das Spektrum von Operatorenscharen mit verallgemeinerten Rayleighquotienten. PhD thesis, Fachbereich Mathematik, Universität Hamburg, 1970\n\n\n\n\n\n","category":"function"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"rfi","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.rfi","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.rfi","text":"rfi(nep,nept,[λ=0,][errmeasure,][tol=eps()*100,][maxit=100,][v=randn,][u=randn,][logger=0,][linsolvecreator=DefaultLinSolverCreator(),])\n\nThis is an implementation of the two-sided Rayleigh functional Iteration (RFI) to compute an eigentriplet of the problem specified by nep. This method requires the transpose of the NEP, specified in nept. λ, u and v are initial guesses for the eigenvalue, the right eigenvector and the left eigenvector respectively. See augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"dep0\");\njulia> nept=DEP([nep.A[1]',nep.A[2]'])\njulia> λ,v,u=rfi(nep,nept)\njulia> compute_resnorm(nep,λ,v) # v is a right eigenvector\n3.0171586304599647e-16\njulia> compute_resnorm(nept,λ,u) # u is a right eigenvector\n7.145081514857076e-17\n\nReference\n\nAlgorithm 4 in  Schreiber, Nonlinear Eigenvalue Problems: Newton-type Methods and Nonlinear Rayleigh Functionals, PhD thesis, TU Berlin, 2008.\n\n\n\n\n\n","category":"function"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"rfi_b","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.rfi_b","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.rfi_b","text":"rfi_b(nep,nept,[λ=0,][errmeasure,][tol=eps()*100,][maxit=100,][v=randn,][u=randn,][logger=0,][linsolvecreator=DefaultLinSolverCreator(),])\n\nThis is an implementation of the two-sided Rayleigh functional Iteration(RFI)-Bordered version to compute an eigentriplet of the problem specified by nep. This method requires the transpose of the NEP, specified in nept. λ, u and v are initial guesses for the eigenvalue, the right eigenvector and the left eigenvector respectively. See augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"dep0\");\njulia> nept=DEP([nep.A[1]',nep.A[2]'])\njulia> λ,v,u=rfi_b(nep,nept,v=ones(ComplexF64,size(nep,1)))\njulia> compute_resnorm(nep,λ,v) # v is a right eigenvector\n5.343670589284583e-15\n\nReference\n\nAlgorithm 5 in  Schreiber, Nonlinear Eigenvalue Problems: Newton-type Methods and Nonlinear Rayleigh Functionals, PhD thesis, TU Berlin, 2008.\n\n\n\n\n\n","category":"function"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"blocknewton","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.blocknewton","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.blocknewton","text":"(S,X)=blocknewton(nep [S,] [X,] [errmeasure,] [tol,] [maxit,] [armijo_factor,] [armijo_max,] [logger])\n\nApplies the block Newton method to nep::AbstractSPMF. The method computes an invariant pair (S,X) using the block Newton approach of Kressner. The variables S,X correspond to starting approximations. The function errmeasure shoule be defined for errmeasure(S,X) and meausures the error in the pair (S,X). See augnewton for other parameters.\n\nExample\n\nThe example shows that compute_MM() becomes zero when a solution has been computed.\n\njulia> nep=nep_gallery(\"dep0\",3);\njulia> (S,X)= blocknewton(nep)\njulia> compute_MM(nep,S,X)\n3×2 Array{Complex{Float64},2}:\n -1.11022e-16+0.0im  1.11022e-16+0.0im\n          0.0+0.0im          0.0+0.0im\n  1.38778e-17+0.0im  2.77556e-17+0.0im\n\nThis example solves the gun problem from the Berlin-Manchester collection\n\njulia> using NonlinearEigenproblems.Gallery\njulia> nep=nep_gallery(\"nlevp_native_gun\");\njulia> II=[1.0 0; 0 1]; S=150^2*II; V=[II;zeros(size(nep,1)-2,2)];\njulia> (Z,X)=blocknewton(nep,S=S,X=V,logger=1,armijo_factor=0.5,maxit=20)\nIteration 1: Error: 6.081316e+03\nIteration 2: Error: 1.701970e-02 Armijo scaling=0.031250\nIteration 3: Error: 1.814887e-02 Armijo scaling=0.250000\n...\nIteration 13: Error: 6.257442e-09\nIteration 14: Error: 2.525942e-15\n\nReferences\n\nD. Kressner A block Newton method for nonlinear eigenvalue problems, Numer. Math., 114 (2) (2009), pp. 355-372\n\n\n\n\n\n","category":"function"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"newtonqr","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.newtonqr","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.newtonqr","text":"λ,v = newtonqr([eltype],nep::NEP;[errmeasure,][tol,][maxit,][λ,][v,][c,][logger])\n\nThis function implements the Newton-QR method as formulated in the reference. The method involves the computation of a rank-revealing QR factorization of M(λ), with the idea that on convergence the the last diagonal element Rnn of the upper-triangular matrix R becomes zero as a result of M(λ) becoming singular. Since the computation of a QR factorization is expensive, it is advisable to use this method for problems of small size or problems with a certain structure that makes the QR computation less expensive. See augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"pep0\")\njulia> λ,v=newtonqr(nep,v=ones(size(nep,1)));\njulia> norm(compute_Mlincomb(nep,λ,v))/norm(v)\n8.440206093655014e-15\n\nReferences\n\nKublanovskaya, V. N., (1970).  On an approach to the solution of the generalized latent value problem for λ-matrices, SIAM J. Numer. Anal. 7, 532–537\nGüttel, S., & Tisseur, F. (2017). The nonlinear eigenvalue problem. Acta Numerica, 26, 1-94. doi:10.1017/S0962492917000034\n\n\n\n\n\n","category":"function"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"implicitdet","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.implicitdet","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.implicitdet","text":"λ,v = implicitdet([eltype],nep::NEP;[errmeasure,][tol,][maxit,][λ,][v,][c,][logger])\n\nThis function implements the Implicit determinant method as formulated Algorithm 4.3 in the reference. The method applies Newton-Raphson to the equation det(M(λ))det(G(λ)) = 0, where G(λ) is a saddle point matrix with M(λ) in the (1,1) block. The (2,1) and (1,2) blocks of G(λ) are set to c^H and c respectively. Note that G(λ) can be non-singular even when M(λ) is singular. See reference for more information. See augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"pep0\")\njulia> λ,v=implicitdet(nep,v=ones(size(nep,1)));\njulia> norm(compute_Mlincomb(nep,λ,v))/norm(v)\n2.566371972986362e-14\n\nReferences\n\nSpence, A., & Poulton, C. (2005). Photonic band structure calculations using nonlinear eigenvalue techniques, J. Comput. Phys., 204 (2005), pp. 65–8\nGüttel, S., & Tisseur, F. (2017). The nonlinear eigenvalue problem. Acta Numerica, 26, 1-94. doi:10.1017/S0962492917000034\n\n\n\n\n\n","category":"function"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"broyden","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.broyden","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.broyden","text":"S,V = broyden([eltype,]nep::NEP[,approxnep];kwargs)\n\nRuns Broydens method (with deflation) for the nonlinear eigenvalue problem defined by nep. An approximate nep can be provided which is used as an initialization of starting matrix/vectors. The optional argument approxnep determines how  to initiate the algorithm. It can be an NEP, the symbol :eye corresponding to starting with an identity matrix, and a Matrix (of size n\times n). Beside most of the standard kwargs as described in augnewton, it supports pmax which is subspace used in deflation, essentially the number of eigenvalues, add_nans::Bool  which determines if NaNs should be added in book keeping. eigmethod which can be :eig, :eigs or :invpow. The :invpow is an implementation of the power method, which is slow but works well e.g. for BigFloat. The kwarg recompute_U determines if the U-matrix should be recomputed in every deflation (which can be more robust). The implementation has two loggers logger and inner_logger. The logger corresponds to outer iterations (deflation) and  inner_logger is the iterates in Broydens method. The kwarg check_error_every and print_error_every   detemine how often errors should be check and how often they should be printed. For real problems with complex conjugate symmetry, you may want to set the kwarg addconj=true in order to reduce computation by automatically adding the complex conjugate vectors.\n\nThe method computes an invariant pair and can therefore find several eigenvalues. The retured value is (S,V) is an invariant pair and the eigenvalues are on the diagonal of S. Eigenpairs can be directly extracted with get_deflated_eigpairs.\n\nExample\n\njulia> nep=nep_gallery(\"dep0\");\njulia> S,V=broyden(nep);\njulia> λ=S[1,1]\n-0.15955391823299253 - 3.874865266487398e-19im\njulia> minimum(svdvals(compute_Mder(nep,λ)))\n1.6293996560844023e-16\njulia> λ=S[2,2]\n-0.5032087003825461 + 1.1969823800738464im\njulia> minimum(svdvals(compute_Mder(nep,λ)))\n1.1073470346550144e-15\njulia> λ=S[3,3]\n1.2699713558173726 + 5.342786996459857e-16im\njulia> minimum(svdvals(compute_Mder(nep,λ)))\n5.905315846211231e-16\njulia> broyden(nep,logger=2,check_error_every=1);  # Prints out a lot more convergence info\n\nIn order to extract eigenpairs you can use the following:\n\njulia> (D,X)=get_deflated_eigpairs(S,V,size(nep,1));\njulia> for i=1:3; @show norm(compute_Mlincomb(nep,D[i],X[:,i])); end\nnorm(compute_Mlincomb(nep, D[i], X[:, i])) = 8.459878994614521e-13\nnorm(compute_Mlincomb(nep, D[i], X[:, i])) = 1.2102336671048442e-13\nnorm(compute_Mlincomb(nep, D[i], X[:, i])) = 2.1012363973403225e-16\n\nReferences\n\nJarlebring, Broyden’s method for nonlinear eigenproblems, SIAM J. Sci. Comput., 41:A989–A1012, 2019, https://arxiv.org/pdf/1802.07322\n\n\n\n\n\n","category":"function"},{"location":"methods/#Projection-methods","page":"NEP-Solvers","title":"Projection methods","text":"","category":"section"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"nlar\njd_betcke\njd_effenberger","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.nlar","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.nlar","text":"function nlar([eltype],nep::ProjectableNEP,[orthmethod=ModifiedGramSchmidt()],[neigs=10],[errmeasure],[tol=eps(real(T))*100],[maxit=100],[0=0],[v=randn(T,size(nep,1))],[logger=0],[linsolvercreator=DefaultLinSolverCreator()],[R=0.01],[eigval_sorter=residual_eigval_sorter],[qrfact_orth=false],[max_subspace=100],[num_restart_ritz_vecs=8],[inner_solver_method=DefaultInnerSolver(),][inner_logger=0])\n\nThe function implements the Nonlinear Arnoldi method, which finds neigs eigenpairs (or throws a NoConvergenceException) by projecting the problem to a subspace that is expanded in the course  of the algorithm. The basis is orthogonalized either by using the QR method if qrfact_orth is true or else by an orthogonalization method orthmethod). This entails solving a smaller projected problem using a method specified by inner_solver_method. The logging of the inner solvers are descided by inner_logger, which works in the same way as logger. (λ,v) is the initial guess for the eigenpair. linsolvercreator specifies how the linear system is created and solved. R is a parameter used by the function specified by eigval_sorter to reject those ritz values that are within a distance R from any of the converged eigenvalues, so that repeated convergence to the same eigenpair can be avoided. max_subspace is the maximum allowable size of the basis befor the algorithm restarts using a basis made of num_restart_ritz_vecs ritz vectors and the eigenvectors that the algorithm has converged to.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"dep0_tridiag\");\njulia> λ,v=nlar(nep,tol=1e-7,neigs=1,maxit=100,v=ones(size(nep,1)));\njulia> norm(compute_Mlincomb(nep,λ[1],v))\n8.00192341259751e-7\n\nReferences\n\nH. Voss, An Arnoldi method for nonlinear eigenvalue problems. BIT. Numer. Math. 44: 387-401, 2004.\n\n\n\n\n\n","category":"function"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.jd_betcke","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.jd_betcke","text":"jd_betcke([eltype]], nep::ProjectableNEP; [neigs=1], [tol=eps(real(T))*100], [maxit=100], [λ=zero(T)], [orthmethod=DGKS],  [errmeasure], [linsolvercreator=DefaultLinSolverCreator()], [v = randn(size(nep,1))], [logger=0], [inner_logger=0], [inner_solver_method=DefaultInnerSolver()], [projtype=:PetrovGalerkin], [target=zero(T)])\n\nThe function computes eigenvalues using Jacobi-Davidson method, which is a projection method. The projected problems are solved using a solver spcified through the type inner_solver_method. The logging of the inner solvers are descided by inner_logger, which works in the same way as logger. For numerical stability the basis is kept orthogonal, and the method for orthogonalization is specified by orthmethod, see the package IterativeSolvers.jl. The function tries to compute neigs number of eigenvalues, and throws a NoConvergenceException if it cannot. The value λ and the vector v are initial guesses for an eigenpair. linsolvercreator is a function which specifies how the linear system is created and solved. The target is the center around which eiganvlues are computed. By default the method uses a Petrov-Galerkin framework, with a trial (left) and test (right) space, hence W^H T(λ) V is the projection considered. By specifying  projtype to be :Galerkin then W=V.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"dep0\",50);\njulia> λ,v=jd_betcke(nep,tol=1e-8,maxit=20);\njulia> norm(compute_Mlincomb(nep,λ[1],v[:,1]))\n1.9570222439914163e-10\n\nReferences\n\nT. Betcke and H. Voss, A Jacobi-Davidson-type projection method for nonlinear eigenvalue problems. Future Gener. Comput. Syst. 20, 3 (2004), pp. 363-372.\nH. Voss, A Jacobi–Davidson method for nonlinear eigenproblems. In: International Conference on Computational Science. Springer, Berlin, Heidelberg, 2004. pp. 34-41.\n\nSee also\n\nC. Effenberger, Robust successive computation of eigenpairs for nonlinear eigenvalue problems. SIAM J. Matrix Anal. Appl. 34, 3 (2013), pp. 1231-1256.\n\n\n\n\n\n","category":"function"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.jd_effenberger","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.jd_effenberger","text":"jd_effenberger([eltype]], nep::ProjectableNEP; [maxit=100], [neigs=1], [inner_solver_method=DefaultInnerSolver()], [orthmethod=DGKS()], [linsolvercreator=DefaultLinSolverCreator()], [tol=eps(real(T))*100], [λ=zero(T)], [v = rand(T,size(nep,1))], [target=zero(T)],  [logger=0], [inner_logger=0])\n\nThe function computes eigenvalues using the Jacobi-Davidson method, which is a projection method. Repreated eigenvalues are avoided by using deflation, as presented in the reference by Effenberger. The projected problems are solved using a solver spcified through the type inner_solver_method. The logging of the inner solvers are descided by inner_logger, which works in the same way as logger. For numerical stability the basis is kept orthogonal, and the method for orthogonalization is specified by orthmethod, see the package IterativeSolvers.jl. The function tries to compute neigs number of eigenvalues, and throws a NoConvergenceException if it cannot. The value λ and the vector v are initial guesses for an eigenpair. linsolvercreator is a function which specifies how the linear system is created and solved. The target is the center around which eiganvalues are computed. For further specifications on the deflation_mode, see the function deflate_eigpair.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> nep=nep_gallery(\"dep0\",100);\njulia> λ,v=jd_effenberger(nep,maxit=30,v=ones(size(nep,1)),λ=0);\njulia> norm(compute_Mlincomb(nep,λ[1],v[:,1]))\n9.577305772525487e-15\n\nReferences\n\nC. Effenberger, Robust successive computation of eigenpairs for nonlinear eigenvalue problems. SIAM J. Matrix Anal. Appl. 34, 3 (2013), pp. 1231-1256.\n\nSee also\n\nT. Betcke and H. Voss, A Jacobi-Davidson-type projection method for nonlinear eigenvalue problems. Future Gener. Comput. Syst. 20, 3 (2004), pp. 363-372.\nH. Voss, A Jacobi–Davidson method for nonlinear eigenproblems. In: International Conference on Computational Science. Springer, Berlin, Heidelberg, 2004. pp. 34-41.\n\n\n\n\n\n","category":"function"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"The following NEP-solvers can also be seen as projection methods:","category":"page"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"iar, tiar, iar_chebyshev,\nnleigs.","category":"page"},{"location":"methods/#Contour-integral-methods","page":"NEP-Solvers","title":"Contour integral methods","text":"","category":"section"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"contour_beyn\ncontour_block_SS","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.contour_beyn","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.contour_beyn","text":"λv,V=contour_beyn([eltype,] nep [,mintegrator];[tol,][logger,][σ,][radius,][linsolvercreator,][N,][neigs,][k])\n\nThe function computes eigenvalues using Beyn's contour integral approach, using an ellipse centered at σ with radii given in radius, or if only one radius is given, the contour is a circle. The numerical quadrature method is specified in mintegrator, which is a type inheriting from MatrixIntegrator, by default MatrixTrapezoidal. For a parallell implementation of the integrator use MatrixTrapezoidalParallel.  The integer k specifies size of the probe subspace. N corresponds to the number of quadrature points. Ellipses are the only supported contours. The linsolvercreator must create a linsolver that can handle (rectangular) matrices as right-hand sides, not only vectors. We integrate in complex arithmetic so eltype must be complex type.\n\nThe kwargs neigs specifies the number of wanted eigvals, and k is the number of columns in the matrix to be integrated (default k=neigs+1). If you give the k parameter and set neigs=typemax(Int) all found eigenvalues will be returned. The kwarg sanity_check decides if sorting and checking (and removal) of eigpairs should be done. If disabled, the method returns k (potentially inaccurate) eigpairs. The parameters errmeasure and tol and rank_drop_tol are used for the sanity check, to extract accurate eigenvalues.\n\nExample\n\njulia> using LinearAlgebra\njulia> nep=nep_gallery(\"dep0\");\njulia> # Look for two eigvals in unit disk\njulia> λv,V=contour_beyn(nep,radius=1.1,neigs=3);\njulia> norm(compute_Mlincomb(nep,λv[1],V[:,1])) # Eigenpair 1\n1.7462847531404259e-15\njulia> norm(compute_Mlincomb(nep,λv[2],V[:,2])) # Eigenpair 2\n7.69695692032292e-15\n\nReferences\n\nWolf-Jürgen Beyn, An integral method for solving nonlinear eigenvalue problems, Linear Algebra and its Applications 436 (2012) 3839–3863\n\n\n\n\n\n","category":"function"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.contour_block_SS","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.contour_block_SS","text":"contour_block_SS([eltype,] nep [,mintegrator];[tol,][logger,][σ,][radius,][linsolvercreator,][N,][neigs,][k,][L])\n\nThis is an implementation of the block_SS contour integral method which is based on the computation of higher order moments. The contour is an ellipse centered at σ with radii given in radius, or if only one radius is given, the contour is a circle. The numerical quadrature method is specified in mintegrator, which is a type inheriting from MatrixIntegrator, by default MatrixTrapezoidal. For a parallell implementation of the integrator use MatrixTrapezoidalParallel.  The integer k specifies size of the probe subspace. N corresponds to the number of quadrature points. The integer L specifies the number of moments. Ellipses are the only supported contours. The linsolvercreator must create a linsolver that can handle (rectangular) matrices as right-hand sides, not only vectors. We integrate in complex arithmetic so eltype must be complex type.\n\nExample\n\njulia> nep=SPMF_NEP([[0 1 ; 1 1.0], [1 0 ; 0 0]], [s->one(s),s->exp(1im*s^2)]);\njulia> λ,V=contour_assu(nep,radius=3,neigs=6)\njulia> @show λ\n6-element Array{Complex{Float64},1}:\n  4.496403249731884e-15 + 2.506628274630998im\n        -2.506628274631 - 2.8727020762175925e-15im\n  3.219972424519104e-16 - 2.5066282746310034im\n     2.5066282746310096 - 1.1438072192922029e-15im\n -2.3814273710772784e-7 - 7.748469160458366e-8im\n   2.381427350935646e-7 + 7.748467479992284e-8im\n\nReferences\n\nAsakura, Sakurai, Tadano, Ikegami, Kimura, A numerical method for nonlinear eigenvalue problems using contour integrals, JSIAM Letters, 2009 Volume 1 Pages 52-55\nVan Beeumen,  Meerbergen, Michiels. Connections between contour integration and rational Krylov methods for eigenvalue problems, 2016, TW673, https://lirias.kuleuven.be/retrieve/415487/\n\n\n\n\n\n","category":"function"},{"location":"methods/#Arnoldi-and-Krylov-based-methods","page":"NEP-Solvers","title":"Arnoldi and Krylov based methods","text":"","category":"section"},{"location":"methods/#IAR","page":"NEP-Solvers","title":"IAR","text":"","category":"section"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"The Infinite ARnoldi method.","category":"page"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"iar","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.iar","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.iar","text":"iar(nep,[maxit=30,][σ=0,][γ=1,][linsolvecreator=DefaultLinSolverCreator(),][tol=eps()*10000,][neigs=6,][errmeasure,][v=rand(size(nep,1),1),][logger=0,][check_error_every=1,][orthmethod=DGKS,][proj_solve=false,][inner_solver_method=DefaultInnerSolver(),][inner_logger=0])\n\nRun the infinite Arnoldi method on the nonlinear eigenvalue problem stored in nep.\n\nThe target σ is the center around which eiganvalues are computed. The value γ corresponds to scaling and specifying a shift and scaling is effectively the same as the transformation λ=γs+σ where s is now the eigenvalue parameter. If you want eigenvalues in a disk centered, select σ as the center of the disk and γ as the radius. The vector v is the starting vector for constructing the Krylov space. The orthogonalization method, used in contructing the orthogonal basis of the Krylov space, is specified by orthmethod, see the package IterativeSolvers.jl. The iteration is continued until neigs Ritz pairs have converged. This function throws a NoConvergenceException if the wanted eigenpairs are not computed after maxit iterations. However, if neigs is set to Inf the iteration is continued until maxit iterations without an error being thrown. The parameter proj_solve determines if the Ritz pairs are extracted using the Hessenberg matrix (false), or as the solution to a projected problem (true). If true, the method is descided by inner_solver_method, and the logging of the inner solvers are descided by inner_logger, which works in the same way as logger.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> using NonlinearEigenproblems, LinearAlgebra\njulia> nep=nep_gallery(\"dep0\",100);\njulia> v0=ones(size(nep,1));\njulia> λ,v=iar(nep;v=v0,tol=1e-5,neigs=3);\njulia> norm(compute_Mlincomb!(nep,λ[1],v[:,1])) # Is it an eigenvalue?\njulia> λ    # print the computed eigenvalues\n3-element Array{Complex{Float64},1}:\n -0.15606211475666945 - 0.12273439802763578im\n -0.15606211475666862 + 0.12273439802763489im\n  0.23169243065648365 - 9.464790582509696e-17im\n\nReferences\n\nAlgorithm 2 in Jarlebring, Michiels Meerbergen, A linear eigenvalue algorithm for the nonlinear eigenvalue problem, Numer. Math, 2012\n\n\n\n\n\n","category":"function"},{"location":"methods/#IAR-Chebyshev","page":"NEP-Solvers","title":"IAR Chebyshev","text":"","category":"section"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"A Chebyshev version of the IAR method.","category":"page"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"iar_chebyshev","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.iar_chebyshev","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.iar_chebyshev","text":"iar_chebyshev(nep,[maxit=30,][σ=0,][γ=1,][linsolvecreator=DefaultLinSolverCreator(),][tolerance=eps()*10000,][neigs=6,][errmeasure,][v=rand(size(nep,1),1),][logger=0,][check_error_every=1,][orthmethod=DGKS][a=-1,][b=1,][compute_y0_method=ComputeY0ChebAuto])\n\nRun the infinite Arnoldi method (Chebyshev version) on the nonlinear eigenvalue problem stored in nep.\n\nThe target σ is the center around which eiganvalues are computed. A Ritz pair λ and v is flagged a as converged (to an eigenpair) if errmeasure is less than tol. The vector v is the starting vector for constructing the Krylov space. The orthogonalization method, used in contructing the orthogonal basis of the Krylov space, is specified by orthmethod, see the package IterativeSolvers.jl. The iteration is continued until neigs Ritz pairs converge. This function throws a NoConvergenceException if the wanted eigenpairs are not computed after maxit iterations. However, if neigs is set to Inf the iteration is continued until maxit iterations without an error being thrown. The kwarg compute_y0_method specifying how the next vector of the Krylov space (in Chebyshev format) can be computed. See compute_y0_cheb in the module NEPSolver with the command ?NEPSolver.compute_y0_cheb.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> using NonlinearEigenproblems, LinearAlgebra\njulia> nep=nep_gallery(\"dep0\",100);\njulia> v0=ones(size(nep,1));\njulia> λ,v=iar_chebyshev(nep;v=v0,tol=1e-5,neigs=3);\njulia> norm(compute_Mlincomb!(nep,λ[1],v[:,1])) # Is it an eigenvalue?\njulia> λ    # print the computed eigenvalues\n3-element Array{Complex{Float64},1}:\njulia> norm(compute_Mlincomb(nep,λ[1],v[:,1]))\n 0.050462487848960284 - 1.4289626573515395e-18im\n -0.07708779190301127 + 7.703053374113074e-18im\n   0.1503856540695659 - 1.662582577182149e-17im\n\nReferences\n\nAlgorithm 2 in Jarlebring, Michiels Meerbergen, A linear eigenvalue algorithm for the nonlinear eigenvalue problem, Numer. Math, 2012\n\n\n\n\n\n","category":"function"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"For the iar_chebyshev the following compute_y0_cheb method is needed, in order to avoid explicit conversions between the Chebyshev basis and the monimial basis.","category":"page"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"NEPSolver.compute_y0_cheb","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.compute_y0_cheb","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.compute_y0_cheb","text":"y0 = compute_y0_cheb([eltype],nep::NEPTypes.DEP,::Type{ComputeY0ChebPEP},X,Y,M0inv,precomp::AbstractPrecomputeData)\n\nComputes the vector y0 used in iar_chebyshev given by\n\n y_0 = sum_i=1^N T_i-1(γ) x_i - sum_j=1^m A_j left( sum_i=1^N+1 T_i-1(-ρ tau_j+γ) y_i right )\n\nwhere T(c) is the vector containing T_i(c) as coefficients, where T_i is the i-th Chebyshev polynomial of the first kind.\n\n\n\n\n\ny0 = compute_y0_cheb([eltype],nep::NEPTypes.PEP,::Type{ComputeY0ChebPEP},X,Y,M0inv,precomp::AbstractPrecomputeData)\n\nComputes the vector y0 used in iar_chebyshev given by\n\n y_0 = sum_j=0^d-1 A_j+1 x D^j T(c) - y T(c)\n\nwhere T(c) is the vector containing T_i(c) as coefficients, where T_i is the i-th Chebyshev polynomial of the first kind and D is the derivation matrix in Chebyshev basis.\n\n\n\n\n\ny0 = compute_y0_cheb([eltype],nep::NEPTypes.SPMF_NEP,::Type{ComputeY0ChebPEP},X,Y,M0inv,precomp::AbstractPrecomputeData)\n\nComputes the vector y0 used in iar_chebyshev given by\n\n y_0= sum_j=0^m M^(j)(mu) X b_j left( D_N right) T_N(c) - Y T_N(c)\n\nwhere T(c) is the vector containing T_i(c) as coefficients, where T_i is the i-th Chebyshev polynomial of the first kind and b_j(lambda)=(f_j(0)-f_j(lambda))lambda=flambda0 are divided differences.\n\n\n\n\n\ny0 = compute_y0_cheb([eltype],nep::NEPTypes.NEP,::Type{ComputeY0ChebNEP},X,Y,M0inv,precomp::AbstractPrecomputeData)\n\nComputes the vector y0 used in iar_chebyshev defined as\n\n y_0 =left( sum_i=0^N-1 B left( fracdd theta right) hat T_i(theta) x_i right)(0) - sum_i=0^N T_i(c) y_i\n\nwhere T_i is the i-th Chebyshev polynomial of the first kind, $ \\ hat T_i$ is the i-th Chebyshev polynomial of the first kind for the interval [a,b]. For a generic nep, this quantity is computed by converting polynomials in monomial basis. This procedure may be numerical unstable if many iterations are required. If for the specific nep a closed formula is available, we suggest to overload this function.\n\n\n\n\n\n","category":"function"},{"location":"methods/#TIAR","page":"NEP-Solvers","title":"TIAR","text":"","category":"section"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"The Tensor Infinite ARnoldi method.","category":"page"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"tiar","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.tiar","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.tiar","text":"tiar(nep,[maxit=30,][σ=0,][γ=1,][linsolvecreator=DefaultLinSolverCreator(),][tolerance=eps()*10000,][neigs=6,][errmeasure,][v=rand(size(nep,1),1),][logger=0,][check_error_every=1,][orthmethod=DGKS(),][proj_solve=false,][inner_solver_method=DefaultInnerSolver(),][inner_logger=0])\n\nRun the tensor infinite Arnoldi method on the nonlinear eigenvalue problem stored in nep. This is equivalent to iar, but handles orthogonalization with a tensor representation.\n\nThe target σ is the center around which eiganvalues are computed. The value γ corresponds to scaling and specifying a shift and scaling is effectively the same as the transformation λ=γs+σ where s is now the eigenvalue parameter. If you want eigenvalues in a disk centered, select σ as the center of the disk and γ as the radius. The vector v is the starting vector for constructing the Krylov space. The orthogonalization method, used in contructing the orthogonal basis of the Krylov space, is specified by orthmethod, see the package IterativeSolvers.jl. The iteration is continued until neigs Ritz pairs have converged. This function throws a NoConvergenceException if the wanted eigenpairs are not computed after maxit iterations. However, if neigs is set to Inf the iteration is continued until maxit iterations without an error being thrown. The parameter proj_solve determines if the Ritz paris are extracted using the Hessenberg matrix (false), or as the solution to a projected problem (true). If true, the method is descided by inner_solver_method, and the logging of the inner solvers are descided by inner_logger, which works in the same way as logger.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> using NonlinearEigenproblems, LinearAlgebra\njulia> nep=nep_gallery(\"dep0\",100);\njulia> v0=ones(size(nep,1));\njulia> λ,v=tiar(nep;v=v0,tol=1e-5,neigs=3);\njulia> norm(compute_Mlincomb!(nep,λ[1],v[:,1])) # Is it an eigenvalue?\njulia> λ    # print the computed eigenvalues\n3-element Array{Complex{Float64},1}:\n 0.050462487743188206 - 3.4059600538119376e-18im\n -0.07708769561361105 + 8.611006691570004e-19im\n   0.1503916927814904 + 9.388210527944734e-18im\n\nReferences\n\nAlgorithm 2 in Jarlebring, Mele, Runborg, The Waveguide Eigenvalue Problem and the Tensor Infinite Arnoldi Method, SIAM J. Scient. computing, 39 (3), A1062-A1088, 2017\n\n\n\n\n\n","category":"function"},{"location":"methods/#Infinite-Lanczos-based-methods","page":"NEP-Solvers","title":"Infinite Lanczos based methods","text":"","category":"section"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"The Infinite Bi-Lanczos method.","category":"page"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"infbilanczos","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.infbilanczos","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.infbilanczos","text":"λv,V,U=infbilanczos([eltype],nep, nept,[linsolvecreator,][linsolvertcreator,][v,][u,][σ,][γ,][tol,][neigs,][errmeasure,][logger,][maxit,][check_error_every])\n\nExecutes the Infinite Bi-Lanczos method on the problem defined by nep::NEP and nept::NEP. nep:NEP is the original nonlinear eigenvalue problem and nept::NEP is its (hermitian) transpose: M(λ^*)^H.  v and u are starting vectors, σ is the shift and γ the scaling. The iteration is continued until neigs Ritz pairs have converged. This function throws a NoConvergenceException if the wanted eigenpairs are not computed after maxit iterations. However, if neigs is set to Inf the iteration is continued until maxit iterations without an error being thrown. See augnewton for other parameters.\n\nExample:\n\njulia> nep=nep_gallery(\"dep0\");\njulia> A=get_Av(nep); fv=get_fv(nep);\njulia> At=[copy(A[1]'),copy(A[2]'),copy(A[3]')]\njulia> nept=SPMF_NEP(At,fv); # Create the transposed NEP\njulia> λv,V=infbilanczos(nep,nept,neigs=3,v=ones(size(nep,1)))\njulia> norm(compute_Mlincomb(nep,λv[1],V[:,1]))\n9.907299130783851e-15\n\nReferences:\n\nThe infinite bi-Lanczos method for nonlinear eigenvalue problems, S. W. Gaaf and E. Jarlebring, SIAM J. Sci. Comput. 39:S898-S919, 2017, preprint\n\n\n\n\n\n","category":"function"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"The Infinite Lanczos method, for symmetric NEPs","category":"page"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"ilan","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.ilan","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.ilan","text":"ilan(nep,[maxit=30,][σ=0,][γ=1,][linsolvecreator=DefaultLinSolverCreator(),][tolerance=eps()*10000,][neigs=6,][errmeasure,][v=rand(size(nep,1),1),][logger=0,][check_error_every=30,][orthmethod=DGKS])\n\nRun the infinite Lanczos method on the symmetric nonlinear eigenvalue problem stored in nep. The current implementation supports only neps in SPMF format.\n\nThe target σ is the center around which eiganvalues are computed. The kwarg errmeasure is a function handle which can be used to specify how the error is measured to be used in termination (default is absolute residual norm). A Ritz pair λ and v is flagged a as converged (to an eigenpair) if errmeasure is less than tol. The vector v is the starting vector for constructing the Krylov space. The orthogonalization method, used in contructing the orthogonal basis of the Krylov space, is specified by orthmethod, see the package IterativeSolvers.jl. The iteration is continued until neigs Ritz pairs have converged. This function throws a NoConvergenceException if the wanted eigenpairs are not computed after maxit iterations. However, if neigs is set to Inf the iteration is continued until maxit iterations without an error being thrown.\n\nSee augnewton for other parameters.\n\nExample\n\njulia> using NonlinearEigenproblems, LinearAlgebra\njulia> nep=nep_gallery(\"dep_symm_double\",10);\njulia> v0=ones(size(nep,1));\njulia> λ,v=ilan(nep;v=v0,tol=1e-5,neigs=3);\njulia> norm(compute_Mlincomb!(nep,λ[1],v[:,1])) # Is it an eigenvalue?\njulia> λ    # print the computed eigenvalues\n3-element Array{Complex{Float64},1}:\n  0.03409997385842267 - 1.425205509434608e-19im\n -0.03100798730589012 + 5.66201058098364e-20im\n  -0.0367653644764646 - 1.607494907684445e-19im\n\nReferences\n\nAlgorithm 2 in Mele, The infinite Lanczos method for symmetric nonlinear eigenvalue problems, https://arxiv.org/abs/1812.07557, 2018\n\n\n\n\n\n","category":"function"},{"location":"methods/#NLEIGS","page":"NEP-Solvers","title":"NLEIGS","text":"","category":"section"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"nleigs","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.nleigs","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.nleigs","text":"nleigs(nep::NEP, Σ::AbstractVector{Complex{T}})\n\nFind a few eigenvalues and eigenvectors of a nonlinear eigenvalue problem, using the nleigs algorithm.\n\nArguments\n\nnep: An instance of a nonlinear eigenvalue problem.\nΣ: A vector containing the points of a polygonal target set in the complex plane.\nΞ: A vector containing a discretization of the singularity set.\nlogger: Level of display (0, 1, 2).\nmaxdgr: Max degree of approximation.\nminit: Min number of iterations after linearization is converged.\nmaxit: Max number of total iterations.\ntol: Tolerance for residual.\ntollin: Tolerance for convergence of linearization.\nv: Starting vector.\nerrmeasure: Function for error measure (residual norm). Called with arguments (λ,v).\nisfunm : Whether to use matrix functions.\nstatic: Whether to use static version of NLEIGS.\nleja: Use of Leja-Bagby points (0 = no, 1 = only in expansion phase, 2 = always).\nnodes: Prefixed interpolation nodes (only when leja is 0 or 1).\nreusefact: Reuse of matrix factorizations (0 = no, 1 = only after converged linearization, 2 = always).\nblksize: Block size for pre-allocation.\nreturn_details: Whether to return solution details (see NleigsSolutionDetails).\ncheck_error_every: Check for convergence / termination every this number of iterations.\n\nSee augnewton for other parameters.\n\nReturn values\n\nλ: Vector of eigenvalues of the nonlinear eigenvalue problem NLEP inside the target set Σ.\nX: Corresponding matrix of eigenvectors.\nres: Corresponding residuals.\ndetails: Solution details, if requested (see NleigsSolutionDetails).\n\nExample\n\njulia> nep=nep_gallery(\"dep0\");\njulia> unit_square = float([1+1im, 1-1im, -1-1im,-1+1im])\njulia> (λ,v)=nleigs(nep,unit_square);\njulia> norm(compute_Mlincomb(nep,λ[1],v[:,1]))\n5.028313023882492e-14\njulia> norm(compute_Mlincomb(nep,λ[2],v[:,2]))\n1.1937025845487509e-13\n\nReferences\n\nS. Guettel, R. Van Beeumen, K. Meerbergen, and W. Michiels. NLEIGS: A class of fully rational Krylov methods for nonlinear eigenvalue problems. SIAM J. Sci. Comput., 36(6), A2842-A2864, 2014.\nNLEIGS Matlab toolbox (GPL License)\nNLEIGS Matlab toolbox (MIT License)\n\n\n\n\n\n","category":"function"},{"location":"methods/#AAA-EIGS","page":"NEP-Solvers","title":"AAA-EIGS","text":"","category":"section"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"AAAeigs","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.AAAeigs","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.AAAeigs","text":"AAAeigs([eltype,] nep::NEP, Z::AbstractArray{T}; [logger=0,][mmax=100,][neigs=6,][maxit=min(max(10*neigs,30),100),][shifts=Vector{T}(),][linsolvercreator=FactorizeLinSolverCreator(max_factorizations=min(length(unique(shifts)),10)),][tol=eps(real(T))*1e6,][tol_appr=eps(real(T))*1e3,][v0=Vector{T}(),][errmeasure=ResidualErrmeasure(nep),][weighted=false,][cleanup_appr=true,][tol_cln=min(eps(real(T)),tol_appr),][return_details=false,][check_error_every=10,][inner_logger=0])\n\nFind a few eigenvalues and eigenvectors of a nonlinear eigenvalue problem, using the AAAeigs algorithm.\n\nArguments\n\nnep: An instance of a nonlinear eigenvalue problem has to be of type AbstractSPMF\nZ: An array containing the sample domain of the nep, given as a series of points.\nmmax: Max degree of AAA-approximation.\nneigs: Number of eigenvalues to find.\nmaxit: Max number of total iterations.\nshifts: L vector of shifts used during the Krylov routine (empty -> shift=0)\ntol: Tolerance for residual.\ntol_appr: Tolerance for convergence of AAA-approximation.\nv0: Starting vector.\nweighted: Wether to use Weighted or Set-Valued AAA.\ncleanup_appr: Whether to detect spurious poles in AAA.\ntol_cln: Tolerance for cleanup of spurious poles.\nreturn_details: Whether to return solution details (see AAASolutionDetails).\ncheck_error_every: Check for convergence / termination every this number of iterations.\ninner_logger: Works in the same way as logger but for the AAA rational approximation (see svAAA)\n\nSee augnewton for other parameters.\n\nReturn values\n\nΛ: Vector of eigenvalues of the nonlinear eigenvalue problem inside the sample set Z.\nX: Corresponding matrix of eigenvectors.\nres: Corresponding residuals.\ndetails: Solution details, if requested (see AAASolutionDetails).\n\nExample\n\njulia> Random.seed!(2022);\njulia> nep=nep_gallery(\"nlevp_native_gun\");\njulia> m=250^2; r=300^2-200^2;\njulia> Z=m-r.+2*r*rand(1000)+im*(rand(1000)*r.+sqrt(1e-13));\njulia> Z=Z[(~).(imag.(Z).>sin.(acos.((real.(Z).-m)/r))*r.-sqrt(1e-13))];\njulia> Z=[transpose([LinRange(m-r+1e-2,m+r-1e-2,250)' m-r.+2*r*(exp.(im*LinRange(0,pi,250)')/2 .+.5)]); Z[1:500]];\njulia> shifts=r*[2/3,(1+im)/3,0,(-1+im)/3,-2/3].+m;\njulia> λ,X=AAAeigs(nep,Z,shifts=shifts);\njulia> [norm(compute_Mlincomb(nep,λ[i],X[:,i]))/norm(X[:,i]) for i=1:length(λ)]\n6-element Vector{Float64}:\n 5.282105614825289e-12\n 1.675900913610527e-11\n 4.971723316733914e-11\n 9.437128735632508e-11\n 1.2277986011104446e-10\n 1.4546362158344052e-10\n\nReferences\n\nP. Lietaert, J. Pérez, B. Vandereycken, and K. Meerbergen. Automatic rational approximation and linearization of nonlinear eigenvalue problems. IMA journal of numerical analysis, 2018.\nR. Van Beeumen, K. Meerbergen, and W. Michiels. Compact rational Krylov methods for nonlinear eigenvalue problems. SIAM Journal on Matrix Analysis and Applications, 36(2):820-838, 2015.\n\n\n\n\n\n","category":"function"},{"location":"methods/#Class-specific-methods","page":"NEP-Solvers","title":"Class specific methods","text":"","category":"section"},{"location":"methods/#Companion-linearizations","page":"NEP-Solvers","title":"Companion linearizations","text":"","category":"section"},{"location":"methods/","page":"NEP-Solvers","title":"NEP-Solvers","text":"companion\npolyeig","category":"page"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.companion","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.companion","text":"E,A = companion(nep::PEP);\n\nLinearizes a  polynomial eigenvalue problem (PEP) a to the companion form, as in the paper by Mehrmann and Voss. More precisely, for a k-th degree PEP with n-by-n coefficient matrices, this returns matrices E and A, both kn-by-kn, corresponding to the linearized problem\n\nAx = λEx\n\nExample\n\njulia> pep = nep_gallery(\"pep0\");\njulia> E,A = companion(pep);\njulia> λ, V = eigen(A,E);\njulia> minimum(svd(compute_Mder(pep,λ[1])).S)\n2.4845217786736996e-12\n\nReferences\n\nV. Mehrmann and H. Voss, Non-linear eigenvalue problems, a challenge for modern eigenvalue methods, GAMM‐Mitteilungen (2004)\n\n\n\n\n\n","category":"function"},{"location":"methods/#NonlinearEigenproblems.NEPSolver.polyeig","page":"NEP-Solvers","title":"NonlinearEigenproblems.NEPSolver.polyeig","text":"λ,v = polyeig([eltype],nep::PEP,[eigsolvertype,])\n\nLinearizes a  polynomial eigenvalue problem (PEP) a to the companion form and solves the corresponding linear eigenvalue problem; see companion. The eigsolvertype is optinal can be used to specify how the linear problem is solved; see eig_solve, and EigSolver.\n\nExample\n\njulia> pep = nep_gallery(\"pep0\");\njulia> λ,V = polyeig(pep);\njulia> minimum(svd(compute_Mder(pep,λ[1])).S)\n1.2050763381899922e-14\njulia> norm(compute_Mlincomb(pep,λ[2],vec(V[:,2])))\n1.0245470569036458e-12\n\n\n\n\n\nλ,v = polyeig([eltype],nep::ChebPEP)\n\nComputes a companion linearization for the NEP represented in a Chebyshev basis, and returns eigenpairs.\n\nExample\n\njulia> using LinearAlgebra\njulia> nep=nep_gallery(\"dep0\");\njulia> chebpep=ChebPEP(nep,9,-3,1,cosine_formula_cutoff=5);\njulia> (λv,V)=polyeig(chebpep);\njulia> ii=argmin(abs.(λv));\njulia> λ=λv[ii];\njulia> v=V[:,ii];\njulia> norm(compute_Mlincomb(chebpep,λ,v))\n1.3543968603949142e-14\njulia> # Actually, it's not a bad approx to the original NEP either\njulia> norm(compute_Mlincomb(nep,λ,v))\n4.326355966047557e-6\n\nSee also ChebPEP.\n\nReferences:\n\nAmiraslani, A., Corless, R. M. & Lancaster, P. \"Linearization of matrix polynomials expressed in poly-nomial bases\" IMA J. Numer. Anal.,29 (2009): 141–157.\nEffenberger and Kressner. \"Chebyshev interpolation for nonlinear eigenvalue problems.\" BIT Numerical Mathematics 52.4 (2012): 933-951.\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Transformations","page":"Transformations","title":"Transformations","text":"","category":"section"},{"location":"transformations/","page":"Transformations","title":"Transformations","text":"Due to the object oriented way of handle NEPs in NEP-PACK, a NEP-object can be transformed to another NEP-object in a number of ways. There is support for:","category":"page"},{"location":"transformations/","page":"Transformations","title":"Transformations","text":"variable transformations,\nexpansions, and\ndeflation.","category":"page"},{"location":"transformations/#Change-of-variables","page":"Transformations","title":"Change of variables","text":"","category":"section"},{"location":"transformations/","page":"Transformations","title":"Transformations","text":"shift_and_scale","category":"page"},{"location":"transformations/#NonlinearEigenproblems.NEPTransformations.shift_and_scale","page":"Transformations","title":"NonlinearEigenproblems.NEPTransformations.shift_and_scale","text":"shift_and_scale(orgnep::NEP;shift=0,scale=1)\n\nTransforms the orgnep by defining a new NEP from the relation T(λ)=M(scale * λ+shift) where M is the orgnep. This function tries  to preserve the NEP type, e.g., a shiftandscale operation on an SPMF-object, return an SPMF object. If it cannot preserve the type, it will return a nep of the struct ShiftScaledNEP.\n\nExample\n\njulia> nep0=nep_gallery(\"pep0\")\njulia> σ=3; α=10;\njulia> nep1=shift_and_scale(nep0,shift=σ,scale=α)\njulia> opnorm(compute_Mder(nep0,α*(4+4im)+σ)-compute_Mder(nep1,4+4im))\n8.875435870738592e-12\n\n\n\n\n\n","category":"function"},{"location":"transformations/","page":"Transformations","title":"Transformations","text":"mobius_transform","category":"page"},{"location":"transformations/#NonlinearEigenproblems.NEPTransformations.mobius_transform","page":"Transformations","title":"NonlinearEigenproblems.NEPTransformations.mobius_transform","text":"mobius_transform(orgnep::NEP,[,a=1][,b=0][,c=0][,d=1])\n\nTransforms a nep (orgnep) M(λ)v to a new nep T(λ)=M((aλ+b)(cλ+d)). This function tries to preserve the type such that T and M are of the same NEP-type (see shift_and_scale()). If it cannot be preserved it will return a MobiusTransformedNEP. It is in general advised to try to preserve the type, and the use of MobiusTransformedNEP can considerably slow down NEP-access.\n\nExample\n\njulia> nep0=nep_gallery(\"pep0\")\njulia> a=1; b=3; c=4; d=5;\njulia> nep1=mobius_transform(nep0,a=a,b=b,c=c,d=d);\njulia> s=3;\njulia> opnorm(compute_Mder(nep0,(a*s+b)/(c*s+d))-compute_Mder(nep1,s))\n0.0\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Expansions","page":"Transformations","title":"Expansions","text":"","category":"section"},{"location":"transformations/","page":"Transformations","title":"Transformations","text":"taylor_expansion_pep","category":"page"},{"location":"transformations/#NonlinearEigenproblems.NEPTransformations.taylor_expansion_pep","page":"Transformations","title":"NonlinearEigenproblems.NEPTransformations.taylor_expansion_pep","text":"taylor_expansion_pep(orgnep::NEP[,d=2])\n\nCompute the truncated (with d terms) Taylor series of the NEP. The output is a PEP.\n\n\n\n\n\n","category":"function"},{"location":"transformations/","page":"Transformations","title":"Transformations","text":"interpolate","category":"page"},{"location":"transformations/#NonlinearEigenproblems.NEPTypes.interpolate","page":"Transformations","title":"NonlinearEigenproblems.NEPTypes.interpolate","text":"interpolate([T=ComplexF64,] nep::NEP, intpoints::Array)\n\nInterpolates a NEP in the points intpoints and returns a PEP, i.e., a polynomial eigenvalue problem in a monomial basis. See ChebPEP for Chebyshev interpolation. The optional argument T is the type in which the matrices of the PEP should be defined.\n\nSee also ChebPEP.\n\n\n\n\n\n","category":"function"},{"location":"transformations/#Deflation","page":"Transformations","title":"Deflation","text":"","category":"section"},{"location":"transformations/","page":"Transformations","title":"Transformations","text":"A NEP can be transformed to another NEP by extending the problem in a way that it essentially removes eigenvalues. This type of deflation is described on the manual page for deflation.","category":"page"},{"location":"linsolvers/#Linear-solvers","page":"Linear solvers","title":"Linear solvers","text":"","category":"section"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"Most NEP-solvers require","category":"page"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"the solution of linear system of equations, or\nthe solution of a standard eigenvalue problem.","category":"page"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"The user can specify which linear solver or eigenvalue solver he/she wants to use. It is also possible to use external or user-defined solvers.","category":"page"},{"location":"linsolvers/#Linear-system-of-equations","page":"Linear solvers","title":"Linear system of equations","text":"","category":"section"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"As a user, you can provide a creator object to many NEP-solvers via the keyword argument linsolvercreator. The creator object corresponds to one (or several) linear system solvers. By default, DefaultLinSolverCreator is used which tries to determine an appropriate linear solver based on the NEP-type. In the next section, we list the default linear solvers.","category":"page"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"If you wish to define your own linear solver, you need to define your own type inheriting from LinSolver as well as a LinSolverCreator. See the documenation for LinSolver and the tutorial on linear solvers.","category":"page"},{"location":"linsolvers/#LinSolver-objects-and-creators","page":"Linear solvers","title":"LinSolver-objects and creators","text":"","category":"section"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"FactorizeLinSolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.FactorizeLinSolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.FactorizeLinSolver","text":"struct FactorizeLinSolver <: LinSolver\n\nThis represents the linear solver associated with julia factorize(). See LinSolver and FactorizeLinSolverCreator for examples.\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"FactorizeLinSolverCreator","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.FactorizeLinSolverCreator","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.FactorizeLinSolverCreator","text":"FactorizeLinSolverCreator(;umfpack_refinements,max_factorizations,nep,precomp_values)\n\nFactorizeLinSolverCreator-objects can instantiate FactorizeLinSolver objects via the create_linsolver function.\n\nThe FactorizeLinSolver is based on factorize-calls. The time point of the call to factorize can be controlled by parameters to FactorizeLinSolverCreator:\n\nBy default, the factorize call is carried out by the instantiation of the FactorizeLinSolver, i.e., when the NEP-solver calls create_linsolver.\nYou can also precompute the factorization, at the time point when you instantiate FactorizeLinSolverCreator. If you set precomp_values::Vector{Number} to a non-empty vector, and set nep kwarg, the factorization (of all λ-values in the precomp_values) will be computed  when the FactorizeLinSolverCreator is instantiated. If the NEP-solver calls a create_linsolver with a λ-value from that vector, the factorization will be used (otherwise it will be computed).\n\nFurther recycling is possible. If the variable max_factorizations is set to a positive value, the object will store that many factorizations for possible reuse. Every lin_solve-call then computes a factorization, unless a lin_solve-call for that λ has been computed earlier. This procedure can at most store max_factorization (which can be set Inf).\n\nSee also: FactorizeLinSolver, create_linsolver\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"BackslashLinSolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.BackslashLinSolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.BackslashLinSolver","text":"struct BackslashLinSolver <: LinSolver\n\nThis represents a linear solver corresponding to the backslash operator (no pre-factorization).\n\nSee also: LinSolver and BackslashLinSolverCreator\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"BackslashLinSolverCreator","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.BackslashLinSolverCreator","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.BackslashLinSolverCreator","text":"struct BackslashLinSolverCreator <: LinSolverCreator\n\nCreator to for the BackslashLinSolver, i.e., usage of backslash to make linear solves. Specify objects of this type if you want the solver to use backslash.\n\nSee also: BackslashLinSolver, create_linsolver\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"GMRESLinSolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.GMRESLinSolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.GMRESLinSolver","text":"struct GMRESLinSolver <: LinSolver\n\nThis represents a solver done with the julia GMRES implementation.\n\nSee also: LinSolver, GMRESLinSolverCreator\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"GMRESLinSolverCreator","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.GMRESLinSolverCreator","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.GMRESLinSolverCreator","text":"GMRESLinSolverCreator(;kwargs...)\n\nThis is the creator for the GMRES-method. Instantiate this object if you want to use GMRES as your linear system solver. The kwargs are stored and used as keyword arguments in the call to gmres. See list of keyword in the IterativeSolvers.jl manual.\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"DefaultLinSolverCreator","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.DefaultLinSolverCreator","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.DefaultLinSolverCreator","text":"DefaultLinSolverCreator\n\nThis is the default linear solver if no other is specified (for most methods). It is a FactorizeLinSolverCreator.\n\nSee also: LinSolver, create_linsolver, lin_solve, FactorizeLinSolverCreator, FactorizeLinSolver\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"DeflatedNEPLinSolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.DeflatedNEPLinSolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.DeflatedNEPLinSolver","text":"struct DeflatedNEPLinSolver <: LinSolver\n\nThis represents a solver for a deflated NEP.\n\nSee also: LinSolver, DeflatedNEPLinSolverCreator, deflate_eigpair\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"DeflatedNEPLinSolverCreator","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.DeflatedNEPLinSolverCreator","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.DeflatedNEPLinSolverCreator","text":"DeflatedNEPLinSolverCreator(orglinsolvercreator)\n\nThis is the creator for case of a deflated NEP. The argument orglinsolvercreator is the LinSolverCreator for the original NEP. The extended linear system\n\nM U X^T 0v1 v2 = b1 b2\n\nis solved with a Schur complement strategy, recycling the linear solver of the original NEP. Hence, pre-computed entities such as, e.g., factorizations and preconditioners can be reused.\n\nNB1: The implementation assumes minimality index = 1. NB2: The Schur complement is explicitly formed. Hence it is only efficient for a few deflated eigenvalues.\n\nSee also: DeflatedNEPLinSolver, create_linsolver, deflate_eigpair\n\nReferences\n\nC. Effenberger, Robust successive computation of eigenpairs for nonlinear eigenvalue problems. SIAM J. Matrix Anal. Appl. 34, 3 (2013), pp. 1231-1256.\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/#Advanced-usage","page":"Linear solvers","title":"Advanced usage","text":"","category":"section"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"LinSolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.LinSolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.LinSolver","text":"abstract type LinSolver\n\nStructs inheriting from this type are able to solve linear systems associated with a NEP, for a specific λ-value. The most common are direct solvers such as FactorizeLinSolver, BackslashLinSolver and iterative solvers such as GMRESLinSolver.\n\nThe LinSolver objects are usually created by the NEP-algorithms through creator functions, which are passed as parameters.\n\nExample\n\nThe most common usecase is that you want to pass a linsolvercreator-function as a parameter to the NEP-algorithm. This example shows how you can use solvers based on backslash or factorize(). In the example, BackslashLinSolver does not exploit that the system matrix remains the same throughout the algorithm and is therefore slower.\n\njulia> nep=nep_gallery(\"qdep0\");\njulia> using BenchmarkTools\njulia> v0=ones(size(nep,1));\njulia> @btime λ,v=quasinewton(nep,λ=-1,v=v0, linsolvercreator=DefaultLinSolverCreator());\n  181.017 ms (3779 allocations: 58.61 MiB)\njulia> @btime λ,v=quasinewton(nep,λ=-1,v=v0, linsolvercreator=BackslashLinSolverCreator());\n  2.040 s (4510 allocations: 553.24 MiB)\n\nExample\n\nThe LinSolvers are constructed for extendability. This example creates our own LinSolver which uses an explicit formula for the inverse if the NEP has dimension 2x2.\n\nCreate the types and a creator.\n\njulia> using LinearAlgebra\njulia> struct MyLinSolver <: LinSolver\n   M::Matrix{ComplexF64}\nend\njulia> function my_linsolvercreator(nep,λ)\n   M=compute_Mder(nep,λ);\n   return MyLinSolver(M);\nend\n\nExplicit import lin_solve to show how to solve a linear system.\n\njulia> import NonlinearEigenproblems.LinSolvers.lin_solve;\njulia> function lin_solve(solver::MyLinSolver,b::AbstractVecOrMat;tol=0)\n   M=solver.M;\n   invM=(1/(det(M)))*[M[2,2] -M[1,2];-M[2,1] M[1,1]]\n   return invM*b\nend\njulia> nep=SPMF_NEP([[1.0 3.0; 4.0 5.0], [2.0 1.0; -1 2.0]], [S->S^2,S->exp(S)])\njulia> λ,v=quasinewton(nep,λ=-1,v=[1;1],linsolvercreator=my_linsolvercreator);\n\nSee also: lin_solve, FactorizeLinSolver, FactorizeLinSolver, DefaultLinSolverCreator, BackslashLinSolver, BackslashLinSolverCreator, GMRESLinSolver, GMRESLinSolverCreator\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"lin_solve","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.lin_solve","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.lin_solve","text":"lin_solve(solver::LinSolver, b::AbstractVecOrMat; tol=0)\n\nThis function solves the linear system represented in solver::LinSolver with a right-hand side b. The tol kwarg is controlling how accurate the linear system needs to be solved. A NEP-algorithm will call this solver every time a linear system associated with M(λ) needs to be solved.\n\nThis function must be overloaded if a user wants to define their own way of solving linear systems. See LinSolver for examples.\n\n\n\n\n\n","category":"function"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"create_linsolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.create_linsolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.create_linsolver","text":"create_linsolver(creator::LinSovlerCreator,nep,λ)\n\nCreates a LinSolver instance for the nep corresponding which is evaluated in λ. The type of the output is decided by dispatch and the type of the LinSolverCreator.\n\nSee also: LinSolver, FactorizeLinSolverCreator, BackslashLinSolverCreator, DefaultLinSolverCreator, GMRESLinSolverCreator.\n\n\n\n\n\n","category":"function"},{"location":"linsolvers/#Standard-eigenvalue-problems","page":"Linear solvers","title":"Standard eigenvalue problems","text":"","category":"section"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"Some NEP-algorithms need to solve an associated linear eigenvalue problem, associated with M(λ). We provide the possibility to use Julia-native eigenvalue solvers, and an interface which allows you to define your own solver. By default, DefaultEigSolver is specified, which tries to determine an appropriate eigenvalue solver based on the NEP-type.","category":"page"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"tip: Tip\nThe NEP-solvers mslp and sgiter require eigenvalue solvers and take the keyword argument eigsolver.","category":"page"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"DefaultEigSolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.DefaultEigSolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.DefaultEigSolver","text":"struct DefaultEigSolver <: EigSolver\n\nA linear eigenvalueproblem solver that calls checks for sparsity and accordingly assigns an appropriate solver.\n\nSee also: EigSolver, eig_solve, EigenEigSolver, ArnoldiEigSolver\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"EigenEigSolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.EigenEigSolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.EigenEigSolver","text":"struct EigenEigSolver <: EigSolver\n\nA linear eigenvalueproblem solver that calls Julia's in-built eigen()\n\nConstructed as EigenEigSolver(A, [B,]), and solves the problem\n\nAx = λBx\n\nThe paramter B is optional an default is indentity, for which a standard linear eigenproblem is solved.\n\nSee also: EigSolver and eig_solve\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"ArnoldiEigSolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.ArnoldiEigSolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.ArnoldiEigSolver","text":"struct ArnoldiEigSolver <: EigSolver\n\nA linear eigenproblem solver for large and sparse problems that calls the Arnoldi method implemented in the Julia package ArnoldiMethod.jl.\n\nConstructed as ArnoldiEigSolver(A, [B,]), and solves the problem\n\nAx = λBx\n\nThe paramter B is optional an default is indentity, for which a standard linear eigenproblem is solved.\n\nSee also: EigSolver and eig_solve\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"EigSolver","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.EigSolver","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.EigSolver","text":"abstract type EigSolver\n\nStructs inheriting from this type are able to solve linear eigenvalue problems arising in certain methods, such as, e.g., mslp, sgiter, and polyeig.\n\nThe EigSolver objects are passed as types to the NEP-algorithms, which uses it to dispatch the correct version of the function eig_solve.\n\nExample\n\nThe most common usecase is that you do not want to specify anything in particular, since the DefaultEigSolver will use a dense or a sparse method depending on you problem. However, this example shows how you can force mslp to use the sparse solver.\n\njulia> nep=nep_gallery(\"qdep0\");\njulia> λ,v = mslp(nep, eigsolvertype=ArnoldiEigSolver);\njulia> norm(compute_Mlincomb(nep,λ,v))\n9.323110647141726e-16\n\nExample\n\nThe EigSolvers are constructed for extendability. As an illustartion this example creates a naive EigSolver which casts the problem to a standard linear eigenproblem and calls the built-in function to solve it.\n\nCreate the types and a creator.\n\njulia> struct MyEigSolver <: EigSolver\n   A\n   E\n   function MyEigSolver(A,E)\n      return new(A,E)\n   end\nend\n\njulia> import NonlinearEigenproblems.LinSolvers.eig_solve;\njulia> function eig_solve(solver::MyEigSolver;nev = 1, target = 0)\n   M = solver.E \\ solver.A\n   eig = eigen(M)\n   i = argmin(abs.(eig.values))\n   return eig.values[i], eig.vectors[:,i]\nend\njulia> nep=nep_gallery(\"dep0\", 50);\njulia> λ,v = mslp(nep, eigsolvertype=MyEigSolver, tol=1e-5);\njulia> norm(compute_Mlincomb(nep,λ,v))\n3.0777795031319117e-10\n\nSee also: eig_solve, DefaultEigSolver, EigenEigSolver, ArnoldiEigSolver, eig_solve\n\n\n\n\n\n","category":"type"},{"location":"linsolvers/","page":"Linear solvers","title":"Linear solvers","text":"eig_solve","category":"page"},{"location":"linsolvers/#NonlinearEigenproblems.LinSolvers.eig_solve","page":"Linear solvers","title":"NonlinearEigenproblems.LinSolvers.eig_solve","text":"eig_solve(solver::EigSolver; [nev,] [target,])\n\nThis function solves the linear eigenvalue problem represented in solver::EigSolver. The nev kwarg is controlling the number of eigenvalues aimed for, and target specifies around which point the eigenvalues are computed. The former has a defalut value equalt to the seize of the problem, and the latter has a defalut value 0.\n\nReturn values are of the form (Vector, Matrix) where the former contains the eigenvalues and the latter the eigenvectors.\n\nThis function must be overloaded if a user wants to define their own way of solving linear eigenvalue problems. See EigSolver for examples.\n\n\n\n\n\n","category":"function"},{"location":"tutorial_nano1/#Tutorial:-Problem-from-nanophotonics","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial: Problem from nanophotonics","text":"","category":"section"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"One of the key challanges within the field of nanophotonics stems from the need to be able to compute the modes of frequency-despersive structures in a reliable and efficient way. The frequency (i.e. eigenvalue) dependency can be viewed as a nonlinearity and therefore naturally leads to nonlinear eigenvalue problems.","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"This tutorial is based on a research preprint where a model is set up and solved with SLEPc. An associated repository of code is available which should be used in combination with gmsh and onelab. Credit for the discretization and application should go to the authors of the paper, in particular Guillaume Demésy for providing the model files online.","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"We will use the model files and onelab for that simulation and reproduce computational results using NEP-PACK.","category":"page"},{"location":"tutorial_nano1/#Part-1:-Setup-the-matrices","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Part 1: Setup the matrices","text":"","category":"section"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"You need to download the code with the model of the frequency-dispersive media here. (Note that we have fixed the specific version of the the model code in the URL.) You also need to install ONELAB from http://onelab.info/.","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"We need the matrices generated by this model, which are not saved to disk by default. A small modification of one of the project files is needed. You need to modify the NonLinearEVP.pro on the line before the EigenSolve specification for the res_NEP_E:","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"Print[M1]; // Add this line\nEigenSolve[M1,neig,eig_target_re,eig_target_im,EigFilter[],\n     { {1}, {-eps_oo_1,gam_1*eps_oo_1, -om_d_1^2,0}, {-1,0,0} },\n     { {1}, {1,-gam_1},                              {1} } ];","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"That is, you should add the text Print[M1]; (in the current version) before line 354.","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"After you do this modification, load the model and click \"run\" in the Gmsh tool, you will obtain files in the current directory containing the FEM-discretizations needed to set up the problem (file_mat_MX.m.bin).","category":"page"},{"location":"tutorial_nano1/#Part-2:-Implementation-in-NEP-PACK","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Part 2: Implementation in NEP-PACK","text":"","category":"section"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"The NEP in this problem has the structure","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"M(λ)=A_1+frac-varepsilon_inftyλ^3+varepsilon_inftygamma_d λ^2-omega_d^2λλ-gamma_dA_2-λ^2A_3","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"The constants are given in the project file and we set them in our julia code:","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"julia> a_lat=50;\njulia> cel=a_lat/(2*pi);\njulia> nrm=a_lat/(2*pi*cel);\njulia> om_d_1=1.1;\njulia> gam_1=0.05;\njulia> om_d_1=om_d_1/nrm;\njulia> gam_1=gam_1/nrm;\njulia> eps_oo_1=1.0;","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"The NEP in this example can be conveniently expressed as a SPMF_NEP, where the first function is constant, the second term is a rational function and the third is a quadratic term. We define them in a matrix function sense:","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"julia> f1=s-> one(s) #\njulia> f2=s-> (s-gam_1*one(s))\\(-eps_oo_1*s^3+gam_1*eps_oo_1*s^2-om_d_1^2*s)\njulia> f3=s-> -s^2","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"If you have carried out Part 1, you should have the sparse discretization matrices available. They are stored in the PETSc-binary format.   NEP-PACK contains functionality to load the generated matrices using the function Gallery.naive_petsc_read.","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"Suppose gmsh_files is a path to the bin-files generated in Part 1. These commands load the matrices","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"julia> A3=Gallery.naive_petsc_read(joinpath(gmsh_files,\"file_mat_M15.m.bin\")); # Switched order is intentional\njulia> A2=Gallery.naive_petsc_read(joinpath(gmsh_files,\"file_mat_M16.m.bin\"));\njulia> A1=Gallery.naive_petsc_read(joinpath(gmsh_files,\"file_mat_M17.m.bin\"));","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"tip: Tip\nThe function Gallery.naive_petsc_read is a partial implementation of the reading files in the PETSc binary file-format.  Another implementation which supports reading and writing is available in the package PETScBinaryIO.","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"The SPMF is created directly","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"julia> nep=SPMF_NEP([A1,A2,A3], [f1,f2,f3]);","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"We can now apply a method of choice. In this case we solve it with the tensor infinite Arnoldi method (tiar)  with a shift/target the same as in the project files","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"julia> (λ,V)=tiar(nep,σ=0.00243604+0.366703im,logger=1,neigs=10,maxit=100);\n-\n--\n=--\n+---\n+----\n+-----\n+------\n+-------\n+--------\n+---------\n+----------\n+==---------\n+++----------\n+++=----------\n++++-----------\n++++------------\n++++-------------\n++++--------------\n++++---------------\n++++----------------\n++++==---------------\n++++++----------------\n++++++-----------------\n++++++=-----------------\n++++++=------------------\n+++++++-------------------\n+++++++--------------------\n+++++++---------------------\n+++++++----------------------\n+++++++==---------------------\n+++++++==----------------------\n+++++++++=----------------------\n+++++++++=-----------------------\n++++++++++------------------------\njulia> λ\n10-element Array{Complex{Float64},1}:\n 0.002436044429913607 + 0.3667026531004412im\n 0.001175454247612957 + 0.3748476897696621im\n 0.006531655269175296 + 0.3736695833524133im\n 0.013279531609677153 + 0.37899563698023087im\n  0.04259449677920191 + 0.38730647107316im\n  0.04388349538759248 + 0.39266023012447837im\n 0.007774845736605659 + 0.25923501436468327im\n  0.09285578050590135 + 0.41819550232817293im\n  0.09374197960056296 + 0.41522753073470614im\n  0.01578630143214552 + 0.49172628247971106im","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"Each row in the logger printout of tiar corresponds to an iteration. The sign - corresponds to an unconverged eigenvalue, + corresponds to a converged eigenvalue and = corresponds to an eigenvalue which is almost converged (interpreted as a factor 10 from the convergence criteria). The eigenvalue  0.007774845736605659 + 0.25923501436468327im which can be found in the printout above, is reported by the default setting in the gmsh tool applied to the model files.","category":"page"},{"location":"tutorial_nano1/","page":"Tutorial 9 (gmsh + nanophotonics)","title":"Tutorial 9 (gmsh + nanophotonics)","text":"(Image: To the top)","category":"page"},{"location":"tutorial_matlab1/#Tutorial:-Solving-NEP-defined-in-MATLAB","page":"Tutorial 7 (MATLAB)","title":"Tutorial: Solving NEP defined in MATLAB","text":"","category":"section"},{"location":"tutorial_matlab1/#A-problem-defined-in-MATLAB","page":"Tutorial 7 (MATLAB)","title":"A problem defined in MATLAB","text":"","category":"section"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"MATLAB is the de-facto standard language for many tasks in scientific computing. If you have a NEP defined in MATLAB, you can quite easily use the NEP-solvers of this package. Below is a description of two ways to solve nonlinear eigenvalue problems defined in MATLAB. There is a cost in terms of efficiency to define your problem in MATLAB, due to overhead associated with communication between the MATLAB and Julia processes. Very large scale problems are recommended to be defined directly in Julia.","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"note: Note\nTo work with NEPs defined in MATLAB you need to have MATLAB installed on your computer. We use the MATLAB interoperability package to link Julia execution with MATLAB execution.","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"Suppose you have the following NEP in MATLAB","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"M(lambda)=A_0+lambda A_1+exp(lambda A_2)","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"where A_1A_2A_3 are martices and exp the matrix exponential. The problem can be defined in MATLAB as follows. This is the contents of the file compute_derivative_k.m:","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"function Z=compute_derivative_k(s,k)\n     randn('seed',0);\n     n=10;\n     A0=randn(n,n); A1=randn(n,n);\n     Z=zeros(n,n);\n     if (k==0)\n         Z=A0+s*A1;\n     end\n     if (k==1)\n         Z=A1;\n     end\n     Z=Z+(A1^k)*expm(s*A1);\nend","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"The function which computes derivative k evaluted in the point s. We assume in the following that the file compute_derivative_k.m is located in the current directory.","category":"page"},{"location":"tutorial_matlab1/#Approach-1:-Implementation-in-NEP-PACK-(using-Mder_NEP)","page":"Tutorial 7 (MATLAB)","title":"Approach 1: Implementation in NEP-PACK (using Mder_NEP)","text":"","category":"section"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"The easiest way to create a NEP which is only defined by its derivative computation is by the helper type Mder_NEP.","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"using NonlinearEigenproblems, MATLAB\nnep=Mder_NEP(10,(s,der) -> mat\"compute_derivative_k($s,double($der))\");","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"The NEP can now be approached with many of the methods in the package, e.g., with a contour integral method (contour_beyn):","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"julia> (λ,V)=contour_beyn(nep, radius=0.6, k=8);\njulia> λ\n2-element Array{Complex{Float64},1}:\n 0.1711954796771912 - 6.401495587242332e-15im\n 0.1547216302712358 - 0.16631220583083045im   ","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"The first argument of the Mder_NEP instantiation is the size of the NEP. The instantiation of the Mder_NEP creates a NEP-object only defined by its matrix derivative functions, given in the call-back function specified by the second argument. In this case, the the function calls a MATLAB process (running in the background completely hidden from the Julia user) and requests a execution of compute_derivate_k with the given arguments. After executing the MATLAB-call, the MATLAB-process sends the matrix back to Julia. In other words, we have coupled the derivative computation of the NEP with a call to MATLAB. More precisely, every call to the compute_Mder function leads to a call to the created MATLAB function. Compare:","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"julia> compute_Mder(nep,0.1+0.2im)\n10×10 Array{Complex{Float64},2}:\n   2.15543-0.101289im     -1.4933-0.0817057im  …    0.220658-0.313894im    0.371533+0.544535im\n  0.751339+0.213974im    0.532557+0.359256im         0.58971-0.135805im    -2.65352-0.308557im\n -0.177809-0.383021im     1.46944+0.374974im        0.965219+0.140168im    0.979515-0.603281im\n  0.204312-0.300014im   -0.576669+0.630099im         1.94032+0.43922im    -0.803364+0.652243im\n -0.378807+0.511258im    0.590185+0.0812181im      -0.381726-0.138047im     1.30005+0.562022im\n   1.58041-0.266624im   -0.347895+0.292268im   …  -0.0826327+0.155039im   -0.691359+0.340299im\n  0.105255+0.0940046im  -0.338352-0.443379im        0.546516-0.062307im    0.445814-0.648929im\n   1.47467-0.646341im    -1.36607-0.195403im         1.02226-0.0228401im    1.14153+0.576545im\n  0.182295-0.143594im    -1.06099+0.492347im        -0.41297-0.409332im   -0.322912-0.219094im\n  0.658504-0.190844im     1.21896+0.280606im       -0.563413-0.073228im     1.25092-0.418521im","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"with the MATLAB call:","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":">> M=compute_derivative_k(0.1+0.2i,0);\n>> M(1:3,1:3) % I don't want to see the whole matrix\nans =\n   2.1554 - 0.1013i  -1.4933 - 0.0817i   0.1131 + 0.0836i\n   0.7513 + 0.2140i   0.5326 + 0.3593i  -1.0211 - 0.5134i\n  -0.1778 - 0.3830i   1.4694 + 0.3750i   0.2180 + 0.1720i","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"You can verify that the output of the call to the contour_beyn-method is a solution directly in MATLAB:","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":">> s = 0.1547216302712358 - 0.16631220583083045i; % copied from the output above (remember: 1im -> 1i)\n>> M=compute_derivative_k(s,0);\n>> min(svd(M)) % Matrix is singular if s is a solution\nans =\n   1.5239e-15","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"NEP-objects in NEP-PACK are defined from compute-functions (as we describe in NEPTypes) and in this case we only defined the derivative computation function compute_Mder. Note that the Mder_NEP-type provides default implementations of compute_Mlincomb as well as compute_MM (by wrapping calls to compute_Mder) in a way that is hidden from the user, such that we can still use algorithms based on those compute functions. More efficiency can be obtained if these compute functions are also implemented, e.g., by a different MATLAB-function.","category":"page"},{"location":"tutorial_matlab1/#Approach-2:-Implementation-in-NEP-PACK-(using-new-type)","page":"Tutorial 7 (MATLAB)","title":"Approach 2: Implementation in NEP-PACK (using new type)","text":"","category":"section"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"We illustrate the extendability of the package by defining our own type, which again uses the MATLAB-package in the background.","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"note: Note\nThe process is also described in the BEM tutorial.","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"The size is hardcoded in this example, so we can define a new type of the specific size:","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"struct MATLABNEP <: NEP\nend\nBase.size(nep::MATLABNEP) = (10,10)\nBase.size(nep::MATLABNEP,::Int) = 10","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"Initiate the MATLAB package and prepare to integrate with NEP-PACK:","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"using MATLAB; # requires MATLAB to be installed\nmat\"addpath('.')\" # Add path to your m-file\nimport NonlinearEigenproblems.compute_Mder;\nimport NonlinearEigenproblems.compute_Mlincomb;\nimport NonlinearEigenproblems.compute_Mlincomb_from_Mder;","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"In this example, the problem is only provided by a function to compute derivatives of M, which we specify by defining a  compute_Mder function. We also specify that linear combinations of derivatives should be computed by calling compute_Mder in the naive way:","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"function compute_Mder(::MATLABNEP,s::Number,der::Integer=0)\n    return mat\"compute_derivative_k(double($s),double($der))\"\nend\ncompute_Mlincomb(nep::MATLABNEP,λ::Number,V::AbstractVecOrMat, a::Vector) = compute_Mlincomb_from_Mder(nep,λ,V,a)\ncompute_Mlincomb(nep::MATLABNEP,λ::Number,V::AbstractVecOrMat) = compute_Mlincomb(nep,λ,V, ones(eltype(V),size(V,2)))","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"Now you can instantiate the NEP and use your favorite NEP-solver, in this case we use newtonqr.","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"julia> nep=MATLABNEP();\njulia> (λ,v)=newtonqr(nep,λ=-3,logger=1,maxit=30,v=ones(10));\niter 1 err:1.033593309412195 λ=-3.0 + 0.0im\niter 2 err:0.3059246224011592 λ=0.83641207310996 + 0.0im\niter 3 err:0.6000405834026614 λ=-1.7728647881500432 + 0.0im\niter 4 err:0.07375061614602237 λ=-0.7800560594951582 + 0.0im\niter 5 err:0.0093516562758152 λ=-0.8707521093182906 + 0.0im\niter 6 err:8.954564848847882e-5 λ=-0.8840785307305598 + 0.0im\niter 7 err:7.446596609664408e-9 λ=-0.88420751056806 + 0.0im\niter 8 err:1.0942739518352825e-15 λ=-0.884207521294992 + 0.0im","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"The residual is small and we have a solution","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"julia> using LinearAlgebra\njulia> norm(compute_Mlincomb(nep,λ,v))/norm(v)\n1.0942739518352825e-15","category":"page"},{"location":"tutorial_matlab1/","page":"Tutorial 7 (MATLAB)","title":"Tutorial 7 (MATLAB)","text":"(Image: To the top)","category":"page"},{"location":"gallery/#Gallery","page":"Gallery","title":"Gallery","text":"","category":"section"},{"location":"gallery/","page":"Gallery","title":"Gallery","text":"NEP-PACK provides a way to access applications in order to easily improve and compare algorithms on realistic problems. Below you will find a description of:","category":"page"},{"location":"gallery/","page":"Gallery","title":"Gallery","text":"Standard native gallery. This gallery provides are accessed typically through the function call nep=nep_gallery(str::String) and returns a NEP-object with efficient compute-functions. The str is an identifier for the problem.\nBerlin-Manchester problem collection. You can access problems from this MATLAB-collection by the call nep=nep_gallery(NLEVP_NEP,str::String), where str is the identified in the MATLAB-package. This requires that you have MATLAB and the problem collection installed.\nExtra problems. We provide careful implementations of certain large-scale problems which are too large to include in the main gallery.","category":"page"},{"location":"gallery/","page":"Gallery","title":"Gallery","text":"julia> nep=nep_gallery(\"dep0\")\njulia> λ,v=newton(nep)\n(-0.3587189459686265 + 0.0im, Complex{Float64}[0.284742+0.0im, -0.143316+0.0im, 0.278378+0.0im, -0.5009+0.0im, -0.613634+0.0im])\njulia> norm(compute_Mlincomb(nep,λ,v))\n4.718447854656915e-16","category":"page"},{"location":"gallery/#Standard-native-gallery","page":"Gallery","title":"Standard native gallery","text":"","category":"section"},{"location":"gallery/","page":"Gallery","title":"Gallery","text":"nep_gallery(::String)","category":"page"},{"location":"gallery/#NonlinearEigenproblems.Gallery.nep_gallery-Tuple{String}","page":"Gallery","title":"NonlinearEigenproblems.Gallery.nep_gallery","text":" nep=nep_gallery(name)\n nep=nep_gallery(name,params)\n nep=nep_gallery(name,params;kwargs)\n\nCollection of nonlinear eigenvalue problems. Returns a NEP object from a gallery of examples of nonlinear eigenvalue problems. The parameter name decides which NEP.\n\nSupported problems:\n\nThe following list describes the NEP with a certain name and the associated parameters (params) and keyword arguments (kwargs), if any.\n\n\ndep0: A random DEP with one delay tau = 1, generated with a pseudorandom number generator. \n  params: size (default = 5)\ndep0_sparse: A random DEP with sparse matrices and one delay tau = 1,  generated with a pseudorandom number generator.\n  Params: Two optional params determining the size (default = 5) and the fill (default = 0.25)\ndep0_tridiag: A random DEP with sparse tridiagonal matrices and one delay tau = 1, generated with a pseudorandom number generator.\n  Params: size (default = 100)\ndep_symm_double: A DEP with double eigenvalues and sparse symmetric matrices and one delay tau = 1.\n  Params: size (default = 100)\n  Reference: Example from H. Voss and M. M. Betcke, Restarting iterative projection methods for Hermitian nonlinear eigenvalue problems with minmax property, Numer. Math., 2017\ndep_double: A DEP with a double non-semisimple eigenvalue in λ=3πi.\n  Reference: Example from E. Jarlebring, Convergence factors of Newton methods for nonlinear eigenvalue problems, LAA, 2012\ndep1: A DEP with one eigenvalue equal to one.\npep0: A random PEP, generated with a pseudorandom number generator\n  Params: size (default = 200)\npep0_sym: A random symmetric PEP, generated with a pseudorandom number generator\n  Params: size (default = 200)\npep0_sparse: A random PEP with sparse matrices, generated with a pseudorandom number generator\n  Params: Two optional params determining the size (default = 200) and the fill (default = 0.03)\nreal_quadratic: A quadratic PEP with real eigenvalues.\n  Solutions:     Four smallest eigenvalues of the problem:\n  ∘ -2051.741417993845\n  ∘ -182.101627437811\n  ∘ -39.344930222838\n  ∘ -4.039879577113\n\ndep_distributed: A NEP corresponding to a distributed delay time-delay system\n  Reference: Example in E. Jarlebring and W. Michiels and K. Meerbergen, The infinite Arnoldi method and an application to time-delay systems with distributed delays, Delay Systems - Methods, Applications and New Trends, 2012\n  Solutions:  Some correct eigenvalues:\n  ∘ -0.400236388049641 + 0.970633098237807i\n  ∘ -0.400236388049641 - 0.970633098237807i\n  ∘ 2.726146249832675 +  0.000000000000000i\n  ∘ -1.955643591177653 + 3.364550574688863i\n  ∘ -1.955643591177653 - 3.364550574688863i\n  ∘ 4.493937056300693 +  0.000000000000000i\n  ∘ -1.631513006819252 + 4.555484848248613i\n  ∘ -1.631513006819252 - 4.555484848248613i\n  ∘ -1.677320660400946 + 7.496870451838560i\n  ∘ -1.677320660400946 - 7.496870451838560i\nqdep0:  A quadratic delay eigenvalue problem.\n Reference: S. W. Gaaf and E. Jarlebring, The infinite Bi-Lanczos method for nonlinear eigenvalue problems, SIAM J. Sci. Comput., 2017\nqdep1:  A quadratic delay eigenvalue problem.\n Reference: E. Jarlebring and W. Michiels and K. Meerbergen, A linear eigenvalue algorithm for the  nonlinear eigenvalue problem, Numer. Math., 2011\nqep_fixed_eig: A quadratic eigenvalue problem with chosen eigenvalues.\n Params: Two optional params determining the size (default = 5) and a vector containing the eigenvalues (default = uniform [-1,1])\nneuron0: A DEP that stems from the modling of a coupled neuron.\n Reference: L. P. Shayer and S. A. Campbell, Stability, bifurcation and multistability in a system of two coupled neurons with multiple time delays, SIAM J. Applied Mathematics, 2000. It is also a benchmark example in DDE-BIFTOOL.\nschrodinger_movebc: A NEP stemming from the discretization of a Schrödinger equation as described in the NEP-PACK online tutorial.  The nonlinearity contains sinh(), cosh() and sqrt().\n Params: The optional parameters are size of discretization n  and domain and potential description L0,L1,α and V0.\nbeam: A DEP modelling a beam with delayed stabilizing feedback described. The A1-term is rank one.\n Params:  size of the matrix (defalut = 100)\n Reference: R. Van Beeumen, E. Jarlebring, and W. Michiels,  A rank-exploiting infinite Arnoldi algorithm for nonlinear eigenvalue problems, 2016.\nsine: A NEP formed by the sum of a polynomial and a sine-function. The sine-term has a rank-one matrix coefficient.\n Reference:  R. Van Beeumen, E. Jarlebring, and W. Michiels,  A rank-exploiting infinite Arnoldi algorithm for nonlinear eigenvalue problems, 2016.\nbem_fichera:  Represents a boundary element discretization of Helmholtz equation for a domain consisting of the unit cube, except one removed corner (Fichera corner). The mesh is hardcoded.   Params: The parameter N determines the size of the problem (default N = 5).\n  Reference: The model stems from the model in these papers:  A boundary element method for solving PDE eigenvalue problems, M. Steinlechner, bachelor thesis, ETH Zürich, 2010 and  Effenberger and Kressner, Chebyshev interpolation for nonlinear eigenvalue problems, BIT Numerical Mathematics, December 2012, Volume 52, Issue 4, pp 933–951\ndtn_dimer: NEP with quotients of Bessel functions stemming from the modeling of resonances \n  Params:  This NEP takes two parameters: data_dir::String and l::Int. The data_dir specifies the directory of the dowloaded FEM-matrices (available here https://umu.app.box.com/s/b52yux3z9rcl8y0l7la22k0vi062cvu5). The integer l specifies the number of DtN-terms: 2l+1.\n  Reference: J. Araujo-Cabarcas, C. Engström and E. Jarlebring, Efficient resonance computations for Helmholtz problems based on a Dirichlet-to-Neumann map, J. Comput. Appl. Math., 330:177-192, 2018)\n\nThe MATLAB-package described in T. Betcke, N. J. Higham, V. Mehrmann, Ch. Schröder, F. Tisseur, NLEVP: A Collection of Nonlinear Eigenvalue Problems, ACM Transactions on Mathematical Software 39(2), January 2011 provides a number of benchmark problems for NEPs. These are available in NEP-PACK in two different ways. We have native implementations of some problems (referred to as nlevp_native_) and the separate GalleryNLEVP. The native implementation is preferred since the GalleryNLEVP  interfaces with MATLAB and is therefore considerably slower.\n\nnlevp_native_gun:  The benchmark problem from the NLEVP-collection called \"gun\", represented in the native NEP-PACK format.   B.-S. Liao, Z. Bai, L.-Q. Lee, and K. Ko. Nonlinear Rayleigh-Ritz iterative method for solving large scale   nonlinear eigenvalue problems.  Taiwan. Journal of Mathematics, 14(3):869–883, 2010\nnlevp_native_cd_player:  The benchmark problem from the NLEVP-collection called \"cd_player\", represented in the native NEP-PACK format.   Y. Chahlaoui, and P. M. Van Dooren, Benchmark examples for model reduction of linear time-   invariant dynamical systems. In Dimension Reduction of Large-Scale Systems, P. Benner, V. Mehrmann,   and D. C. Sorensen, Eds. Lecture Notes in Computational Science and Engineering Series, vol. 45.   Springer-Verlag, Berlin, 380–392, 2005.   and   P. M. R. Wortelboer, M. Steinbuch, and  O. H. Bosgra, Closed-loop balanced reduction with   application to a compact disc mechanism. In Selected Topics in Identification, Modeling and Control.   Vol. 9. Delft University Press, 47–58, 1996.   and   W. Draijer, M. Steinbuch, and  O. H. Bosgra, Adaptive control of the radial servo system of a   compact disc player. Automatica 28, 3, 455–462. 1992.\nnlevp_native_fiber: The benchmark problem from the NLEVP-collection called \"fiber\", represented in the native NEP-PACK format.   One of terms in this problem is approximated by interpolation, and may not always coincide with the benchmark.   L. Kaufman, Eigenvalue problems in fiber optic design. SIAM J. Matrix Anal. Appl. 28, 1, 105–117, 2006.   and   X. Huang, Z. Bai, and Y. Su, Nonlinear rank-one modification of the symmetric eigenvalue problem. J. Comput. Math. 28, 2, 218–234, 2010\nnlevp_native_hadeler: The benchmark problem from the NLEVP-collection called \"hadeler\", represented in the native NEP-PACK format. The problem is of the form M(λ)=(e^λ-1)B+A_0+A_2λ^2. \n  Hadeler K.  P.  1967.  Mehrparametrige  und  nichtlineare  Eigenwertaufgaben. Arch.  Rational  Mech. Anal. 27, 4, 306–328.\nnlevp_native_pdde_stability: The benchmark problem from the NLEVP-collection called \"pdde_stability\", represented in the native NEP-PACK format.   This problem is a quadratic eigenvalue with arbitrary given size n. See   E. Jarlebring, The Spectrum of Delay-Differential Equations:   Numerical Methods, Stability and Perturbation, PhD thesis,   TU Braunschweig, Institut Computational Mathematics, Germany, 2008 and   H. Fassbender, N. Mackey, D. S. Mackey and C. Schroeder, Structured   Polynomial Eigenproblems Related to Time-Delay Systems, ETNA, 2008, vol 31, pp 306-330\nnlevp_native_loaded_string:  The benchmark problem from the NLEVP-collection called \"pdde_stability\", represented in the native NEP-PACK format.   The parameters are (n,kappa,m) where n is the size, and the NEP is a SPMF with rational terms and the coefficient   matrices are rank one modifications of Toeplitz matrices.\n  S. I. Solov\"ev. Preconditioned iterative methods for a class of nonlinear eigenvalue problems. Linear Algebra Appl., 415 (2006), pp.210-229.\n\nExample\n\njulia> nep=nep_gallery(\"dep0\",100);\njulia> norm(compute_Mlincomb(nep,1.0+1.0im,ones(size(nep,1))))\n57.498446538064954\n\nSee also the following galleries:\n\nGalleryNLEVP\nGalleryWaveguide\n\n\n\n\n\n","category":"method"},{"location":"gallery/#Berlin-Manchester-collection","page":"Gallery","title":"Berlin-Manchester collection","text":"","category":"section"},{"location":"gallery/","page":"Gallery","title":"Gallery","text":"If MATLAB and the Berlin-Manchester collection are installed, you can access the Berlin-Manchester collection problems with the GalleryNLEVP. This is a wrapper, which makes  MATLAB-calls (via Julias MATLAB interoperability package) for every compute-function call. This can be very inefficient due to overhead. You may want to convert your NEP to a native type, e.g., ChebPEP.","category":"page"},{"location":"gallery/","page":"Gallery","title":"Gallery","text":"julia> using GalleryNLEVP\njulia> nlevp_path=\"/home/user/myname/work/src/nlevp\";\njulia> nep=nep_gallery(NLEVP_NEP,\"hadeler\",nlevp_path);\njulia> λ,v=quasinewton(nep,λ=0.2,logger=1,maxit=20,tol=1e-10);\njulia> norm(compute_Mlincomb(nep,λ,v))/norm(v)\n9.698206079849311e-11","category":"page"},{"location":"gallery/","page":"Gallery","title":"Gallery","text":"Problems loaded from the Berlin-Manchester collection are NEP-objects where every call to access a function generates a call to an underlying MATLAB-session. Some problems in the Berlin-Manchester collection have native support in NEP-PACK, i.e., avoiding a MATLAB-access in every call; see nep_gallery above.","category":"page"},{"location":"gallery/#Extra-gallery-problems","page":"Gallery","title":"Extra gallery problems","text":"","category":"section"},{"location":"gallery/","page":"Gallery","title":"Gallery","text":"Stand-alone implementation of certain larger problems can be accessed in a similar way to the standard native gallery. A native implementation of a waveguide eigenvalue problem can be accessed as.","category":"page"},{"location":"gallery/","page":"Gallery","title":"Gallery","text":"julia> using GalleryWaveguide\njulia> nep=nep_gallery(WEP,benchmark_problem=\"TAUSCH\");","category":"page"},{"location":"logger/#Logger","page":"Logger","title":"Logger","text":"","category":"section"},{"location":"logger/#Basic-usage","page":"Logger","title":"Basic usage","text":"","category":"section"},{"location":"logger/","page":"Logger","title":"Logger","text":"NEP-PACK provides considerable functionality to control the printouts and information of the NEP-solvers. All NEP-solvers take the keyword argument logger which specifies if things should be stored in a logger and/or printed. The main loggers are the PrintLogger which only provides printouts, and ErrorLogger which stores error information.","category":"page"},{"location":"logger/","page":"Logger","title":"Logger","text":"We illustrate with a combination with the error measure. This example shows how to plot the eigenvalue error of a NEP-solver by using a reference solution.","category":"page"},{"location":"logger/","page":"Logger","title":"Logger","text":"First let us only user logger=1 in combination with a EigvalReferenceErrmeasure.","category":"page"},{"location":"logger/","page":"Logger","title":"Logger","text":"julia> A0=[3.0 4 ; 5 6]; A1=[-1.0 0 ; 3.0 1.0];\njulia> nep=DEP([A0,A1]); # Delay eigenvalue problem\njulia> (λref,_)=resinv(nep,v=[1;1],λ=8,tol=1e-16); # Compute a reference solution\njulia> resinv(nep,v=[1;1],λ=8,logger=1,errmeasure=EigvalReferenceErrmeasure(nep,λref));\nPrecomputing linsolver\niter 1 err:1.2171484853011378 λ=8.0 + 0.0im\niter 2 err:0.21696340485295096 λ=9.000185080448187 + 0.0im\niter 3 err:0.032989925133875886 λ=9.250138410435014 + 0.0im\niter 4 err:0.004864643426348181 λ=9.21228384187479 + 0.0im\niter 5 err:0.0007206309370317854 λ=9.21786911623817 + 0.0im\niter 6 err:0.00010667933045382938 λ=9.217041805970684 + 0.0im\niter 7 err:1.579396864670457e-5 λ=9.217164279269785 + 0.0im\niter 8 err:2.3382761789036977e-6 λ=9.217146147024959 + 0.0im\niter 9 err:3.461794584325162e-7 λ=9.217148831480596 + 0.0im\niter 10 err:5.1251506150151727e-8 λ=9.217148434049632 + 0.0im\niter 11 err:7.587733108493921e-9 λ=9.217148492888871 + 0.0im\niter 12 err:1.1233556307388426e-9 λ=9.217148484177782 + 0.0im\niter 13 err:1.6631140908884845e-10 λ=9.21714848546745 + 0.0im\niter 14 err:2.4622082150926872e-11 λ=9.217148485276516 + 0.0im\niter 15 err:3.645084234449314e-12 λ=9.217148485304783 + 0.0im\niter 16 err:5.400124791776761e-13 λ=9.217148485300598 + 0.0im\niter 17 err:7.993605777301127e-14 λ=9.217148485301218 + 0.0im\niter 18 err:1.0658141036401503e-14 λ=9.217148485301127 + 0.0im","category":"page"},{"location":"logger/","page":"Logger","title":"Logger","text":"The displayed err are eigenvalue errors and we now wish to plot them:","category":"page"},{"location":"logger/","page":"Logger","title":"Logger","text":"julia> logger=ErrorLogger();\njulia> resinv(nep,v=[1;1],λ=8,\n    errmeasure=EigvalReferenceErrmeasure(nep,λref),logger=logger);\njulia> errvec=logger.errs[1:17,1]; # This contains the iteration error","category":"page"},{"location":"logger/","page":"Logger","title":"Logger","text":"We use Plots for plotting:","category":"page"},{"location":"logger/","page":"Logger","title":"Logger","text":"julia> using Plots;\njulia> plot(errvec,yaxis=:log,marker=:star,xlabel=\"iteration\",ylabel=\"eigval error\")","category":"page"},{"location":"logger/","page":"Logger","title":"Logger","text":"The theory predicts linear convergence, which we also observe.","category":"page"},{"location":"logger/","page":"Logger","title":"Logger","text":"<br>\n<img src=\"https://nep-pack.github.io/NonlinearEigenproblems.jl/logger_resinv_conv.png\" height=300>","category":"page"},{"location":"logger/#Logger-types","page":"Logger","title":"Logger types","text":"","category":"section"},{"location":"logger/","page":"Logger","title":"Logger","text":"Logger\nPrintLogger\nErrorLogger","category":"page"},{"location":"logger/#NonlinearEigenproblems.NEPCore.Logger","page":"Logger","title":"NonlinearEigenproblems.NEPCore.Logger","text":"abstract type Logger ; end\n\nThe type represents a way to log information throughout the algorithms. Error history and other properties can be stored in the logger. The most common Loggers are PrintLogger and ErrorLogger.\n\nAs a method developer you want to use push_info! and push_iteration_info!\n\nSee also: PrintLogger and ErrorLogger.\n\n\n\n\n\n","category":"type"},{"location":"logger/#NonlinearEigenproblems.NEPCore.PrintLogger","page":"Logger","title":"NonlinearEigenproblems.NEPCore.PrintLogger","text":"struct PrintLogger <: Logger ;\nfunction PrintLogger(displaylevel)\n\nWhen you use this logger, you will obtain printouts in stdout, no other logging. The displaylevel parameter specifies how much should be printed. The higher the value, the more is printed. Zero means no printouts.\n\n\n\n\n\n","category":"type"},{"location":"logger/#NonlinearEigenproblems.NEPCore.ErrorLogger","page":"Logger","title":"NonlinearEigenproblems.NEPCore.ErrorLogger","text":"struct ErrorLogger <: Logger\nErrorLogger(nof_eigvals=100,nof_iters=100,displaylevel=1)\n\nUse this object if you want to save the error history in a method. The displaylevel is interpreted as in PrintLogger. The kwargs nof_eigvals and nof_iters is used to preallocate memory used for saving.\n\nWhen you use this logger, the error of push_iteration_info!-calls will be stored in logger.errs.\n\n\n\n\n\n","category":"type"},{"location":"logger/#Advanced-usage","page":"Logger","title":"Advanced usage","text":"","category":"section"},{"location":"logger/","page":"Logger","title":"Logger","text":"The logging functionality can be extended in case you want to collect (or throw away) some of the information. You need to create a new type which implements the following methods.","category":"page"},{"location":"logger/","page":"Logger","title":"Logger","text":"push_info!\npush_iteration_info!","category":"page"},{"location":"logger/#NonlinearEigenproblems.NEPCore.push_info!","page":"Logger","title":"NonlinearEigenproblems.NEPCore.push_info!","text":"function push_info!(logger, [level,] v; continues::Bool=false)\n\nPushes a string v to the logger. If continues=true, the next push_info! (or push_iteration_info!) is connected to this, e.g. line-feed will be omitted.\n\n\n\n\n\n","category":"function"},{"location":"logger/#NonlinearEigenproblems.NEPCore.push_iteration_info!","page":"Logger","title":"NonlinearEigenproblems.NEPCore.push_iteration_info!","text":"function push_iteration_info!(logger, [level,] iter; kwargs)\n\nPushes information about a specific iteration iter. Standardized keywords are λ, err and v.\n\n\n\n\n\n","category":"function"},{"location":"deflation/#Deflation","page":"Deflation","title":"Deflation","text":"","category":"section"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"Several NEP-algorithms are able to find one eigenvalue, but may have difficulties finding several eigenvalues. Deflation is a transformation technique which can transform a NEP by effectively removing computed eigenvalues, and allowing several eigenvalues to be computed by repeated application of the same NEP-algorithm.","category":"page"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"NEP-PACK provides a solver-independent implementation of deflation which can be combined (essentially) with any NEP-solver.  NEP-PACK also has some NEP-solver deflation techniques and reconvergence avoidance techniques  incoprorated directly in the solver, e.g., in the nonlinear Arnoldi method (nlar), the Jacobi-Davidson method (jd_betcke) and Broyden's method (broyden).","category":"page"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"The technique takes a NEP and a solution and creates a bigger NEP with one dimension larger but where the eigenvalue is removed from the solution set. Due to the abstraction of NEP-objects in NEP-PACK, the deflated NEP is again a NEP and we can apply the NEP-solver to the deflated NEP.","category":"page"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"Given a NEP (which can be a deflated NEP) nep and an eigenpair (λ,v) you can compute a deflated NEP by calling dnep=deflate_eigpair(nep,λ,v) and dnep will essentially have the same eigenvalues as nep, except λ.\nThe transformation changes the eigenvectors such that the eigenvectors of nep and dnep will be different. To extract the eigenvectors (and the eigenvalues) you can call get_deflated_eigpairs(dnep).","category":"page"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"note: Note\nMore elaborate deflation examples can be found in the tutorial on deflation.","category":"page"},{"location":"deflation/#Theory","page":"Deflation","title":"Theory","text":"","category":"section"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"The theory follows the presentation of the technique in the PhD thesis of Cedric Effenberger. It can be summarized as follows, in a somewhat simplified form (for the index one case). The deflation is based on a theory for NEPs essentially stating that if (sx) is an eigenpair, then under certain general conditions (which we implicitly assume are satisfied),  the extended nonlinear eigenvalue problem","category":"page"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"T(λ)=beginbmatrixM(λ)M(λ)x(s-λ)^-1 x^T  0endbmatrix","category":"page"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"has the same eigenvalues as the original problem except for the eigenvalue s which is no longer part of the solution set. We have effectively removed (i.e. deflated) the eigenpair (s,x). More eigenpairs can be deflated with techniques of partial Schur factorizations, which the user does not need to be aware of, due to the abstraction provided by the functions below. When we create a deflated NEP, we create the NEP T.","category":"page"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"There are several ways to represent the T, which is why deflation has several modes. If you run","category":"page"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"julia> dnep=deflate_eigpair(nep,λ1,v1,mode=:SPMF)","category":"page"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"the dnep will be of the type AbstractSPMF. More precisely, if","category":"page"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"M(λ)=A_1f_1(λ)+cdots+A_mf_m(λ)","category":"page"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"the deflated NEP will be","category":"page"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"T(λ)=\nbeginbmatrixA_100  0endbmatrixf_1(λ)+cdots+\nbeginbmatrixA_m00  0endbmatrixf_m(λ)+","category":"page"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"beginbmatrix0A_1x0  0endbmatrixfracf_1(λ)s-λ+cdots+\nbeginbmatrix0A_mx0  0endbmatrixfracf_m(λ)s-λ+\nbeginbmatrix00x^T  0endbmatrix","category":"page"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"Clearly, the deflated NEP has more SPMF-terms than the original NEP. When the parameter mode=:SPMF is set, the deflation method will explicitly construct an SPMF_NEP. This is not recommended if you have many SPMF-terms in the original problem, but can be efficient when you only have a few terms. (Some additional exploitation is however implemented, since we can use the fact that the introduced terms are of low rank, and therefore naturally represented as a LowRankFactorizedNEP.)","category":"page"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"If you select mode=:Generic, the compute functions are implemented without the use of SPMF, and can be more efficient if the NEP has many SPMF-terms. When mode=:MM the compute-functions are all implemented by calls to compute_MM. This will not be efficient if compute_Mder(nep,λ,der) where  der>0 is needed.","category":"page"},{"location":"deflation/#Functions","page":"Deflation","title":"Functions","text":"","category":"section"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"deflate_eigpair","category":"page"},{"location":"deflation/#NonlinearEigenproblems.NEPTypes.deflate_eigpair","page":"Deflation","title":"NonlinearEigenproblems.NEPTypes.deflate_eigpair","text":"dnep=deflate_eigpair(orgnep::NEP,λ,v,[mode=:Auto])\n\nThis function creates a deflated NEP based on (λv), which are assumed to an eigenpair of nep. Effectively, the function will return dnep::NEP which has the same solutions as orgnep, except those corresponding to (λv). Deflation is typically used to avoid reconvergence.\n\nIf orgnep is a DeflatedNEP, the orgnep the deflation in orgnep will be updated.\n\nThe mode kwarg can be :Auto, :Generic, :SPMF, :MM. This specifies how the deflated NEP should be represented. Which mode is the most efficient depends on many problem properties. If the original NEP is an AbstractSPMF with only a few terms, mode=:SPMF may be efficient. The SPMF-mode is based on a diagonalization of the deflated invariant pair and is not necessarily robust when you deflate eigenvalues near to each other. When mode=:MM is used, all compute functions are implemented via calls to the compute_MM. This can work well for small dense problems. The :Generic is based on an explicit derivation of the problem (via binomial expansion) which can be efficient if low order derivates are needed. If :Auto is selected, NEP-PACK tries to determine which one is the most efficient based on the orgnep.\n\nExample:\n\njulia> nep=nep_gallery(\"dep0\");\njulia> (λ,v)=newton(nep,v=ones(size(nep,1)));\njulia> dnep=deflate_eigpair(nep,λ,v)\njulia> (λ2,v2)=augnewton(dnep,v=ones(size(dnep,1)));  # this converges to different eigval\njulia> using LinearAlgebra;\njulia> minimum(svdvals(compute_Mder(nep,λ2)))\n2.5161012836775824e-17\n\nThe function get_deflated_eigpairs() extracts the eigenpairs that have been deflated. The returned pairs are eigenpairs of the original NEP:\n\njulia> dnep=deflate_eigpair(dnep,λ2,v2);\njulia> (D,V)=get_deflated_eigpairs(dnep)\njulia> norm(compute_Mlincomb(nep,D[1],V[:,1]))\n2.3970746442479104e-16\njulia> norm(compute_Mlincomb(nep,D[2],V[:,2]))\n8.101585801848734e-16\n\nReferences\n\nC. Effenberger, Robust solution methods for nonlinear eigenvalue problems, PhD thesis, 2013, EPF Lausanne\n\n\n\n\n\n","category":"function"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"get_deflated_eigpairs","category":"page"},{"location":"deflation/#NonlinearEigenproblems.NEPTypes.get_deflated_eigpairs","page":"Deflation","title":"NonlinearEigenproblems.NEPTypes.get_deflated_eigpairs","text":"(D,V)=get_deflated_eigpairs(S,V,n)\n(D,V)=get_deflated_eigpairs(dnep::DeflatedNEP [λ,v])\n\nReturns a vector of eigenvalues D and a matrix with corresponding eigenvectors V of the invariant pair S,V. The eigenpairs correspond to the original problem, underlying the DeflatedNEP. The optional parameters λ,v allows the inclusion of an additional eigpair. Essentially, the optional parameters are the expanding the deflation and the running get_deflated_eigpairs  with kwarg, i.e.,\n\n(D,V)=get_deflated_eigpairs(deflate_eigpair(dnep,λ,v))`\n\nSee example in deflate_eigpair.\n\n\n\n\n\n","category":"function"},{"location":"deflation/","page":"Deflation","title":"Deflation","text":"(Image: To the top)","category":"page"},{"location":"innersolvers/#Projection","page":"Projection","title":"Projection","text":"","category":"section"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"Many NEP-solvers are based on a computation of a solution to a projected problem, i.e., if VWinmathbbR^ntimes p we need to solve the (smaller) NEP","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"W^HM(λ)Vz=0","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"This is sometimes called a nonlinear Rayleigh-Ritz procedure, or a direct projection. These are inner solvers for many NEP-solvers.","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"NEP-PACK provides a framework to handle projected problems and inner solves. This is implemented into two separate components:","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"Projection: As a user (or NEP-solver developer) you can create a new object corresponding to the projection. In NEP-PACK, the projection is again an object of with type inheriting from NEP. More precisely, it is a Proj_NEP which you normally create with the function create_proj_NEP.\nInner solvers: Since the projected problem is again a NEP, in principle any of the NEP-solvers of this package can be used. This is handled by the InnerSolver objects which are wrappers for corresponding NEP-solvers such that we can pass appropriate parameters to the inner soler. The inner solver is controlled by the inner_solver_method keyword in many NEP-solvers. By default DefaultInnerSolver is used.","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"As a NEP-user, you often do not need to care about how the projection is handled, e.g., if you use the type SPMF_NEP with only a few terms. For instance, if you wish to use the infinite Arnoldi method (iar) to handle the project solves in the nonlinear Arnoldi method (nlar), you can call nlar with the kwarg inner_solver_method=IARInnerSolver():","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"julia> nep=nep_gallery(\"dep0_tridiag\");\njulia> λ,v=nlar(nep,neigs=1,inner_solver_method=IARInnerSolver(),logger=1);\nUsing inner solver IARInnerSolver(1.0e-13, 80, :ones, false, NonlinearEigenproblems.NEPSolver.iar)\niter 1 err:0.07075594099201046 λ=-0.09271600160844096 + 0.03235352263155604im\niter 2 err:0.03648528716335285 λ=0.1565592513189133 + 0.013613366856692472im\niter 3 err:0.026208926915836202 λ=-0.03227579276149921 - 0.02208846862836847im\niter 4 err:0.007172980379743359 λ=-0.05583493095814305 - 0.003087442900200613im\niter 5 err:0.006924911617556792 λ=-0.05401508521132263 + 0.001517986336058301im\niter 6 err:0.002090878656094346 λ=-0.05536501763852141 + 0.00024284078743963842im\niter 7 err:0.0006103719429985026 λ=-0.05575237680802954 - 0.00013474280139834488im\niter 8 err:0.0002665363571995074 λ=-0.05558344084437247 + 6.558335069789856e-6im\niter 9 err:0.023093036823993347 λ=-0.02304829345220316 + 0.0005911146839749534im\niter 10 err:1.092985097378946e-5 λ=-0.055653357185449566 - 2.575336159079228e-6im\niter 11 err:5.316449394914625e-7 λ=-0.05565515933487699 + 2.446717728666673e-7im\niter 12 err:0.016299715925824968 λ=0.023211712543947764 - 0.033813269858071315im\niter 13 err:4.899222816433482e-8 λ=-0.05565520569884035 - 2.0175841868490324e-8im\niter 14 err:4.320444084682331e-9 λ=-0.055655212526421895 + 1.2690665519371834e-9im\niter 15 err:7.639277885601529e-10 λ=-0.05565521363070881 + 3.971813908747728e-11im\niter 16 err:4.941632484271334e-11 λ=-0.055655213920101095 - 7.493472629149413e-12im\niter 17 err:0.010663980713333146 λ=0.008967322670902417 + 0.016345149953039387im\niter 18 err:3.2317477531099844e-12 λ=-0.05565521393097803 - 6.246051566770699e-13im\niter 19 err:2.3964655361108506e-13 λ=-0.05565521393184677 + 6.221189257479347e-14im\niter 20 err:1.1735483724254833e-13 λ=-0.055655213931828935 + 2.058434802154811e-15im\niter 21 err:8.164760090914088e-15 λ=-0.055655213931847865 + 7.498992677576017e-16im\n****** 1 converged to eigenvalue: -0.055655213931847865 + 7.498992677576017e-16im errmeasure:8.164760090914088e-15","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"The logging of the inner solver is controlled by the kwarg inner_logger, which follows the same framework as the standard NEP-PACK Logger. This produces very verbose output illustrating also the convergence of the inner solve:","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"julia> λ,v=nlar(nep,neigs=1,inner_solver_method=IARInnerSolver(),logger=1,inner_logger=1);\n\nUsing inner solver IARInnerSolver(1.0e-13, 80, :ones, false, NonlinearEigenproblems.NEPSolver.iar)\n-\n--\n---\n----\n-----\n------\n=------\n+-------\niter 1 err:0.06907648709827012 λ=-0.13302652304722704 + 0.0499583011875092im\n-\n--\n---\n----\n-----\n------\n=------\n+-------\niter 2 err:0.03702238592099922 λ=0.08696844790344242 + 0.010741310688729204im\n-\n--\n---\n----\n-----\n------\n-------\n=-------\n+=-------\niter 3 err:0.029408773621139236 λ=0.0076466477038438325 - 0.07172981749577159im\n-\n--\n---\n----\n-----\n------\n-------\n--------\n+--------\n...","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"Rayleigh functional computation, which corresponds to projection with p=1, is also handled with this framework.","category":"page"},{"location":"innersolvers/#Inner-solvers","page":"Projection","title":"Inner solvers","text":"","category":"section"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"The inner solvers inherit from InnerSolver. The following inner solvers are available by default.","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"NewtonInnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.NewtonInnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.NewtonInnerSolver","text":"struct NewtonInnerSolver\nfunction NewtonInnerSolver(;tol=1e-13,maxit=80,starting_vector=:Vk,\n                           newton_function=augnewton)\n\nUses a Newton-like method to solve the inner problem, with tolerance, and maximum number of iterations given by tol and maxit. The starting vector can be :ones, :randn, or :Vk. The value :Vk specifies the use of the outer NEP-solver keyword argument (Vk). This is typically the previous iterate in the outer method.\n\nThe kwarg newton_function, specifies a Function which is called. The type supports augnewton, newton, resinv quasinewton, newtonqr. In principle it can be any method which takes the same keyword arguments as these methods.\n\nSee also: InnerSolver, inner_solve\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"IARInnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.IARInnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.IARInnerSolver","text":"struct IARInnerSolver\nfunction IARInnerSolver(;tol=1e-13,maxit=80,\n           starting_vector=:ones,normalize_DEPs=:auto,\n           iar_function=iar)\n\nUses iar, tiar or iar_chebyshev to solve the inner problem, with tolerance, and maximum number of iterations given by tol and maxit. The starting vector can be :ones or :randn. The iar_function can be iar, tiar or iar_chebyshev (or any function taking the same parameters as input). normalize_DEPs determines if the we should carry out precomputation and make sure the projection of a DEP  is again a DEP (which can speed up performance). It can take the value true, false or :auto. :auto sets it to true if we use the iar_chebyshev solver.\n\nThe kwarg iar_function, specifies a Function which is called. Examples of functions are iar and iar_chebyshev. It can be any NEP-solver which takes the same keyword arguments as these methods.\n\nSee also: InnerSolver, inner_solve\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"IARChebInnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.IARChebInnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.IARChebInnerSolver","text":"function IARChebInnerSolver(;tol=1e-13,maxit=80,starting_vector=:ones,\n                            normalize_DEPs=true)\n\nUses iar_chebyshev to solve the inner problem. See IARInnerSolver for keyword argument documentation.\n\nSee also: IARInnerSolver, InnerSolver, inner_solve\n\n\n\n\n\n","category":"function"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"ContourBeynInnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.ContourBeynInnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.ContourBeynInnerSolver","text":"struct ContourBeynInnerSolver <: InnerSolver\nfunction ContourBeynInnerSolver(;tol=sqrt(eps(real(Float64))),\n                                radius=:auto,N=1000)\n\nUses contour_beyn to solve the inner problem, with radius and number of quadrature nodes, given by radius and n. If the variable radius is set to :auto, the integration radius will be automatically selected by using the eigenvalue approximations specified by the outer solver.\n\nSee also: InnerSolver, inner_solve\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"PolyeigInnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.PolyeigInnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.PolyeigInnerSolver","text":"struct PolyeigInnerSolver <: InnerSolver\nfunction PolyeigInnerSolver()\n\nSpecifies the use of polyeig to solve the inner problem. This is intended for NEPs of the type PEP.\n\nSee also: InnerSolver, inner_solve\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"SGIterInnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.SGIterInnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.SGIterInnerSolver","text":"struct SGIterInnerSolver <: InnerSolver\n\nUses sgiter to solve the inner problem.\n\nSee also: InnerSolver, inner_solve\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"NleigsInnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.NleigsInnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.NleigsInnerSolver","text":"struct NleigsInnerSolver <: InnerSolver\nfunction NleigsInnerSolver(;Σ= :auto,nodes =:auto, tol=1e-6 )\n\nUses nleigs to solve the inner problem, in the region Σ with shifts nodes and with tolerance tol. If the variable Σ is set to :auto, the region Σ will be set by using the eigenvalues approximations. See nleigs for description of parameters.\n\nSee also: InnerSolver, inner_solve\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"DefaultInnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.DefaultInnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.DefaultInnerSolver","text":"struct DefaultInnerSolver <: InnerSolver\n\nDispatches a version of inner_solve based on the type of the NEP provided. This function tries to automatically detect which solver is recommended.\n\nSee also: InnerSolver, inner_solve\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/#Inner-solvers:-Advanced-usage","page":"Projection","title":"Inner solvers: Advanced usage","text":"","category":"section"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"You can define your own inner solver by inheriting from InnerSolver and implementing the function inner_solve. Since the inner_solve obtains information from the solver via keyword arguments, you need to end your method signature with kwargs...).","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"InnerSolver","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.InnerSolver","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.InnerSolver","text":"abstract type InnerSolver\n\nStructs inheriting from this type are used to solve inner problems in an inner-outer iteration.\n\nThe InnerSolver objects are passed to the NEP-algorithms, which uses it to dispatch the correct version of the function inner_solve. Utilizes existing implementations of NEP-solvers and inner_solve acts as a wrapper to these.\n\nExample\n\nThere is a DefaultInnerSolver that dispatches an inner solver based on the provided NEP. However, this example shows how you can force nlar to use the IARInnerSolver for a PEP.\n\njulia> nep=nep_gallery(\"pep0\", 100);\njulia> λ,v = nlar(nep, inner_solver_method=NEPSolver.IARInnerSolver(), neigs=1, num_restart_ritz_vecs=1, maxit=70, tol=1e-8);\njulia> norm(compute_Mlincomb(nep,λ[1],vec(v)))\n8.68118417430353e-9\n\nSee also: inner_solve, DefaultInnerSolver, NewtonInnerSolver, PolyeigInnerSolver, IARInnerSolver, IARChebInnerSolver, SGIterInnerSolver, ContourBeynInnerSolver\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"inner_solve","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.inner_solve","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.inner_solve","text":"inner_solve(is::InnerSolver,T_arit,nep;kwargs...)\n\nSolves the projected linear problem with solver specied with is. This is to be used as an inner solver in an inner-outer iteration. T specifies which method to use. The most common choice is DefaultInnerSolver. The function returns (λv,V) where λv is an array of eigenvalues and V a matrix with corresponding vectors. The struct T_arit defines the arithmetics used in the outer iteration and should prefereably also be used in the inner iteration.\n\nDifferent inner_solve methods take different kwargs. These are standardized kwargs:\n\nneigs: Number of wanted eigenvalues (but less or more may be returned)\nσ: target specifying where eigenvalues\nλv, V: Vector/matrix of guesses to be used as starting values\nj: the jth eigenvalue in a min-max characterization\ntol: Termination tolarance for inner solver\ninner_logger: Determines how the inner solves are logged. See Logger for further references\n\n\n\n\n\n","category":"function"},{"location":"innersolvers/#Projection-2","page":"Projection","title":"Projection","text":"","category":"section"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"The NEP-PACK functionality for projected problems are represented by projection types. Normally, the projection is created by create_proj_NEP from a standard NEP. After creating a projected NEP, you can set the projection subspace (represented by the matrices V and W) using set_projectmatrices! or expand_projectmatrices!.","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"julia> A=[1 0 0; 0 1.0 0; 0 0 1]; B=[1 2 3; 3 3 3 ; 4 -1 -1.0];\njulia> nep=SPMF_NEP([A, B], [s->s, s->s^5]);\njulia> pnep=create_proj_NEP(nep);\njulia> W=[4 1 ; 6 1  ; 6.0 2]; V=[3 3;3 4.0;4.0 -1];\njulia> set_projectmatrices!(pnep,W,V); # modifies pnep\njulia> λ=3.0+1im;\njulia> W'*compute_Mder(nep,λ)*V\n2×2 Array{Complex{Float64},2}:\n -3366.0+92958.0im  -2238.0+61334.0im\n  -690.0+19290.0im   -513.0+13909.0im\njulia> compute_Mder(pnep,λ)\n2×2 Array{Complex{Float64},2}:\n -3366.0+92958.0im  -2238.0+61334.0im\n  -690.0+19290.0im   -513.0+13909.0im","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"Effectively, the Proj_NEP creates compute functions, which are designed to be as efficient as possible.","category":"page"},{"location":"innersolvers/#Projection-functions","page":"Projection","title":"Projection functions","text":"","category":"section"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"You can create a projected NEP with create_proj_NEP, and specify the projection space with set_projectmatrices! and expand_projectmatrices!.","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"create_proj_NEP","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPTypes.create_proj_NEP","page":"Projection","title":"NonlinearEigenproblems.NEPTypes.create_proj_NEP","text":"pnep=create_proj_NEP(orgnep::ProjectableNEP[,maxsize [,T]])\n\nCreate a NEP representing a projected problem N(λ)=W^HM(λ)V,  where the base NEP is represented by orgnep. The optional parameter maxsize::Int determines how large the projected problem can be and T is the Number type used for the projection matrices (default ComplexF64). These are needed for memory preallocation reasons. Use set_projectmatrices! and expand_projectmatrices!  to specify projection matrices V and W.\n\nExample:\n\nThe following example illustrates that a projection of a NEP is also a NEP and we can for instance call compute_Mder on it:\n\njulia> nep=nep_gallery(\"pep0\")\njulia> V=Matrix(1.0*I,size(nep,1),2);\njulia> W=Matrix(1.0*I,size(nep,1),2);\njulia> pnep=create_proj_NEP(nep);\njulia> set_projectmatrices!(pnep,W,V);\njulia> compute_Mder(pnep,3.0)\n2×2 Array{Complex{Float64},2}:\n  6.08082+0.0im  -5.47481+0.0im\n 0.986559+0.0im  -6.98165+0.0im\njulia> W'*compute_Mder(nep,3.0)*V  # Gives the same result\n2×2 Array{Float64,2}:\n 6.08082   -5.47481\n 0.986559  -6.98165\n\nIf you know that you will only use real projection matrices, you can specify this in at the creation:\n\njulia> pnep=create_proj_NEP(nep,2,Float64);\njulia> set_projectmatrices!(pnep,W,V);\njulia> compute_Mder(pnep,3.0)\n2×2 Array{Float64,2}:\n 6.08082   -5.47481\n 0.986559  -6.98165\n\n\n\n\n\n","category":"function"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"set_projectmatrices!","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPTypes.set_projectmatrices!","page":"Projection","title":"NonlinearEigenproblems.NEPTypes.set_projectmatrices!","text":"set_projectmatrices!(pnep::Proj_NEP,W,V)\n\nSet the projection matrices for the NEP to W and V, i.e., corresponding the NEP: N(λ)=W^HM(λ)V. See also create_proj_NEP.\n\nExample\n\nThis illustrates if W and V are vectors of ones, the projected problem becomes the sum of the rows and columns of the original NEP.\n\njulia> nep=nep_gallery(\"pep0\")\njulia> pnep=create_proj_NEP(nep);\njulia> V=ones(200,1);  W=ones(200,1);\njulia> set_projectmatrices!(pnep,W,V);\njulia> compute_Mder(pnep,0)\n1×1 Array{Complex{Float64},2}:\n 48.948104019482756 + 0.0im\njulia> sum(compute_Mder(nep,0),dims=[1,2])\n1×1 Array{Float64,2}:\n 48.948104019482955\n\n\n\n\n\n","category":"function"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"expand_projectmatrices!","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPTypes.expand_projectmatrices!","page":"Projection","title":"NonlinearEigenproblems.NEPTypes.expand_projectmatrices!","text":"expand_projectmatrices!(nep::Proj_SPMF_NEP, Wnew, Vnew)\n\nThe projected NEP is updated by adding the last column of Wnew and Vnew to the basis. Note that Wnew and Vnew contain also the \"old\" basis vectors. See also create_proj_NEP\n\nExample:\n\nIn the following example you see that the expanded projected problem has one row and column more, and the leading subblock is the same as the smaller projected NEP.\n\njulia> nep=nep_gallery(\"pep0\"); n=size(nep,1);\njulia> V=Matrix(1.0*I,n,2); W=Matrix(1.0*I,n,2);\njulia> pnep=create_proj_NEP(nep);\njulia> set_projectmatrices!(pnep,W,V);\njulia> compute_Mder(pnep,0)\n2×2 Array{Complex{Float64},2}:\n 0.679107+0.0im   -0.50376+0.0im\n 0.828413+0.0im  0.0646768+0.0im\njulia> Vnew=[V ones(n)]\njulia> Wnew=[W ones(n)]\njulia> expand_projectmatrices!(pnep,Wnew,Vnew);\njulia> compute_Mder(pnep,0)\n3×3 Array{Complex{Float64},2}:\n 0.679107+0.0im   -0.50376+0.0im  -12.1418+0.0im\n 0.828413+0.0im  0.0646768+0.0im   16.3126+0.0im\n -17.1619+0.0im   -10.1628+0.0im   48.9481+0.0im\n\n\n\n\n\n","category":"function"},{"location":"innersolvers/#Projection-types","page":"Projection","title":"Projection types","text":"","category":"section"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"NEPs for which this projection can be computed inherit from ProjectableNEP.","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"ProjectableNEP","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPTypes.ProjectableNEP","page":"Projection","title":"NonlinearEigenproblems.NEPTypes.ProjectableNEP","text":"abstract ProjectableNEP <: NEP\n\nA ProjectableNEP is a NEP which can be projected, i.e., one can construct the problem W*M(λ)Vw=0 with the Proj_NEP. A NEP which is of this must have the function create_proj_NEP(orgnep::ProjectableNEP) implemented. This function must return a Proj_NEP.\n\nSee also: set_projectmatrices!.\n\nExample:\n\njulia> nep=nep_gallery(\"dep0\");\njulia> typeof(nep)\nDEP{Float64,Array{Float64,2}}\njulia> isa(nep,ProjectableNEP)\ntrue\njulia> projnep=create_proj_NEP(nep);\njulia> e1 = Matrix(1.0*I,size(nep,1),1);\njulia> set_projectmatrices!(projnep,e1,e1);\njulia> compute_Mder(nep,3.0)[1,1]\n-2.942777908030041\njulia> compute_Mder(projnep,3.0)\n1×1 Array{Complex{Float64},2}:\n -2.942777908030041 + 0.0im\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"The result of the projection is represented in a Proj_NEP.","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"Proj_NEP","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPTypes.Proj_NEP","page":"Projection","title":"NonlinearEigenproblems.NEPTypes.Proj_NEP","text":"abstract type Proj_NEP <: NEP\n\nProj_NEP represents a projected NEP. The projection is defined as the NEP\n\nN(λ)=W^HM(λ)V\n\nwhere M(λ) is a base NEP and W and V rectangular matrices representing a basis of the projection spaces. Instances are created with create_proj_NEP. See create_proj_NEP for examples.\n\nAny Proj_NEP needs to implement two functions to manipulate the projection:\n\nset_projectmatrices!: Set matrices W and V\nexpand_projectmatrices!: Effectively expand the matrices W and V with one column.\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"One explicit instance is the Proj_SPMF_NEP.","category":"page"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"Proj_SPMF_NEP","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPTypes.Proj_SPMF_NEP","page":"Projection","title":"NonlinearEigenproblems.NEPTypes.Proj_SPMF_NEP","text":"struct Proj_SPMF_NEP <: Proj_NEP\n\nThis type represents the (generic) way to project NEPs which are AbstractSPMF. See examples in create_proj_NEP.\n\n\n\n\n\n","category":"type"},{"location":"innersolvers/#Rayleigh-functional-computation","page":"Projection","title":"Rayleigh functional computation","text":"","category":"section"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"compute_rf","category":"page"},{"location":"innersolvers/#NonlinearEigenproblems.NEPSolver.compute_rf","page":"Projection","title":"NonlinearEigenproblems.NEPSolver.compute_rf","text":"compute_rf(eltype::Type,nep::NEP,x,inner_solver::InnerSolver;\n           y=x, target=zero(T), λ=target,TOL=eps(real(T))*1e3,max_iter=10)\n\nComputes the Rayleigh functional of the nep, i.e., computes a vector Λ of values λ such that y^TM(λ)x=0, using the procedure specified in inner_solver. The default behaviour consists of a scalar valued Newton-iteration, and the returned vector has only one element.\n\nThe given eltype<:Number is the type of the returned vector.\n\nExample\n\nThis uses iar to solve the (scalar) nonlinear problem.\n\njulia> nep=nep_gallery(\"dep0\");\njulia> x=ones(size(nep,1));\njulia> s=compute_rf(ComplexF64,nep,x,IARInnerSolver())[1] # Take just first element\n-1.186623627962043 - 1.5085094961223182im\njulia> x'*compute_Mlincomb(nep,s,x)\n-8.881784197001252e-16 + 1.0880185641326534e-14im\n\n\n\n\n\n","category":"function"},{"location":"innersolvers/","page":"Projection","title":"Projection","text":"(Image: To the top)","category":"page"},{"location":"tutorial_newmethod/#Tutorial:-Implementing-your-own-method","page":"Tutorial 10 (New solver)","title":"Tutorial: Implementing your own method","text":"","category":"section"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"Although we try to provide state-of-the-art algorithms in NEP-PACK, you may want to implement a solver which is not available in NEP-PACK. By using the NEP-PACK data types and structures when you implement your solver, you can make your life easier in several ways. You do not need to know the internals of NEP-PACK. Correct usage will give you access to many applications, helper functionality to combine with, and you will have to possibility to compare your method with other solvers. We now illustrate how to implement your own NEP-solver.","category":"page"},{"location":"tutorial_newmethod/#Halley's-method","page":"Tutorial 10 (New solver)","title":"Halley's method","text":"","category":"section"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"Halley's method for root-finding of nonlinear scalar equations has fast local convergence - even faster than Newton's method in terms convergence order, and often faster in terms of number of iterations. A NEP can be formulated as a root-finding problem since a solution will always satisfy","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"f(λ)=det(M(λ))=0","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"The application of Halley's method to this nonlinear scalar equation will serve as an example solver, although it does, to our knowledge, not lead to a competitive algorithm. Halley's method for the root-finding problem is defined by the iteration","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"λ_k+1=λ_k-frac2f(λ_k)f(λ_k)2(f(λ_k))^2-f(λ_k)f(λ_k)","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"There are formulas for the derivatives of the determinant, we will here for simplicity just use finite difference approximation to estimate the derivatives, i.e.,","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":" f(λ)approx fracf(λ+δ)-f(λ-δ)2δ","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":" f(λ)approx fracf(λ+δ)-2f(λ)+f(λ-δ)δ^2","category":"page"},{"location":"tutorial_newmethod/#Implementation-in-NEP-PACK-(preliminary-version)","page":"Tutorial 10 (New solver)","title":"Implementation in NEP-PACK (preliminary version)","text":"","category":"section"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"Let us first define our solver function and introduce the function whose roots we wish to find. The matrix M(λ) is obtained by a call to the compute_Mder-function.","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"using NonlinearEigenproblems\nfunction halley(nep::NEP;λ=0.0,δ=sqrt(eps()),maxit=100,tol=eps()*100)\n   f=s-> det(compute_Mder(nep,s)); # The objective function\n   # More code here\nend","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"The main loop (which should go in # More code here) can be implemented, in a way that does not involve many function evaluations, as follows:","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"   for i=1:maxit\n       fλ=f(λ)\n       fλp=f(λ+δ)\n       fλm=f(λ-δ)\n       fp=(fλp-fλm)/(2δ)\n       fpp=(fλp-2*fλ+fλm)/(δ^2)\n       Δλ=2*fλ*fp/(2*fp^2-fλ*fpp);\n       λ=λ-Δλ;\n       @show (i,λ)\n       if (abs(Δλ)<tol)\n          return λ\n       end\n   end","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"Let us now test the code on a benchmark problem:","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"julia> nep=nep_gallery(\"dep0\");\njulia> λ=halley(nep)\n(i, λ) = (1, -0.13876571372157542)\n(i, λ) = (2,  0.15938372556136426)\n(i, λ) = (3, -0.15955391446207692)\n(i, λ) = (4, -0.15955391823299248)","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"Clearly, the algorithm terminates after 4 iterations. We can verify that this is actually a solution easily if we also have an approximate eigenvector. An eigenvector can be computed/estimated by essentially one step of inverse iteration, on the matrix M(λ):","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"julia> x=normalize(compute_Mder(nep,λ)\\ones(size(nep,1)))\n5-element Array{Float64,1}:\n  0.14358324743994907\n  0.9731847884093298\n -0.12527093093249475\n  0.031821422867456914\n  0.12485915894832478","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"The residual norm  M(λ)x does indeed become almost zero so it seems we have a solution:","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"julia> norm(compute_Mlincomb(nep,λ,x))\n7.093661646042283e-16","category":"page"},{"location":"tutorial_newmethod/#Implementation-in-NEP-PACK-(full-version)","page":"Tutorial 10 (New solver)","title":"Implementation in NEP-PACK (full version)","text":"","category":"section"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"In the following we illustrate a more advanced usage of the NEP-PACK method development: NEP-PACKs logging facility  and error estimation. See Logger and Errmeasure. This gives access to other ways to measure error as well as a logging and inspection of error history in a way that is the same for all solvers and simplifies comparisons.","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"using NonlinearEigenproblems, LinearAlgebra, Plots\nfunction halley(nep::NEP;λ=0.0,δ=sqrt(eps()),maxit=100,\n                tol=eps()*100,logger=0,\n                errmeasure = DefaultErrmeasure(nep))\n    # Setup the logger.\n    @parse_logger_param!(logger);\n\n    n=size(nep,1);\n    f=s-> det(compute_Mder(nep,s)); # The objective function\n\n\n    for i=1:maxit\n        fλ=f(λ)\n        fλp=f(λ+δ)\n        fλm=f(λ-δ)\n        fp=(fλp-fλm)/(2δ)\n        fpp=(fλp-2*fλ+fλm)/(δ^2)\n        Δλ=2*fλ*fp/(2*fp^2-fλ*fpp);\n        λ=λ-Δλ;\n        # Compute an eigenvector. This will not work if the\n        # eigenvector is orthogonal to ones(n)\n        x=normalize(compute_Mder(nep,λ)\\ones(n));\n        err=estimate_error(errmeasure,λ,x)  # Estimate the error\n        push_iteration_info!(logger,i; λ=λ,err=err) # Put it into the log\n        if (err<tol)\n            return (λ,x)\n        end\n    end\nend","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"We can now run our new method using with a logger=1 keyword argument so we get the standardized output of iteration info:","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"julia> (λ,x)=halley(nep,logger=1);\niter 1 err:0.010384216303530201 λ=-0.13876571372157542\niter 2 err:8.082978338039669e-5 λ=-0.15938372556136426\niter 3 err:1.7901681647471861e-9 λ=-0.15955391446207692\niter 4 err:1.0389976569127096e-16 λ=-0.15955391823299248\njulia> norm(compute_Mlincomb(nep,λ,x))\n7.093661646042283e-16","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"The use of the NEP-PACK logging functionality makes it very easy to visualize the error. If you now want to plot the error history, you can use the ErrorLogger:","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"julia> mylogger=ErrorLogger()\njulia> (λ,x)=halley(nep,logger=mylogger);\njulia> plot(mylogger.errs[1:10,1],yaxis=:log)","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"We clearly observe the superlinear convergence:","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"using Gadfly # hide\nz=[ 0.08492602120772309   # hide\n        0.07450867012944977 # hide\n        0.032639292900081246 # hide\n        0.00281602165251169 # hide\n        1.1025990567599428e-5 # hide\n        1.0638098128402615e-10 # hide\n        4.942402279980973e-17 # hide\n       ]; # hide\nplot(y=z, Scale.y_log10(), Geom.line) # hide","category":"page"},{"location":"tutorial_newmethod/","page":"Tutorial 10 (New solver)","title":"Tutorial 10 (New solver)","text":"(Image: To the top)","category":"page"},{"location":"hydrotutorial/#Tutorial:-Stability-of-parallel-shear-flows","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial: Stability of parallel shear flows","text":"","category":"section"},{"location":"hydrotutorial/#Background","page":"Tutorial 12 (Orr–Somerfeld)","title":"Background","text":"","category":"section"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"Stability analysis of flows is a very important problem in fluid mechanics.  Linearizing the Navier–Stokes equations around the mean flow and then eliminating pressure gives us the Orr–Sommerfeld and Squire equations, which are a system of fourth order PDEs describing the dynamics:","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"left(Big(dfracpartial partial t+Udfracpartial partial xBig)nabla^2-Udfracpartial partial x-frac1Renabla^4right)v = 0\nleft(dfracpartial partial t+Udfracpartial partial x-frac1Renabla^2right)eta = -Udfracpartial vpartial z","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"More precisely, these equations stem from modeling using a mean base laminar flow overlineU = beginpmatrixU(y) 0 0endpmatrix and the perturbation u = beginpmatrixu v wendpmatrix. The normal vorticity is denoted eta.","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"This is a text-book model for fluid flows. The model is often used to study stability by making a plane wave ansatz and a transformation, and subsequently rewriting the discretized problem as a large standard eigenvalue problem, see Chapter 7, Stability and Transition in Shear Flows, Schmid, Peter J., Henningson, Dan S. We will here show that the plane wave ansatz directly leads to a NEP, which can be solved with methods in NEP-PACK without any additional transformations. We reproduce computational results in the above reference.","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"We thank Miguel Beneitez and Prabal Negi, Department of Mechanics, KTH for the valuable discussions and the discretization code.","category":"page"},{"location":"hydrotutorial/#Formulation-as-a-nonlinear-eigenvalue-problem","page":"Tutorial 12 (Orr–Somerfeld)","title":"Formulation as a nonlinear eigenvalue problem","text":"","category":"section"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"To study stability we use the plane wave perturbations ansatz","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"v(xyzt) = tildev(y)exp(i(alpha x+beta z-omega t))\neta(xyzt) = tildeeta(y)exp(i(alpha x+beta z-omega t))","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"which transforms the system to","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"left((-iomega+ialpha U)(mathcalD^2-alpha^2-beta^2)-ialpha U-frac1Re(mathcalD^2-alpha^2-beta^2)^2right)tildev = 0\nleft((-iomega+ialpha U)-frac1Re(mathcalD^2-alpha^2-beta^2)right)eta = -ibeta Utildev","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"where mathcalD denotes the 1-D differential operator fracpartial partial y. In this example, we consider the boundary conditions tildev = mathcalDtildev = tildeeta = 0. We assume that beta and omega are given and we wish to solve for the eigenvalue alphainmathbbC.","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"This is usually done by using a transformation of the form","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"beginpmatrixtildev tildeetaendpmatrix = beginpmatrixtildeV tildeEendpmatrixexp(-alpha y)","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"which reduces the power of alpha from four to two. The problem is then discretized and solved as a quadratic eigenvalue problem. See Chapter 7 in Schmid–Henningson for details.  ","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"Rather than using the transformation approach described in the book of Schmid–Henningson, we simply discretize mathcalD to D (using a suitable numerical discretization) which leads to a polynomial eigenvalue problem of fourth order.","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"We define diagonal matrices U_0, U_1 and U_2  as follows","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"U_0 = diag(U(y_0)U(y_1)ldotsU(y_n))\nU_1 = diag(U(y_0)U(y_1)ldotsU(y_n))\nU_2 = diag(U(y_0)U(y_1)ldotsU(y_n))","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"where y_i_i=1ldotsn denotes the y-coordinates of the n grid points used for discretization. The discretized problem, after expanding the powers, gives","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"left-fracIRealpha^4-iU_0alpha^3+left(frac2D^2Re+left(iomega-\nfrac2beta^2Reright)Iright)alpha^2right+\nleftleft(iU_0(D^2-beta^2I)-U_2right)alpha +Big(frac2beta^2D^2Re-fracD^4Re-fracbeta^4IRe+iomega(beta^2I-D^2)Big)righttildev = 0\nibeta U_1tildev+leftfracIRealpha^2 + iU_0 alpha +left(left(fracbeta^2Re-iomegaright)I-fracD^2Reright)righttildeeta = 0","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"This can be be formulated as a polynomial eigenvalue problem","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"M(lambda) = A_0+A_1lambda+A_2lambda^2+A_3lambda^3+A_4lambda^4","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"and the matrices A_0ldotsA_4 are given by","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"A_0 = beginpmatrixfrac2beta^2D^2Re-fracD^4Re-fracbeta^4IRe+iomega(beta^2I-D^2) 0 ibeta U_1left(fracbeta^2Re-iomegaright)I-fracD^2Reendpmatrix\nA_1 = beginpmatrixiU_0(D^2-beta^2I)-U_2 00 iU_0endpmatrix\nA_2 = beginpmatrixfrac2D^2Re+left(iomega-\nfrac2beta^2Reright)I 00 fracIReendpmatrix\nA_3 = beginpmatrix-iU_0 00 0endpmatrix\nA_4 = beginpmatrix-fracIRe 00 0endpmatrix","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"The eigenvector is given by beginpmatrixtildev^T  tildeetaendpmatrix^T","category":"page"},{"location":"hydrotutorial/#Problem-setup-in-NEP-PACK","page":"Tutorial 12 (Orr–Somerfeld)","title":"Problem setup in NEP-PACK","text":"","category":"section"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"The tutorial uses the helper-functions chebdif and cheb4c, which are provided in cheb4c.jl and chebdif.jl.","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"using NonlinearEigenproblems, Plots, ToeplitzMatrices;\ninclude(\"cheb4c.jl\");\ninclude(\"chebdif.jl\");","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"We begin by initializing the parameters to the values used to generate the data in Table 7.1 in Schmid–Henningson.","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"N = 256;      # Number of interior points\nRe = 2000;    # Reynolds number\nω  = 0.3;     # Input frequency\nβ  = 0.0;     # Spanwise wavenumber","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"To set up the matrices A_i, we need the discretized matrices corresponding to the operators mathcalD^2 and mathcalD^4. Here, we do this using Chebyshev nodes.","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"# Çhebyshev discretization of differential operators\nyF,DM = chebdif(N+2, 4);    \nD2 = DM[2:N+1,2:N+1,2];              #D^2\nyF,D4 = cheb4c(N+2);                 #D^4\n\n# The base flow for Poiseuille plane flow\nU   = 1 .-yF.^2;\nUp  = -2*yF;\nUpp = -2;\n\neye = Matrix{Float64}(I, N, N);  ","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"We can now set up the coefficient matrices and create a corresponding PEP object.","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"A4 = [-eye/Re zeros(N,N);zeros(N,N) zeros(N,N)];\nA3 = [-1im*diagm(0 => U) zeros(N,N);zeros(N,N) zeros(N,N)];\nA2 = [(1im*ω-2β^2/Re)*eye+2D2/Re zeros(N,N);zeros(N,N) eye/Re];\nA1 = [1im*(diagm(0 => U)*(D2-eye*β^2)-Upp*eye) zeros(N,N);zeros(N,N) 1im*diagm(0=>U)];\nA0 = [2β^2*D2/Re-D4/Re-β^4*eye/Re+1im*ω*(β^2*eye-D2) zeros(N,N);1im*β*diagm(0 => Up) (-1im*ω+β^2/Re)*eye-D2/Re];\nnep = PEP([A0,A1,A2,A3,A4]); #Create a PEP object","category":"page"},{"location":"hydrotutorial/#Solving-with-NEP-PACK","page":"Tutorial 12 (Orr–Somerfeld)","title":"Solving with NEP-PACK","text":"","category":"section"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"Because of poorly scaled coefficient matrices, direct application of NEP-PACK's solvers on this problem is inadequate. We note that the norm of the coefficient matrices are:","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"julia> norm.(get_Av(nep))\n5-element Array{Float64,1}:\n      8.37194982854379e13\n 473949.06740743306      \n 303285.4108872535       \n      9.817076958035932  \n      0.008","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"Fortunally we can get around this issue by scaling the PEP with NEP-PACK's shift_and_scale , and solving the scaled problem T(lambda) = M(100lambda) instead.","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"sc=100;\nnep1 = shift_and_scale(nep,scale=sc);\nmult_scale = norm(nep1.A[end]);\nnep2 = PEP(nep1.A ./ mult_scale);","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"The scaled PEP has much better scaled coefficient matrices.","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"julia> norm.(get_Av(nep2))\n5-element Array{Float64,1}:\n    1.0464937285679738e8\n   59.24363342592913    \n 3791.0676360906696     \n   12.271346197544913   \n    1.0","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"In this example, we are interested in computing several eigenvalues and our region of interest for the spectrum is in the first quadrant. We use the Tensor Infinite Arnoldi (TIAR) method implemented in tiar. The method is called twice with different shifts σ.","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"λ1,v1 = tiar(nep2,σ=0.006,v=ones(size(nep,1)),neigs=10,maxit=200,tol=1e-14);\nλ2,v2 = tiar(nep2,σ=0.005+0.005im,v=ones(size(nep,1)),neigs=10,maxit=200,tol=1e-14);\nλtotal = [λ1;λ2];","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"The computed eigenvalues are scaled back to get the eigenvalues of the original problem.","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":" julia> λ_orig = sc*λtotal\n20-element Array{Complex{Float64},1}:\n  0.3765784040323032 + 0.09959915134763689im\n 0.30865495875240445 + 0.008960297181538185im\n  0.4087137042139992 + 0.15906877547743775im\n  0.9787481874161135 + 0.0443939782417711im  \n  0.3430534698620533 + 0.049837687199345705im\n -0.2863097014631293 - 0.9011417554715162im  \n  0.6116671743160434 + 0.14049254864376023im\n 0.40933722321954447 + 0.15820580776369225im\n 0.43950860634751715 + 0.22808195062035772im\n 0.37687009160849716 + 0.09924325053688597im\n 0.47944942696208637 + 0.40059913080096726im\n  0.4934801111510124 + 0.520295324777746im   \n   0.496596553706975 + 0.480303769976205im   \n 0.49307795048742775 + 0.6085434637464817im  \n  0.5095613980300516 + 0.6639488620533516im  \n  0.4998069928360967 + 0.3870365082453997im  \n  0.4861657916302239 + 0.45751028495939855im\n  0.4766598864386299 + 0.5557787925858408im  \n  0.4684227095574837 + 0.4353215518427161im  \n  0.5014319544500476 + 0.5889845608687214im  ","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"The computed eigenvalues in the first quadrant can be plotted by:","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"julia> plot(real.(λ_orig),imag.(λ_orig),seriestype=:scatter,xaxis=[0.2,1.05],yaxis=[0,0.8])","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"The resulting plot is:","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"<br>\n<img src=\"https://nep-pack.github.io/NonlinearEigenproblems.jl/eigvals.png\" height=450>","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"This is in agreement with Figure 7.2 from Schmid–Henningson for the eigenvalues in the first quadrant.","category":"page"},{"location":"hydrotutorial/","page":"Tutorial 12 (Orr–Somerfeld)","title":"Tutorial 12 (Orr–Somerfeld)","text":"<br>\n<img src=\"https://nep-pack.github.io/NonlinearEigenproblems.jl/henningson.png\" height=450>","category":"page"},{"location":"compute_functions/#Compute-functions","page":"Compute functions","title":"Compute functions","text":"","category":"section"},{"location":"compute_functions/","page":"Compute functions","title":"Compute functions","text":"The nonlinear eigenvalue problems in NEP-PACK are defined by the data stored in the corresponding NEP-class. The advised way NEP-solvers access the data is to do it through three main functions, which take the NEP-object as input.","category":"page"},{"location":"compute_functions/","page":"Compute functions","title":"Compute functions","text":"compute_Mder: Computes a given derivative of the matrix function M(λ).\ncompute_Mlincomb (or compute_Mlincomb!, with same documentation): Computes a linear combination of derivatives M(λ)\ncompute_MM: Computes the block residual.","category":"page"},{"location":"compute_functions/","page":"Compute functions","title":"Compute functions","text":"The choice of these functions as the fundamental way to access a NEP is a balancing between what applications can provide and NEP-solvers need.","category":"page"},{"location":"compute_functions/","page":"Compute functions","title":"Compute functions","text":"A user who needs a new class of NEPs (which is not available in among the standard types) is advised to use the helper functions Mder_NEP and/or Mder_Mlincomb_NEP rather than reimplementing the compute-functions, since the helper types are more user friendly. Implementation of your own NEP-type is only advised if needed for efficiency reasons.","category":"page"},{"location":"compute_functions/","page":"Compute functions","title":"Compute functions","text":"tip: Tip\nExamples of usage of Mder_NEP and/or Mder_Mlincomb_NEP are available in tutorials on boundary element method, python, matlab, and fortran.","category":"page"},{"location":"compute_functions/","page":"Compute functions","title":"Compute functions","text":"As a NEP-solver developer, compute_Mlincomb-calls are preferred over compute_Mder-calls, for the same reasons that algorithms that only require matrix vector products can be easier to use in a given application than an iterative algorithm using only matrix vector products. It is in general also more efficient although they produce the same result up to round-off errors:","category":"page"},{"location":"compute_functions/","page":"Compute functions","title":"Compute functions","text":"julia> using BenchmarkTools;\njulia> n=1000; p=10;\njulia> nep=DEP([randn(n,n), randn(n,n)];\njulia> V=randn(n,p);\njulia> @btime compute_Mlincomb(nep,1.0,V);\n  478.316 μs (19 allocations: 80.78 KiB)\njulia> @btime for k=1:p; z[:]+=compute_Mder(nep,1.0,k)*V[:,k]; end\n  78.510 ms (183 allocations: 465.71 MiB)","category":"page"},{"location":"compute_functions/","page":"Compute functions","title":"Compute functions","text":"The compute_Mlincomb-function exist in two variants, where compute_Mlincomb! may modify the V-matrix, but in general require less memory allocations.","category":"page"},{"location":"compute_functions/","page":"Compute functions","title":"Compute functions","text":"For a type where only compute_Mder is implemented, the compute_Mlincomb-functionality can be provided by delegating using the function compute_Mlincomb_from_Mder, such that methods which require compute_Mlincomb can be used.","category":"page"},{"location":"compute_functions/#Compute-functions-documentation","page":"Compute functions","title":"Compute-functions documentation","text":"","category":"section"},{"location":"compute_functions/","page":"Compute functions","title":"Compute functions","text":"compute_Mder","category":"page"},{"location":"compute_functions/#NonlinearEigenproblems.NEPCore.compute_Mder","page":"Compute functions","title":"NonlinearEigenproblems.NEPCore.compute_Mder","text":"compute_Mder(nep::NEP,λ::Number [,i::Integer=0])\n\nComputes the ith derivative of nep evaluated in λ.\n\nExample\n\nThis example shows that compute_Mder(nep,λ,1) gives the first derivative.\n\njulia> nep=nep_gallery(\"dep0\");\njulia> ϵ=1e-5; λ=2.25;\njulia> Aminus=compute_Mder(nep,λ-ϵ);\njulia> Aplus=compute_Mder(nep,λ+ϵ);\njulia> opnorm((Aplus-Aminus)/(2ϵ)-compute_Mder(nep,λ,1))\n1.8783432885257602e-11\n\n\n\n\n\n","category":"function"},{"location":"compute_functions/","page":"Compute functions","title":"Compute functions","text":"compute_Mlincomb","category":"page"},{"location":"compute_functions/#NonlinearEigenproblems.NEPCore.compute_Mlincomb","page":"Compute functions","title":"NonlinearEigenproblems.NEPCore.compute_Mlincomb","text":"compute_Mlincomb(nep::NEP,λ::Number,V, a::Vector=ones(size(V,2)), startder=0)\ncompute_Mlincomb!(nep::NEP,λ::Number,V, a::Vector=ones(size(V,2)), startder=0)\n\nComputes the linear combination of derivatives\nΣ_i a_i M^(i)(λ) v_i starting from derivative startder. The function compute_Mlincomb! does the same but may modify the V matrix/array.\n\nExample\n\nThis example shows that compute_Mder gives a result consistent with compute_Mlincomb. Note that compute_Mlincomb is in general faster since no matrix needs to be constructed.\n\njulia> nep=nep_gallery(\"dep0\");\njulia> v=ones(size(nep,1)); λ=-1+1im;\njulia> norm(compute_Mder(nep,λ,1)*v-compute_Mlincomb(nep,λ,hcat(v,v),[0,1]))\n0.0\n\n\n\n\n\ncompute_Mlincomb(nep::NEP,λ::Number,V,a::Array,startder::Integer)\n\nComputes linear combination starting with derivative startder, i.e., Σ_i a_i M^(i+startder)(λ) v_i\n\nThe default implementation of this can be slow. Overload for specific NEP if you want efficiency, e.g., in  augnewton, iar, and others.\n\n\n\n\n\n","category":"function"},{"location":"compute_functions/","page":"Compute functions","title":"Compute functions","text":"compute_MM","category":"page"},{"location":"compute_functions/#NonlinearEigenproblems.NEPCore.compute_MM","page":"Compute functions","title":"NonlinearEigenproblems.NEPCore.compute_MM","text":"compute_MM(nep::NEP,S,V)\n\nComputes the sum Σ_i M_i V f_i(S) for a NEP, where S and V are matrices, and the NEP satisfies M(λ)=Σ_i M_i f_i(λ).\n\nExample\n\nThis example shows that for diagonal S, the result of compute_MM can also be computed with compute_Mlincomb\n\njulia> nep=nep_gallery(\"dep0\");\njulia> D=diagm(0 => [1,2])\n2×2 Array{Int64,2}:\n 1  0\n 0  2\njulia> V=ones(size(nep,1),2);\njulia> W=compute_MM(nep,D,V);\njulia> norm(W[:,1]-compute_Mlincomb(nep,D[1,1],V[:,1]))\n0.0\njulia> norm(W[:,2]-compute_Mlincomb(nep,D[2,2],V[:,2]))\n4.440892098500626e-16\n\nReference\n\nProperties of the quantity Σ_i M_i V f_i(S) for non-polynomial nonlinear eigenvalue problems were extensively used in:\n\nD. Kressner A block Newton method for nonlinear eigenvalue problems, Numer. Math., 114 (2) (2009), pp. 355-372\nC. Effenberger, Robust solution methods for nonlinear eigenvalue problems, PhD thesis, 2013, EPF Lausanne\n\n\n\n\n\n","category":"function"},{"location":"compute_functions/#Type-helpers","page":"Compute functions","title":"Type helpers","text":"","category":"section"},{"location":"compute_functions/","page":"Compute functions","title":"Compute functions","text":"Mder_NEP\nMder_Mlincomb_NEP","category":"page"},{"location":"compute_functions/#NonlinearEigenproblems.NEPTypes.Mder_NEP","page":"Compute functions","title":"NonlinearEigenproblems.NEPTypes.Mder_NEP","text":"Mder_NEP(n,Mder_fun; maxder=max)\n\nCreates a NEP from its compute_Mder function defined by the function handle Mder_fun. The Mder_fun(λ,der) takes two parameters a scalar λ::Number, derivative number  der. The size n::Int must also be specified. The function Mder_fun(λ,der) should return the n x n matrix corresponding to the  derth derivatve. If only a limited number of derivatives are available, maxder should be set, e.g., if not derivatives are implemented, set maxder=0. The function compute_Mlicomb is automatically available by (delegation) to compute_Mlincomb_from_Mder.\n\nNote: This is a convenience function it is not recommended for high performance computations, since, e.g., it will not maintain type stability.\n\nExample\n\nThe following example defines a linear eigenvalue problem A0+λA1 defined in an external function.\n\njulia> using LinearAlgebra; # For the I function\njulia> function my_Mder(s,der)\n    A0=ones(Float64,3,3)-I; A0[1,1]=-1;\n    A1=ones(Float64,3,3)*3; A1[2,3]=0;\n    if (der==0)\n       return A0+A1*s;\n    elseif (der==1)\n       return A1;\n    else\n       return zero(A0);\n    end\nend\njulia> nep=Mder_NEP(3,my_Mder);\njulia> (λ,v)=augnewton(nep,v=ones(3));\njulia> norm(compute_Mder(nep,λ)*v)\n5.551115123125783e-17\n\n\n\n\n\n","category":"function"},{"location":"compute_functions/#NonlinearEigenproblems.NEPTypes.Mder_Mlincomb_NEP","page":"Compute functions","title":"NonlinearEigenproblems.NEPTypes.Mder_Mlincomb_NEP","text":"Mder_Mlincomb_NEP(n,Mder_fun, [maxder_Mder,] Mlincomb_fun, [maxder_Mlincomb])\n\nCreates a NEP from its compute_Mder and compute_Mlincombfunctions  defined by the function handles Mder_fun and Mlincomb_fun. The Mlincomb_fun(λ,X) takes two parameters a scalar λ::Number and a matrix X.  The size n::Int must also be specified. The function Mlincomb_fun(λ,X) should return a vector corresponding of the linear combination of derivatives multiplied with the vectors in X. If only a limited number of derivatives are implemented, maxder_Mder or maxder_Mlincomb should be set, e.g., if not derivatives are implemented, set maxder=0.\n\nSee also Mder_NEP.\n\nNote: This is a convenience function it is not recommended for high performance computations, since, e.g., it will not maintain type stability.\n\nExample\n\nThe following example defines a linear eigenvalue problem A0+λA1 defined in an external function.\n\njulia> using LinearAlgebra; # For the I function\njulia> function my_Mder(s,der)\n    A0=ones(Float64,3,3)-I; A0[1,1]=-1;\n    A1=ones(Float64,3,3)*3; A1[2,3]=0;\n    if (der==0)\n       return A0+A1*s;\n    elseif (der==1)\n       return A1;\n    else\n       return zero(A0);\n    end\nend\njulia> function my_Mlincomb(s,X) # Compute linear comb of derivatives\n    A0=ones(Float64,3,3)-I; A0[1,1]=-1;\n    A1=ones(Float64,3,3)*3; A1[2,3]=0;\n    if (size(X,2) <= 1)\n       return A0*X[:,1]+s*A1*X[:,1]\n    else # This means: size(X,2) => 2\n       return A0*X[:,1]+A1*(s*X[:,1]+X[:,2]);\n    end\nend\njulia> nep=Mder_Mlincomb_NEP(3,my_Mder,my_Mlincomb);\njulia> (λ,v)=augnewton(nep,v=[1.0; 2.3; 0.0])\njulia> norm(compute_Mder(nep,λ)*v)\n6.798699777552591e-17\n\n\n\n\n\n","category":"type"},{"location":"compute_functions/","page":"Compute functions","title":"Compute functions","text":"compute_Mlincomb_from_Mder","category":"page"},{"location":"compute_functions/#NonlinearEigenproblems.NEPCore.compute_Mlincomb_from_Mder","page":"Compute functions","title":"NonlinearEigenproblems.NEPCore.compute_Mlincomb_from_Mder","text":"compute_Mlincomb_from_Mder(nep::NEP,λ::Number,V,a)\n\nThe function computes Mlincomb by a call to compute_Mder. This function is slow since it requires the construction of the matrices. Usage normally by overloading in this way\n\n    compute_Mlincomb(nep::MyNEP,λ::Number,V,a)=compute_Mlincomb_from_Mder(nep,λ,V,a)\n\n\n\n\n\n","category":"function"},{"location":"compute_functions/","page":"Compute functions","title":"Compute functions","text":"compute_Mlincomb_from_MM","category":"page"},{"location":"compute_functions/#NonlinearEigenproblems.NEPCore.compute_Mlincomb_from_MM","page":"Compute functions","title":"NonlinearEigenproblems.NEPCore.compute_Mlincomb_from_MM","text":"compute_Mlincomb_from_MM(nep::NEP,λ::Number,V,a)\n\nThis function provides a compute_Mlincomb-function call  by invoking a call to compute_MM. The underlying mathematical relationship  is described in github issue #2 and #3.\n\nThe standard usage is by the following command:\n\ncompute_Mlincomb(nep::MyNEP,λ::Number,V,a)=compute_Mlincomb_from_MM(nep,λ,V,a)\n\n\n\n\n\n","category":"function"},{"location":"#NEP-PACK","page":"Introduction","title":"NEP-PACK","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"NEP-PACK is a package with implementations of methods to solve and to manipulate nonlinear eigenvalue problems of the type: Find (λv)inmathbbCtimesmathbbC^n such that","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"M(λ)v=0","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"and vneq 0.","category":"page"},{"location":"#Getting-started","page":"Introduction","title":"Getting started","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Install it as a registered  package in Julia's REPL package mode by typing ] add Nonline...:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> ]\n(v1.0) pkg> add NonlinearEigenproblems","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Then we can start to load the NEP-PACK package","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> using NonlinearEigenproblems","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"As a first example we will solve the NEP associated with the matrix polynomial","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"M(λ)=beginbmatrix13newline56endbmatrix+\nλbeginbmatrix34newline66endbmatrix+\nλ^2beginbmatrix10newline01endbmatrix","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The following code creates this NEP, by constructing an object called PEP, an abbreviation for polynomial eigenvalue problem. It subsequently solves it using the NEP solution method implemented in the NEP-solver polyeig:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> A0=[1.0 3; 5 6]; A1=[3.0 4; 6 6]; A2=[1.0 0; 0 1.0];\njulia> nep=PEP([A0,A1,A2])\nPEP(2, Array{Float64,2}[[1.0 3.0; 5.0 6.0], [3.0 4.0; 6.0 6.0], [1.0 0.0; 0.0 1.0]])\njulia> λ,v=polyeig(nep)\n(Complex{Float64}[1.36267+0.0im, -0.824084+0.280682im, -0.824084-0.280682im, -8.7145+0.0im], Complex{Float64}[-1.0+0.0im 0.739183-0.196401im 0.739183+0.196401im 0.627138+0.0im; 0.821812+0.0im -0.501408-0.375337im -0.501408+0.375337im 1.0+0.0im])","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"You have now solved your first nonlinear eigenvalue problem with NEP-PACK.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"In order to verify that we have a solution, we can check that  M(λ) is singular, with a singular vector v such that M(λ)v=0:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> λ1=λ[1]; v1=v[:,1];\njulia> using LinearAlgebra # the norm-function is in this Julia package\njulia> norm(A0*v1+λ1*A1*v1+λ1^2*v1)/norm(v1)\n1.1502634749464687e-14","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"tip: Tip\nMATLAB users: Do you have a NEP defined in MATLAB? You can solve MATLAB-defined NEPs with this package.  See the MATLAB tutorial. We also have some MATLAB implementations of the solvers in NEP-PACK in a separate repository.","category":"page"},{"location":"#Accessing-more-complicated-applications","page":"Introduction","title":"Accessing more complicated applications","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"We have made benchmark examples available through the function nep_gallery:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> nep=nep_gallery(\"dep0\",100);\njulia> size(nep)\n(100, 100)\njulia> λ,v=mslp(nep,tol=1e-10);\njulia> λ\n0.05046248970129549 - 7.60684247532422e-16im\njulia> size(v)\n(100,)\njulia> resnorm=norm(compute_Mlincomb(nep,λ,v))\n5.178780131881974e-13","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Information about the gallery can be found by typing ?nep_gallery. The second argument in the call to nep_gallery is a problem parameter, in this case specifying that the  size of the problem should be 100. The example solves the problem with the NEP-algorithm MSLP. The parameter tol specifies the tolerance for iteration termination.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"note: Note\nAll the NEP-solvers have considerble documentation easily available. Every NEP-solver has documentation accompanied with at least one example, and references to corresponding research papers, which we strongly recommend you to cite if you use the method. This is available to you in Julia's repl-prompt. Type ?mslp and you will see an example how to use mslp and that citation credit should go to A. Ruhe, Algorithms for the nonlinear eigenvalue problem, SIAM J. Numer. Anal. 10 (1973) 674-689. This documentation is the same as the online documentation under the tab NEP-solvers.","category":"page"},{"location":"#A-model-of-a-neuron","page":"Introduction","title":"A model of a neuron","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The following (delay) differential equation models the interaction of two neurons","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"dotx_1(t)=-kappa x_1(t)+betatanh(x_1(t-tau_3))+a_1tanh(x_2(t-tau_2))","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"dotx_2(t)=-kappa x_2(t)+betatanh(x_2(t-tau_3))+a_2tanh(x_1(t-tau_1))","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"See L. P. Shayer and S. A. Campbell.  Stability, bifurcation and multistability in a system of two coupled neurons with multiple time delays. SIAM J. Applied Mathematics , 61(2):673–700, 2000. It is also available as a first demo in DDE-BIFTOOL. The linear stability analysis of this problem requires the solution of a nonlinear eigenvalue problem","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"M(λ)=-λI+A_0+A_1e^-tau_1λ+A_2e^-tau_2λ+A_3e^-tau_3λ","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"where the matrices are the Jacobian at the stationary solution. For the zero stationary solution, the matrices are","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"kappa=0.5; a2=2.34; a1=1; beta=-1;\nA0=-kappa*[1 0; 0 1];\nA1=a2*[0 0; 1 0];\nA2=a1*[0 1; 0 0];\nA3=beta*[1 0; 0 1];","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"We can now create the nonlinear eigenvalue problem and determine the stability by first creating the problem","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> tauv=[0;0.2;0.2;1.5];\njulia> dep=DEP([A0, A1,   A2, A3],tauv);","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The constructor  DEP is an abbreviation for a delay eigenvalue problem, which is a NEP with exponential terms stemming from the stability analysis of a delay-differential equation. See Types and data-structures for other NEP-types. You can now solve this NEP, for instance, with the infinite Arnoldi method:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> λ,V=iar_chebyshev(dep,maxit=100); # This takes some time the first time is run due to JIT-compiler","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The figure in a demo of DDE-BIFTOOL http://ddebiftool.sourceforge.net/demos/neuron/html/demo1_stst.html#3 can be directly generated by","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Gadfly\nset_default_plot_size(12cm, 12cm)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using Gadfly\nλ=[ -0.09712795241565722 + 2.612885243197631e-19im # hide\n         0.30886599775839135 + 4.146563548756125e-18im # hide\n        -0.45584765486526174 + 1.6884551234089458im # hide\n         -0.4558476548652613 - 1.6884551234089418im # hide\n         -0.8832708076887316 + 5.325050575287575im # hide\n         -0.8832708076887288 - 5.3250505752875625im] # hide\nplot(x=real.(λ),y=imag.(λ), Guide.xlabel(\"real(λ)\"), Guide.ylabel(\"imag(λ)\"))","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"tip: Tip\nThis problem is also available in the Gallery by calling dep=nep_gallery(\"neuron0\"). Most of the NEPs constructed in the tutorials are also available in corresponding gallery problems. See all gallery problems under NEP Gallery. In particular, note that the problems in the Berlin-Manchester collection of problems NLEVP are also directly available.","category":"page"},{"location":"#The-\"gun\"-benchmark-problem","page":"Introduction","title":"The \"gun\" benchmark problem","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"One of the most common benchmark problems for NEPs is the so-called \"gun\"-problem. It models an electromagnetic cavity, and it is directly available in the NEP-PACK gallery. (See gallery references or type ?nep_gallery at the repl-prompt.) This is how you can set it up and solve it with the block Newton method:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> nep=nep_gallery(\"nlevp_native_gun\");\njulia> n=size(nep,1)\njulia> S=150^2*[1.0 0; 0 1]; V=[[1 0; 0 1]; zeros(n-2,2)];\njulia> (Z,X)=blocknewton(nep,S=S,X=V,logger=1,armijo_factor=0.5,maxit=20)\nIteration 1: Error: 6.081316e+03\nIteration 2: Error: 1.701970e-02 Armijo scaling=0.031250\nIteration 3: Error: 1.814887e-02 Armijo scaling=0.250000\n...\nIteration 13: Error: 6.257442e-09\nIteration 14: Error: 2.525942e-15","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"This algorithm returns a partial Schur factorization of the NEP, and therefore the eigenvalues of the small matrix Z are eigenvalues of the problem. An eigenpair of the NEP can be extracted by diagonalizing:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> using LinearAlgebra\njulia> (Λ,P)=eigen(Z);\njulia> VV=X*P;  # Construct the eigenvector matrix\njulia> v=VV[:,1]; λ=Λ[1]\n61330.208714730004 + 63185.15983933589im\njulia> norm(compute_Mlincomb(nep,λ,v)) # Very small residual\n1.8270553408452648e-16","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"If you use the NEP-algorithms for research, please give the author of the algorithm credit by citiation. The recommended citation can be found in the function documentation, e.g., ?blocknewton.","category":"page"},{"location":"#Your-own-NEP-nonlinearity","page":"Introduction","title":"Your own NEP nonlinearity","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"As an application researcher, we recommend that you first try to express your problem in the following form since it gives access to several efficient routines associated with the NEP, in turn making it possible to use many NEP-solvers. A problem that can be expressed as a (short) S um of P roducts of M atrices and F unctions can be represented with the objects of type SPMF_NEP in NEP-PACK. For instance, a problem with three terms","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"M(λ) = A+λB+e^sin(λ2)C","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"can be created by","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> A=(1:4)*(1:4)'+I; B=diagm(1 => [1,2,3]); C=ones(4,4);\njulia> f1= λ-> one(λ);\njulia> f2= λ-> λ;\njulia> f3= λ-> exp(sin(λ/2));\njulia> nep=SPMF_NEP([A,B,C],[f1,f2,f3]);","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The NEP is solved by using the NEP-object as a parameter in a call to an algorithm, e.g.,","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> v0 = 0.1*[1,-1,1,-1];\njulia> λ,v=quasinewton(nep,λ=4,v=v0)\n(3.1760990071435193 + 0.0im, Complex{Float64}[2.892363187499394 + 0.0im, -1.6573097795628646 + 0.0im, 0.00729776922332883 + 0.0im, -0.09002519738673213 + 0.0im])","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"As usual, you can check that we computed a sensible solution:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> (A+B*λ+C*exp(sin(λ/2)))*v\n4-element Array{Complex{Float64},1}:\n  -3.489601657766542e-12 + 0.0im\n -1.0118303586944344e-12 + 0.0im\n  -9.480334553029193e-13 + 0.0im\n  -5.912084880273861e-13 + 0.0im","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"note: Note\nThe functions f1,f2 and f3 in the example above have to be defined for scalar values and for matrices (in the matrix function sense, not elementwise sense). This is the reason f1 needs to be defined as one(λ), instead of just 1. Fortunately, many elementary functions in Julia already have matrix function implementations, e.g., exp([1 2 ; 3 4]) will return the matrix exponential of the given matrix.","category":"page"},{"location":"#Chebyshev-interpolation","page":"Introduction","title":"Chebyshev interpolation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"In applications, NEP-nonlinearities may be complicated to implement. Directly using the SPMF-functionality where every function needs to be defined in a matrix function sense may require too much work. In this case you may want to use an approximation method to create a new different NEP object for which the matrix functions are easy to implement (or directly available in the package). We illustrate this property with NEP-PACKs Chebyshev interpolation feature.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Suppose you have the following NEP, which requires a Bessel function. The Bessel function is analytic, but its matrix function is not easily available.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> using SpecialFunctions; # for the besselj\njulia> fv=Vector{Function}(undef,m);\njulia> Av=Vector{Matrix{Float64}}(undef,3)\njulia> fv[1]=s->one(s);\njulia> Av[1]=[ -2.0  -1.0   8.0; -1.0  0  -1.0;   -2.0   -1.0  -2.0];\njulia> fv[2]=s->s;\njulia> Av[2]=[4.0 -7.0  14.0; 8.0  9.0 -13.0; -1.0 -1.0    10.0];\njulia> fv[3]=s->besselj(0, s);\njulia> Av[3]=[-7.0 -0.0 -9.0; 8.0  3.0 -3.0;  0.0 13.0  2.0]","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"We use SPMF_NEP again, but in order to suppress a warning message indicating that evaluation with a  matrix function is not available we use the keyword check_consistency=false.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> nep=SPMF_NEP(Av,fv,check_consistency=false);","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Note that we cannot directly use the nep object with most NEP-solvers, since we did not provide a matrix function implementation for besselj. Any method requiring a derivative will just throw an error message that a matrix function is not defined. Let us now construct an interpolating Chebyshev polynomial, which we can use instead (since its matrix functions are trivial). The command ChebPEP, by default  interpolates a NEP in the interval [-1,1] using Chebyshev points and represent the approximation in a Chebyshev basis:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> cheb=ChebPEP(nep,9,cosine_formula_cutoff=9);","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"We can now use an arbitrary method to try to solve this problem, e.g., the newtonqr method.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> (λ,v)=newtonqr(cheb,λ=0.0,logger=1)\niter 1 err:0.20552458291903797 λ=0.0 + 0.0im\niter 2 err:0.10317368136012978 λ=-3.1180031985377803 + 0.0im\niter 3 err:0.03898166871714645 λ=-0.5814386400379581 + 0.0im\niter 4 err:0.001421286693333467 λ=-0.4572312118506711 + 0.0im\niter 5 err:1.599526685190599e-6 λ=-0.46101438033594805 + 0.0im\niter 6 err:1.9383172515233692e-12 λ=-0.4610101105535983 + 0.0im\niter 7 err:2.1034235144362163e-17 λ=-0.4610101105484241 + 0.0im\n(-0.4610101105484241 + 0.0im, Complex{Float64}[-0.597958+0.0im, 0.322148+0.0im, 1.0+0.0im], Complex{Float64}[-0.257712+0.0im, -0.964465+0.0im, -0.0582387+0.0im])","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"This solved the interpolated problem quite accurately, which turns out to be a reasonable approximation of the original problem:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"julia> norm(compute_Mlincomb(nep,λ,v))\n1.148749763351579e-9","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The function compute_Mlincomb returns the evaluation of M(λ)*v; see the manual section for compute functions.","category":"page"},{"location":"#What-now?","page":"Introduction","title":"What now?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Now you are ready to try out one of our tutorials on artificial boundary conditions, boundary element method, contour integration, or deflation. See also the other tutorials (in the side-bar), or have a look at the examples in NEP-solvers and  NEP Gallery.","category":"page"},{"location":"#How-do-I-cite-it?","page":"Introduction","title":"How do I cite it?","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"We have a preprint for this work. If you find this software useful please cite this preprint by using this citation data:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"@Misc{,\n  author = \t {E. Jarlebring and M. Bennedich and G. Mele and E. Ringh and P. Upadhyaya},\n  title = \t {{NEP-PACK}: A {Julia} package for nonlinear eigenproblems},\n  year = \t {2018},\n  note = \t {https://github.com/nep-pack},\n  eprint = \t {arXiv:1811.09592},\n}","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"If you use a specific NEP-solver, please also give credit to the algorithm researcher. Reference to a corresponding algorithm paper can be found by in, e.g., by writing ?resinv.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"(Image: To the top)","category":"page"},{"location":"types/#Types-and-Data-structures","page":"Types & Data structures","title":"Types & Data structures","text":"","category":"section"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"Nonlinear eigenvalue problems in NEP-PACK are represented by objects of the type NEP. Each NEP-object needs to provide compute functions as we describe in the manual page on compute functions. Efficient compute functions are already implemented for many common and several general types.","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"In the section specific types below, we list a number of common classes. As a user, first see if your problem fits to one of those classes, as NEP-PACK has very efficient compute functions for these classes. If your NEP does not fit into any of the specific types, we recommend that a user tries to specify the problem as an SPMF_NEP, which is described in the section general types. If your problem can be phrased as a sum of two specific or general types, it is recommended that you use the SumNEP-type. NEP-PACK also supports efficient computation with low-rank NEPs via the LowRankFactorizedNEP.","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"If your NEP is not easily expressed as an SPMF_NEP, you may want to use the helper types. The data types associated with compact certain pencils are also supported, as described in the CORK data types.","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"The types also have a number of associated operations and transformation functions. The following example illustrates how you can resample a NEP (by interpolation with a Chebyshev polynomial basis in Chebyshev points provided by the ChebPEP constructor) and apply a NEP-solver which requires many function evaluations, in this case contour_beyn. The two-stage solution approach is much more efficient.","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"julia> nep_bem=nep_gallery(\"bem_fichera\");\njulia> cheb_nep=ChebPEP(nep_bem,20,0,10); # resample the NEP with 20 cheb points\n 32.651313 seconds (263.16 M allocations: 36.279 GiB, 17.19% gc time)\njulia> @time (λ1,v1)=contour_beyn(nep_bem,radius=[5 0.2],σ=5.0, N=100,k=10,);\n180.329069 seconds (1.39 G allocations: 183.462 GiB, 13.01% gc time)\njulia> @time (λ2,v2)=contour_beyn(cheb_nep,radius=[5 0.2],σ=5.0, N=100,k=10,);\n  4.319376 seconds (362.34 k allocations: 8.856 GiB, 12.42% gc time)","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"Note that running the contour integral method on the cheb_nep is much faster, even if we take into account that the resampling takes some computational effort. The computed solutions are very similar","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"julia> λ1\n2-element Array{Complex{Float64},1}:\n 6.450968052414575 - 4.819767260258272e-5im\n 8.105873440358572 - 0.00012794471501522612im\njulia> λ2\n2-element Array{Complex{Float64},1}:\n 6.450968052984224 - 4.819762104884087e-5im\n 8.105873439472735 - 0.0001279450670266529im","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"Moreover, if we want a very accurate solution, we can run a locally convergence iterative method on the original problem. It converges in very few iterations:","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"julia> (λ2_1,v1_1)=quasinewton(nep_bem,λ=λ2[1], v=v2[:,1],logger=1);\nPrecomputing linsolver\niter 1 err:3.638530108313503e-12 λ=6.450968052984224 - 4.819762104884087e-5im\niter 2 err:1.2789912958165988e-14 λ=6.450968052419756 - 4.819768321350077e-5im\njulia> (λ2_2,v1_2)=quasinewton(nep_bem,λ=λ2[2], v=v2[:,2],logger=1)\nPrecomputing linsolver\niter 1 err:3.4824421200567996e-12 λ=8.105873439472735 - 0.0001279450670266529im\niter 2 err:2.05407750614131e-14 λ=8.105873440343123 - 0.00012794469925178411im","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"tip: Tip\nThe use of of Chebyshev interpolation in combination with the boundary element method (but with a companion linearization approach) was presented in  Effenberger and Kressner. \"Chebyshev interpolation for nonlinear eigenvalue problems.\" BIT Numerical Mathematics 52.4 (2012): 933-951. See also the tutorial on boundary element method.","category":"page"},{"location":"types/#Specific-types","page":"Types & Data structures","title":"Specific types","text":"","category":"section"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"DEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.DEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.DEP","text":"type DEP <: AbstractSPMF\nfunction DEP(AA::Vector{AbstractMatrix} [,tauv::Vector=[0,1.0]])\n\nA DEP (Delay Eigenvalue problem) is a problem defined by the sum\n\nM(λ)=-λI + Σ_i A_i exp(-τ_i λ)\n\nwhere all of the matrices are of size nn. This type of NEP describes the stability of time-delay systems.\n\nThe construction takes the system matrices A_i, and tauv is a vector of the values  τ_i.\n\nExample:\n\njulia> A0=randn(3,3); A1=randn(3,3);\njulia> tauv=[0,0.2] # Vector with delays\njulia> dep=DEP([A0,A1],tauv)\njulia> λ=3.0;\njulia> M1=compute_Mder(dep,λ)\njulia> M2=-λ*I+A0+A1*exp(-tauv[2]*λ)\njulia> norm(M1-M2)\n0.0\n\n\n\n\n\n","category":"type"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"There are two types to represent PEPs natively in NEP-PACK. You can use a monomial basis with PEP or a Chebyshev basis with ChebPEP.","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"PEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.PEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.PEP","text":"struct PEP <: AbstractSPMF\nfunction PEP(AA::Vector{AbstractMatrix})\n\nThe type PEP defines a polynomial eigenvalue  problem via its monomial coefficients. A polynomial eigenvalue problem (PEP) is defined by the sum the\n\nΣ_i A_i λ^i\n\nwhere i = 012, and  all of the matrices are of size nn. The vector AA contains A_1.\n\nExample\n\njulia> A0=[1.0 3; 4 5]; A1=A0.+one(2); A2=ones(2,2);\njulia> pep=PEP([A0,A1,A2])\njulia> compute_Mder(pep,3)-(A0+A1*3+A2*9)\n2×2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0\n\nSee also polyeig, companion, ChebPEP, interpolate.\n\n\n\n\n\n","category":"type"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"ChebPEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.ChebPEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.ChebPEP","text":"ChebPEP(orgnep::NEP,k,[a=-1,[b=1]] [,cosine_formula_cutoff=5])\n\nThe type ChebPEP<:AbstractSPMF represents a polynomial function where the function is stored using a Chebyshev basis scaled to the interval [a,b], i.e.,\n\nM(λ)= B_0T_0(λ)++B_k-1T_k-1(λ)\n\nwhere T_i are the scaled and shifted Chebyshev polynomials.\n\nThe constructor ChebPEP takes nep::NEP as an input and interpolates this NEP in k Chebyshev nodes, resulting in a polynomial of degree k-1, represented by its coefficients in the Chebyshev basis. Interpolation in Chebyshev nodes and representation with Chebyshev basis, is known to have attractive approximation properties, as well as robustness with respect to round-off errors.\n\nThe kwarg cosine_formula_cutoff decides how the Chebyshev polynomials should be computed. For larger degrees, it is better to use the cosine formula, whereas for low degrees the explicit monomial expression is more efficient. The explicit monomial expression will be used for degrees lower than cosine_formula_cutoff.\n\nExample:\n\njulia> nep=nep_gallery(\"dep0\");\njulia> chebpep=ChebPEP(nep,9);\njulia> using LinearAlgebra;\njulia> norm(compute_Mder(nep,0.3)-compute_Mder(chebpep,0.3))\n1.2881862971045282e-8\njulia> chebpep=ChebPEP(nep,19); # Better interpolation\njulia> norm(compute_Mder(nep,0.3)-compute_Mder(chebpep,0.3))\n2.0312004517316714e-15\n\nSee also: polyeig, PEP\n\n\n\n\n\n","category":"type"},{"location":"types/#REP","page":"Types & Data structures","title":"REP","text":"","category":"section"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"The Rational Eigenvalue Problem is described by:","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"REP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.REP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.REP","text":"function REP(A,roots,poles)\n\nA REP-call creates a rational eigenvalue problem. The REP is defined by the sum Σ_i A_i s_i(λ)q_i(λ), where i = 0,1,2,..., all of the matrices are of size nn and s_i and q_i are polynomials. The constructor takes the roots and poles as input of polynomials with normalized highest coefficient. The NEP is defined as\n\n-λI+A_0+A_1fracp(λ)q(λ)\n\nwhere p has the roots roots and q has the roots poles.\n\nExample\n\njulia> A0=[1 2; 3 4]; A1=[3 4; 5 6];\njulia> nep=REP([A0,A1],[1,3], [4,5,6]);\njulia> compute_Mder(nep,3)\n2×2 Array{Float64,2}:\n Inf  Inf\n Inf  Inf\njulia> (λ,x)=quasinewton(nep,v=[1;0])\n(-0.3689603779201249 + 0.0im, Complex{Float64}[-2.51824+0.0im, 1.71283+0.0im])\njulia> -λ*x+A0*x+A1*x*(λ-1)*(λ-3)/((λ-4)*(λ-5)*(λ-6))\n2-element Array{Complex{Float64},1}:\n -2.5055998942313806e-13 + 0.0im\n   1.318944953254686e-13 + 0.0im\n\n\n\n\n\n","category":"function"},{"location":"types/#General-types","page":"Types & Data structures","title":"General types","text":"","category":"section"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"The basic class is the abstract class NEP which represents a NEP. All other defined NEPs should inherit from NEP, or from a more specialized version; see, e.g., ProjectableNEP or AbstractSPMF.","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"NEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPCore.NEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPCore.NEP","text":"abstract NEP\n\nA NEP object represents a nonlinear eigenvalue problem. All NEPs should implement\n\nsize(nep::NEP,d)\n\nand at least one of the following\n\nM = compute_Mder(nep::NEP,λ::Number,i::Integer=0)\nV = compute_Mlincomb(nep::NEP,λ::Number,V::AbstractVecOrMat,a::Vector) (or compute_Mlincomb!)\nMM = compute_MM(nep::NEP,S,V)\n\n\n\n\n\n","category":"type"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"Below we list the most common types built-in to NEP-PACK, and further down how you can access the NEP. However, the structure is made for extendability, and hence it is possible for you to extend with your own class of NEPs.","category":"page"},{"location":"types/#SPMF","page":"Types & Data structures","title":"SPMF","text":"","category":"section"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"One of the most common problem types is the SPMF_NEP. SPMF is short for Sum of Products of Matrices and Functions and the NEP is described by","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"M(λ) = sum_i A_i f_i(λ)","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"The constructor of the SPMF_NEP, takes the the matrices and the functions, but also a number of other (optional) parameters which may increase performance or preserve underlying types.","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"SPMF_NEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.SPMF_NEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.SPMF_NEP","text":"struct SPMF_NEP{T<:AbstractMatrix,Ftype}  <: AbstractSPMF{T}\nfunction SPMF_NEP(AA, fii [,check_consistency=true] [,Schur_fact = false]\n                  [,align_sparsity_patterns = false] [,Ftype=ComplexF64])\n\nAn SPMF_NEP is a NEP defined by a Sum of Products of Matrices and Functions, i.e.,\n\nM(λ)=_i A_i f_i(λ)\n\nAll of the matrices A_0 are of size nn and f_i are a functions. The  functions f_i must be defined for matrices in the standard matrix function sense. The constructor creates a SPMF_NEP consisting of matrices AA and functions fii.\n\nParameters\n\nAA is a Vector of matrices. The matrices have to be of the same type. If you need a NEP with different types you can use SumNEP to construct a sum of two SPMF_NEP.\nfii is a Vector of functions. Each function takes one parameter S. The functions must be available both as a scalar valid function and a matrix function. If S is a square matrix, fii[k](S) musst also be a square matrix. If S is a scalar fii[k](S) is a scalar.\ncheck_consistency (default true) determines if we should initiate by running tests to verify that the fii satisfies the conditions that every function is valid both for matrices and scalars. This is done by using @code_typed and the functions need to be type-stable in that sense.\nalign_sparsity_patterns (default false) has effect only for sparse matrices (SparseMatrixCSC). If align_sparsity_patterns=true the SparseMatrixCSC matrices will be replaced by equivalent SparseMatrixCSC matrices where the colptr and rowval are identical. This increases the speed of some functions, e.g., compute_Mder. If align_sparsity_patterns=true the matrices in the NEP should be considered read only. If the sparsity patterns are completely or mostly distinct, it may be more efficient to set this flag to false.\nFtype (default ComplexF64) determines an underlying type of the functions. The output of any function should be \"smaller\" than the promoted type of the input and Ftype. More precisely, if F=fii[k], then the type logic is as follows eltype(F(λ))=promote_type(eltype(λ),Ftype).\nSchur_fact (default false) determines if the compute_MM function should triangularize the matrix before carrying out the computation. This can be faster for large matrices.\n\nExample\n\njulia> A0=[1 3; 4 5]; A1=[3 4; 5 6];\njulia> id_op=S -> one(S) # Note: We use one(S) to be valid both for matrices and scalars\njulia> exp_op=S -> exp(S)\njulia> nep=SPMF_NEP([A0,A1],[id_op,exp_op]);\njulia> compute_Mder(nep,1)-(A0+A1*exp(1))\n2×2 Array{Float64,2}:\n 0.0  0.0\n 0.0  0.0\n\n\n\n\n\n","category":"type"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"AbstractSPMF\nget_Av\nget_fv","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.AbstractSPMF","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.AbstractSPMF","text":"abstract  AbstractSPMF <: ProjectableNEP\n\nAn AbstractSPMF is an abstract class representing NEPs which can be represented as a sum of products of matrices and functions M(λ)=Σ_i A_i f_i(λ), where i = 0,1,2,..., all of the matrices are of size nn and f_i are functions.\n\nAny AbstractSPMF has to have implementations of get_Av() and get_fv() which return the functions and matrices.\n\n\n\n\n\n","category":"type"},{"location":"types/#NonlinearEigenproblems.NEPTypes.get_Av","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.get_Av","text":"get_Av(nep::AbstractSPMF)\n\nReturns an array of matrices A_i in the AbstractSPMF: M(λ)=Σ_i A_i f_i(λ)\n\n\n\n\n\n","category":"function"},{"location":"types/#NonlinearEigenproblems.NEPTypes.get_fv","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.get_fv","text":"get_Av(nep::AbstractSPMF)\n\nReturns an Array of functions (that can be evaluated both as scalar and matrix functions) f_i in the AbstractSPMF: M(λ)=Σ_i A_i f_i(λ)\n\n\n\n\n\n","category":"function"},{"location":"types/#Projectable-NEP-types","page":"Types & Data structures","title":"Projectable NEP types","text":"","category":"section"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"There are also types associated with projection described on  the projection manual page:","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"ProjectableNEP\nProj_NEP","category":"page"},{"location":"types/#SumNEP","page":"Types & Data structures","title":"SumNEP","text":"","category":"section"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"It is also possible to consider NEPs that are sums of other NEPs. For such situations there are SumNEPs. Specifically GenericSumNEP and SPMFSumNEP. Both are constructed using the function SumNEP.","category":"page"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"SumNEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.SumNEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.SumNEP","text":"SumNEP{nep1::NEP,nep2::NEP}\nSumNEP{nep1::AbstractSPMF,nep2::AbstractSPMF}\n\nSumNEP is a function creating an object that corresponds to a sum of two NEPs, i.e., if nep is created by SumNEP it is defined by\n\nM(λ)=M_1(λ)+M_2(λ)\n\nwhere M_1 and M_2 are defined by nep1 and nep2.\n\nExample:\n\njulia> nep1=DEP([ones(3,3),randn(3,3)])\njulia> nep2=PEP([ones(3,3),randn(3,3),randn(3,3)])\njulia> sumnep=SumNEP(nep1,nep2);\njulia> s=3.0;\njulia> M=compute_Mder(sumnep,s);\n3×3 Array{Float64,2}:\n  8.54014     6.71897   7.12007\n -0.943908  -13.0795   -0.621659\n  6.03155    -7.26726  -6.42828\njulia> M1=compute_Mder(nep1,s);\njulia> M2=compute_Mder(nep2,s);\njulia> M1+M2  # Same as M\n3×3 Array{Float64,2}:\n  8.54014     6.71897   7.12007\n -0.943908  -13.0795   -0.621659\n  6.03155    -7.26726  -6.42828\n\nSee also: SPMFSumNEP, GenericSumNEP\n\n\n\n\n\n","category":"function"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"GenericSumNEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.GenericSumNEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.GenericSumNEP","text":"struct GenericSumNEP{NEP1<:NEP,NEP2<:NEP}  <: NEP\n\nSee also: SumNEP, SPMFSumNEP\n\n\n\n\n\n","category":"type"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"SPMFSumNEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.SPMFSumNEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.SPMFSumNEP","text":"struct SPMFSumNEP{NEP1<:AbstractSPMF,NEP2<:AbstractSPMF}  <: AbstractSPMF{AbstractMatrix}\n\nSee also: SumNEP, GenericSumNEP\n\n\n\n\n\n","category":"type"},{"location":"types/#Low-rank-NEPs","page":"Types & Data structures","title":"Low-rank NEPs","text":"","category":"section"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"LowRankFactorizedNEP","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTypes.LowRankFactorizedNEP","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTypes.LowRankFactorizedNEP","text":"struct LowRankFactorizedNEP <: AbstractSPMF\nfunction LowRankFactorizedNEP(L::Vector,U::Vector,f::Vector)\nfunction LowRankFactorizedNEP(L::Vector,U::Vector,A::Vector, f::Vector)\n\nRepresentation of a NEP which has low rank in the sense that it is an SPMF where each of the terms are factorized: A[i]=L[i]*U[i]'. The factorization is provided in the L and U vectors and the full matrix A[i] can be either provided (or is otherwise implicitly computed).\n\nExample:\n\njulia> L=randn(5,1); U=randn(5,1);\njulia> f=S->exp(S)\njulia> nep=LowRankFactorizedNEP([L],[U],[f]);\njulia> X=randn(5,2);\njulia> norm(compute_Mlincomb(nep,0.0,X)-L*U'*X*ones(2),1)\n6.661338147750939e-16\n\n\n\n\n\n","category":"type"},{"location":"types/#CORK-data-types","page":"Types & Data structures","title":"CORK data types","text":"","category":"section"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"CORKPencil","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTransformations.CORKPencil","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTransformations.CORKPencil","text":"struct CORKPencil\nfunction CORKPencil(M,N,Av,Bv,Z);\nfunction CORKPencil(nep,is)\n\nThe struct CORKPencil represents a pencil with a particular structure, as given in the reference. The data can either be constructed directly via the first constructor, or from a NEP in the second constructor. The second constructor takes a NEP and  is which specifies a CORK-structure as well as an approximation method. This can be objects of the type IarCorkLinearization or NleigsCorkLinearization, which are the CORK-linearizations equivalent to (certain versions of) iar and nleigs.\n\nSee buildPencil how to build standard pencil.\n\nExample:\n\nThe following example constructs a  CORKPencil from a general NEP and then computes approximations of NEPs by the interpolation approach of nleigs.\n\njulia> using LinearAlgebra\njulia> A=(1:4)*(1:4)'+I; B=diagm(1 => [1,2,3]); C=ones(4,4);\njulia> f1= λ-> one(λ);\njulia> f2= λ-> λ;\njulia> f3= λ-> exp(sin(λ/2));\njulia> nep=SPMF_NEP([A,B,C],[f1,f2,f3]);\njulia> cp=CORKPencil(nep,NleigsCorkLinearization());\njulia> (A,B)=buildPencil(cp) # Form the pencil\njulia> λv=eigen(A,B).values;\njulia> λ=λv[sortperm(abs.(λv))[1]]; # Smallest eigval\njulia> minimum(svdvals(compute_Mder(nep,λ))) # It's a solution\n2.4364382475487156e-11\n\nReferences:\n\nCompact rational Krylov methods for nonlinear eigenvalue problems SIAM Journal on Matrix Analysis and Applications, 36 (2), 820-838, 2015.\n\n\n\n\n\n\n","category":"type"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"buildPencil","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTransformations.buildPencil","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTransformations.buildPencil","text":"(A,B)=buildPencil(cp)\n\nConstructs a pencil from a CORKPencil or CORKPencilLR. The returned matrices correspond to a generalized eigenvalue problem. See also CORKPencil, CORKPencilLR. See [lowRankCompress] for examples.\n\n\n\n\n\n","category":"function"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"CORKPencilLR","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTransformations.CORKPencilLR","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTransformations.CORKPencilLR","text":"struct CORKPencilLR\nfunction CORKPencilLR(M,N,Av,AvLR,Bv,BvLR,Z);\n\nRepresents / constructs a low-rank CORK-pencil. AvLR, BvLR and Z correspond to the low-rank factorization of terms Av and Bv. See CORKPencil and reference below.\n\nExample\n\nThe example illustrate a low-rank linearization of a Taylor expansion of the NEP A0-λI+vv^Te^-λ.\n\njulia> A0=[1.0 3.0; -1.0 2.0]/10;\njulia> v=reshape([-1.0 ; 1]/sqrt(2),n,1);\n\njulia> Av=[-A0-v*v']\njulia> Bv=[-one(A0)-v*v']\njulia> BvLR=[v/2, -v/3, v/4, -v/5, v/6, -v/7,  v/8, -v/9]\njulia> AvLR=zero.(BvLR);\njulia> Z=v;\njulia> d=9;\njulia> M=diagm( 0 =>  ones(d) )[2:end,:]\njulia> N=diagm( -1 =>  1 ./ (1:d-1) )[2:end,:]\njulia> cplr=CORKPencilLR(M,N,Av,AvLR,Bv,BvLR,Z);\njulia> (AA,BB)=buildPencil(cplr);\njulia> λ=eigen(AA,BB).values[end];\njulia> minimum(svdvals(A0-λ*I+v*v'*exp(-λ)))\n8.870165379112754e-13\n\nReferences:\n\nSection 7 in Compact rational Krylov methods for nonlinear eigenvalue problems SIAM Journal on Matrix Analysis and Applications, 36 (2), 820-838, 2015.\n\n\n\n\n\n","category":"type"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"lowRankCompress","category":"page"},{"location":"types/#NonlinearEigenproblems.NEPTransformations.lowRankCompress","page":"Types & Data structures","title":"NonlinearEigenproblems.NEPTransformations.lowRankCompress","text":"cplr=lowRankCompress(cp_org::CORKPencil,dtilde,rk)\n\nConstructs a CORKPencilLR from a CORKPencil. This is done by assuming that terms higher than dtilde are of low rank, with rank rk. More precisely, all A[j] and B[j] for j>dtilde are assumed to be of the form C_jZ^T.\n\nExample\n\nThis illustrates how to form a CORKPencil from a NEP, and subsequently form a smaller pencil using CORKPencilLR.\n\njulia> A0=[1.0 3.0; -1.0 2.0]/10;\njulia> v=[-1.0 ; 1]/sqrt(2);\njulia> nep=DEP([A0,v*v']);\njulia> cp_org=CORKPencil(nep,IarCorkLinearization(d=10));\njulia> cplr=lowRankCompress(cp_org::CORKPencil,1,1);\njulia> (AA,BB)=buildPencil(cplr);\njulia> λ=eigen(AA,BB).values[end];\njulia> minimum(svdvals(A0-λ*I+v*v'*exp(-λ))) # Check if it is an eigval\n2.7621446071952216e-14\n\n\n\n\n\n","category":"function"},{"location":"types/#Helper-types","page":"Types & Data structures","title":"Helper types","text":"","category":"section"},{"location":"types/","page":"Types & Data structures","title":"Types & Data structures","text":"There are also the helper types Mder_NEP and Mder_Mlincomb_NEP. These are further described in the section about Compute functions","category":"page"}]
}
